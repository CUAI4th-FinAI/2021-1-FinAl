{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPTER 07 합성곱 신경망(CNN)\n",
    "\n",
    "### 7.1 전체 구조\n",
    "\n",
    "지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었고, 이를 **완전연결(전연결)** 이라고 하며, 연결된 계층을 **Affine 계층**이라는 이름으로 구현함. \n",
    "- 완전연결 신경망은 Affine 계층 뒤에 활성화 함수를 갖는 ReLU(혹은 Sigmoid 계층)이 이어짐. \n",
    "- Affine-ReLU 조합의 연결이 쌓이는 구조,Affine-Softmax로 이어지는 소프트맥스 계층에서 최종 결과(확률) 출력\n",
    "\n",
    "CNN은 새로운 합성곱계층과 풀링계층이 추가됨. \n",
    "- Conv-ReLU-(Pooling)의 흐름으로 연결됨.\n",
    "- 출력에 가까운 층에서는 지금까지의 Affine-ReLU 구성을 사용할 수 있으며, 마지막 출력계층에서 Affine-Softmax조합을 그대로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 합성곱 계층\n",
    "\n",
    "#### 완전연결 계층의 문제점\n",
    "\n",
    "**데이터의 형상이 무시된다**<br>\n",
    "ex) 이미지 데이터를 완전연결 계층에 입력할때는 3차원(세로/가로/채널(색상)) 데이터를 1차원 데이터로 바꿔줘야함. <br>\n",
    "완전 연결 계층은 형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원의 뉴런)으로 취급하여 형상에 담긴 정보를 살릴 수 없음\n",
    "\n",
    "**합성곱 계층은 형상을 유지한다**<br>\n",
    "이미지처럼 형상을 가진 데이터도 제대로 이해할 수 있음\n",
    "\n",
    "#### 패딩\n",
    "\n",
    "- 합성곱 연산을 수행하기 전 입력 데이터 주변을 특정값(ex.0)으로 채우는 작업\n",
    "- 출력 크기를 조정할 목적으로 사용\n",
    "- 입력 데이터의 공간적 크기를 고정한 채로 다음 계층에 전달하는 방법\n",
    "\n",
    "#### 스트라이드\n",
    "\n",
    "- 필터에 적용하는 위치의 간격\n",
    "\n",
    "입력 크기를 (H,W), 필터 크기를 (FH,FW), 출력 크기를 (OH,OW), 패딩을 P, 스트라이드를 S라 하면 출력 크기는 다음 식으로 계산\n",
    "\n",
    "OH = (H+2P-FH)/S +1\n",
    "\n",
    "OW = (W+2P-FW)/S +1\n",
    "\n",
    "\n",
    "#### 3차원 데이터의 합성곱 연산\n",
    "\n",
    "입력 데이터의 채널 수와 필터의 채널 수가 같아야 함을 주의\n",
    "\n",
    "\n",
    "#### 배치 처리\n",
    "![batch image](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile1.uf.tistory.com%2Fimage%2F99E4C84E5C4D31B7280942)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 풀링 계층\n",
    "\n",
    "풀링은 세로/가로 방향의 공간을 줄이는 연산<br>\n",
    "최대 풀링, 평균 풀링 등의 방법이 있음<br>\n",
    "![python image2](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F99A50F395AAD46301BE8C1)\n",
    "\n",
    "#### 풀링 계층의 특징\n",
    "\n",
    "1. **학습해야 할 매개변수가 없음**\n",
    "2. **채널 수가 변하지 않음**\n",
    "3. **입력의 변화에 영향을 적게 받음**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 합성 곱/ 풀링 계층 구현하기\n",
    "\n",
    "#### im2col\n",
    "\n",
    "\n",
    "<img src=\"https://blog.kakaocdn.net/dn/5a4T2/btqGvQi5TOO/O52OKATjFmFqnzNBKyJtvK/img.png\"  width=\"400\" height=\"200\">\n",
    "\n",
    "\n",
    "![im2col_2.png](https://blog.kakaocdn.net/dn/7QTDk/btqQmOWfPXc/AFhJWTYhSFIVuslykBvpg0/img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 중간 데이터（backward 시 사용）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  풀링 계층 구현하기\n",
    "\n",
    "다음의 세단계로 진행\n",
    "1. 입력 데이터를 전개한다\n",
    "2. 행별 최댓값을 구한다\n",
    "3. 적절한 모양으로 성형한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 CNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"C:/Users/minjuKim/Desktop/[FIN_AI]_study_myself/deep-learning-from-scratch-master\")  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2991201185697814\n",
      "=== epoch:1, train acc:0.258, test acc:0.281 ===\n",
      "train loss:2.296271453140716\n",
      "train loss:2.2908352497947146\n",
      "train loss:2.2856821197858235\n",
      "train loss:2.275070933430098\n",
      "train loss:2.258414648421277\n",
      "train loss:2.2443344045237295\n",
      "train loss:2.22329914280903\n",
      "train loss:2.195714760165943\n",
      "train loss:2.1359716584985717\n",
      "train loss:2.1312564572384334\n",
      "train loss:2.088970088558379\n",
      "train loss:2.0290442900956056\n",
      "train loss:2.0246334248785764\n",
      "train loss:1.9245283771049706\n",
      "train loss:1.8230658701828155\n",
      "train loss:1.8070708627185632\n",
      "train loss:1.684438088636148\n",
      "train loss:1.6133453210922641\n",
      "train loss:1.5995651497350707\n",
      "train loss:1.5581410693192148\n",
      "train loss:1.4136803366709998\n",
      "train loss:1.323693697400723\n",
      "train loss:1.3384338487119183\n",
      "train loss:1.3107193042868883\n",
      "train loss:1.1914065829635836\n",
      "train loss:1.1463547687041067\n",
      "train loss:0.9203726975492547\n",
      "train loss:0.9307846661914501\n",
      "train loss:1.0217390427316588\n",
      "train loss:0.8331217268513474\n",
      "train loss:0.9120374658976135\n",
      "train loss:0.8917634814184154\n",
      "train loss:0.9425142530826407\n",
      "train loss:0.8237819136644846\n",
      "train loss:0.7061375431479917\n",
      "train loss:0.7424664021251899\n",
      "train loss:0.6701452319000812\n",
      "train loss:0.583499024888468\n",
      "train loss:0.702681130504739\n",
      "train loss:0.7654115000152878\n",
      "train loss:0.5979450540002864\n",
      "train loss:0.6349908843826971\n",
      "train loss:0.6035940319148932\n",
      "train loss:0.5968803624624982\n",
      "train loss:0.564133861151215\n",
      "train loss:0.6111767884683655\n",
      "train loss:0.5080432394516494\n",
      "train loss:0.43801609178576567\n",
      "train loss:0.6112023330126469\n",
      "train loss:0.38242149671276915\n",
      "train loss:0.5185850277947334\n",
      "train loss:0.38556901325721976\n",
      "train loss:0.4037185008877628\n",
      "train loss:0.507079199327911\n",
      "train loss:0.5995175331498814\n",
      "train loss:0.4557386276259288\n",
      "train loss:0.4871709198333341\n",
      "train loss:0.746149856615551\n",
      "train loss:0.3896470920696843\n",
      "train loss:0.6907404627108156\n",
      "train loss:0.5187748233910123\n",
      "train loss:0.5483156773789288\n",
      "train loss:0.43903471281315204\n",
      "train loss:0.4599703841456178\n",
      "train loss:0.6114460769708994\n",
      "train loss:0.4213859229617215\n",
      "train loss:0.6564792403559477\n",
      "train loss:0.5807124035513292\n",
      "train loss:0.4777258571717466\n",
      "train loss:0.42858409987236795\n",
      "train loss:0.36967450737736657\n",
      "train loss:0.542912246502755\n",
      "train loss:0.318855995294209\n",
      "train loss:0.5667427943565596\n",
      "train loss:0.4662397963313136\n",
      "train loss:0.5021077183271826\n",
      "train loss:0.4407870842470036\n",
      "train loss:0.4476118361294526\n",
      "train loss:0.42964420004587744\n",
      "train loss:0.3397734733928713\n",
      "train loss:0.5091937131150026\n",
      "train loss:0.6460817503631685\n",
      "train loss:0.3772881172833278\n",
      "train loss:0.5087563090606987\n",
      "train loss:0.41161059285103724\n",
      "train loss:0.41941699825503265\n",
      "train loss:0.5515889635667626\n",
      "train loss:0.5152982752001058\n",
      "train loss:0.3577690986834608\n",
      "train loss:0.2940004648624743\n",
      "train loss:0.3917278147796952\n",
      "train loss:0.35254039214328114\n",
      "train loss:0.21686750519022296\n",
      "train loss:0.41049730246911914\n",
      "train loss:0.26065830081653274\n",
      "train loss:0.34091645287513067\n",
      "train loss:0.3250803212659041\n",
      "train loss:0.4671924596139163\n",
      "train loss:0.3875461385239813\n",
      "train loss:0.41628679016761533\n",
      "train loss:0.2489441220930023\n",
      "train loss:0.4315170723846149\n",
      "train loss:0.38922371622654095\n",
      "train loss:0.3627059788517377\n",
      "train loss:0.3650116627958193\n",
      "train loss:0.2452834584485489\n",
      "train loss:0.35277121205663325\n",
      "train loss:0.4238493395040664\n",
      "train loss:0.19637873385900725\n",
      "train loss:0.4507424712890246\n",
      "train loss:0.4595883107059185\n",
      "train loss:0.2828184664857753\n",
      "train loss:0.44513569582514223\n",
      "train loss:0.6358091206115817\n",
      "train loss:0.4178864685679997\n",
      "train loss:0.42100989139360656\n",
      "train loss:0.3946683315720972\n",
      "train loss:0.21423091459363172\n",
      "train loss:0.44066822157553254\n",
      "train loss:0.2971607776239989\n",
      "train loss:0.26963535318662935\n",
      "train loss:0.3464775900662035\n",
      "train loss:0.3837400481998823\n",
      "train loss:0.5286841436188293\n",
      "train loss:0.41755139020349985\n",
      "train loss:0.23101450335377233\n",
      "train loss:0.34936295610164547\n",
      "train loss:0.4190823993873959\n",
      "train loss:0.3307831864231585\n",
      "train loss:0.47053547276054397\n",
      "train loss:0.28457348045939873\n",
      "train loss:0.370409786820282\n",
      "train loss:0.4292748462233996\n",
      "train loss:0.22653093266176996\n",
      "train loss:0.39536927797515875\n",
      "train loss:0.2856564596722772\n",
      "train loss:0.23447594765566568\n",
      "train loss:0.2981384776040978\n",
      "train loss:0.4035762705521908\n",
      "train loss:0.24101913917641427\n",
      "train loss:0.38152593408178603\n",
      "train loss:0.27590569326092956\n",
      "train loss:0.5054326785615936\n",
      "train loss:0.47744088833532866\n",
      "train loss:0.3699822268681494\n",
      "train loss:0.3094311070795386\n",
      "train loss:0.3380556272220444\n",
      "train loss:0.3468444470101554\n",
      "train loss:0.5176226806432682\n",
      "train loss:0.3495383739401777\n",
      "train loss:0.3531122032726944\n",
      "train loss:0.36030975038049656\n",
      "train loss:0.31073402663509475\n",
      "train loss:0.3183198964735639\n",
      "train loss:0.2547507572940393\n",
      "train loss:0.3187289250685826\n",
      "train loss:0.25845718453414784\n",
      "train loss:0.4336639972349299\n",
      "train loss:0.40994912349626267\n",
      "train loss:0.2929809552483671\n",
      "train loss:0.4288362617949039\n",
      "train loss:0.33358145246548715\n",
      "train loss:0.3755178665855905\n",
      "train loss:0.4065646708847509\n",
      "train loss:0.5640921937559374\n",
      "train loss:0.3178109322745841\n",
      "train loss:0.29236428291076266\n",
      "train loss:0.3582051453787047\n",
      "train loss:0.2714955204780088\n",
      "train loss:0.20502624350143406\n",
      "train loss:0.21511867797082107\n",
      "train loss:0.1562488891813584\n",
      "train loss:0.4724520939288604\n",
      "train loss:0.3510135524897211\n",
      "train loss:0.23160647944012755\n",
      "train loss:0.4114951028168925\n",
      "train loss:0.24330918080440378\n",
      "train loss:0.21186564155974252\n",
      "train loss:0.49206638392274676\n",
      "train loss:0.21143571957582835\n",
      "train loss:0.21629004466176732\n",
      "train loss:0.5341465958977528\n",
      "train loss:0.1907579037516986\n",
      "train loss:0.20813882246855792\n",
      "train loss:0.33410416281807775\n",
      "train loss:0.451476148694462\n",
      "train loss:0.3225179087106318\n",
      "train loss:0.3348724474298438\n",
      "train loss:0.2553658123619361\n",
      "train loss:0.36806588446583\n",
      "train loss:0.37973286440448184\n",
      "train loss:0.2982131193895044\n",
      "train loss:0.21376814715221537\n",
      "train loss:0.26644743555375533\n",
      "train loss:0.3766812178677023\n",
      "train loss:0.3104997766018267\n",
      "train loss:0.17561303193836547\n",
      "train loss:0.1668660744140054\n",
      "train loss:0.20480077019100615\n",
      "train loss:0.26597156018532075\n",
      "train loss:0.30582820923044873\n",
      "train loss:0.31604121727242634\n",
      "train loss:0.32022561790023796\n",
      "train loss:0.1971476135364769\n",
      "train loss:0.2567486446057303\n",
      "train loss:0.3481186916114801\n",
      "train loss:0.2779189309538704\n",
      "train loss:0.37877804751093064\n",
      "train loss:0.2807110463698933\n",
      "train loss:0.3071714160623461\n",
      "train loss:0.25641852427841494\n",
      "train loss:0.2554950586260682\n",
      "train loss:0.1849310160261207\n",
      "train loss:0.2646807991776458\n",
      "train loss:0.20242165419522845\n",
      "train loss:0.17799273719309333\n",
      "train loss:0.1833628754789323\n",
      "train loss:0.302537130206506\n",
      "train loss:0.3271300259686316\n",
      "train loss:0.3209457085041622\n",
      "train loss:0.25327313750304176\n",
      "train loss:0.39217695002270503\n",
      "train loss:0.22850572191802082\n",
      "train loss:0.3900573681326951\n",
      "train loss:0.258757129363429\n",
      "train loss:0.19185098631012884\n",
      "train loss:0.18875078420421898\n",
      "train loss:0.5237360476934708\n",
      "train loss:0.16808086094858665\n",
      "train loss:0.2335607373563514\n",
      "train loss:0.31352342315588666\n",
      "train loss:0.20696893453407253\n",
      "train loss:0.25466400135777995\n",
      "train loss:0.38863829036179487\n",
      "train loss:0.36860943104319316\n",
      "train loss:0.40749363440205044\n",
      "train loss:0.21574827786977818\n",
      "train loss:0.32314968991535037\n",
      "train loss:0.39242380920919073\n",
      "train loss:0.36279185997351654\n",
      "train loss:0.37822506766128294\n",
      "train loss:0.22569444095547092\n",
      "train loss:0.4311840245874076\n",
      "train loss:0.44957553073465895\n",
      "train loss:0.3450091869742929\n",
      "train loss:0.287887585016102\n",
      "train loss:0.3955142713818887\n",
      "train loss:0.24420370170880887\n",
      "train loss:0.44680944633638503\n",
      "train loss:0.2663952330950551\n",
      "train loss:0.4248198880546887\n",
      "train loss:0.34500445413773057\n",
      "train loss:0.2443097879974628\n",
      "train loss:0.20572466808258041\n",
      "train loss:0.3424291176248977\n",
      "train loss:0.3111547673267289\n",
      "train loss:0.2304090520954445\n",
      "train loss:0.35831334639124973\n",
      "train loss:0.33475908251489483\n",
      "train loss:0.3290232555932428\n",
      "train loss:0.38447694811493827\n",
      "train loss:0.2675367747891499\n",
      "train loss:0.26671578033173304\n",
      "train loss:0.27957812525047343\n",
      "train loss:0.287410791942147\n",
      "train loss:0.2057071623422201\n",
      "train loss:0.41886271621654103\n",
      "train loss:0.2283634251989399\n",
      "train loss:0.2970870412876865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21604050231537028\n",
      "train loss:0.1974705273427285\n",
      "train loss:0.2845026032692654\n",
      "train loss:0.34526832320634776\n",
      "train loss:0.17204204403102769\n",
      "train loss:0.3349357760845455\n",
      "train loss:0.40779324744013334\n",
      "train loss:0.29552876118058796\n",
      "train loss:0.4909131572130825\n",
      "train loss:0.2161559255387894\n",
      "train loss:0.26293670367684674\n",
      "train loss:0.14219785223028883\n",
      "train loss:0.19511564552519028\n",
      "train loss:0.24756400631735115\n",
      "train loss:0.2334041770226391\n",
      "train loss:0.13184171271784695\n",
      "train loss:0.24433299993696886\n",
      "train loss:0.29606561093236133\n",
      "train loss:0.2982190656373017\n",
      "train loss:0.3117622030697369\n",
      "train loss:0.38870850519995814\n",
      "train loss:0.26087342210387127\n",
      "train loss:0.2202614802244915\n",
      "train loss:0.2522553141727874\n",
      "train loss:0.3126936278374703\n",
      "train loss:0.20451794509526433\n",
      "train loss:0.35305957710271235\n",
      "train loss:0.3066428593243551\n",
      "train loss:0.3396336691417892\n",
      "train loss:0.17198924007190286\n",
      "train loss:0.18298461392295484\n",
      "train loss:0.21197055015381708\n",
      "train loss:0.20510909141091596\n",
      "train loss:0.21294693926229716\n",
      "train loss:0.2288021486289022\n",
      "train loss:0.17969420476639697\n",
      "train loss:0.1458022191250526\n",
      "train loss:0.09394027364465046\n",
      "train loss:0.21389970714373177\n",
      "train loss:0.3334979975739524\n",
      "train loss:0.33576558104767584\n",
      "train loss:0.19172269839644737\n",
      "train loss:0.24558379461733865\n",
      "train loss:0.31178190597241207\n",
      "train loss:0.24164123877886406\n",
      "train loss:0.15448783863563909\n",
      "train loss:0.2576771919575922\n",
      "train loss:0.13609188338698286\n",
      "train loss:0.22373010900843032\n",
      "train loss:0.2067875017760204\n",
      "train loss:0.21726440175989914\n",
      "train loss:0.18740205613331845\n",
      "train loss:0.19585283161764772\n",
      "train loss:0.31399418478300023\n",
      "train loss:0.274152183043555\n",
      "train loss:0.19349552274784249\n",
      "train loss:0.17652471952048818\n",
      "train loss:0.29589529415679494\n",
      "train loss:0.2865565498632383\n",
      "train loss:0.23638834400018913\n",
      "train loss:0.2273462483834561\n",
      "train loss:0.21930883419241998\n",
      "train loss:0.22888122312766931\n",
      "train loss:0.17273824289033635\n",
      "train loss:0.13842423001755663\n",
      "train loss:0.17320894394589798\n",
      "train loss:0.23152216904929002\n",
      "train loss:0.16355495375414952\n",
      "train loss:0.3880250509487721\n",
      "train loss:0.24149412495257758\n",
      "train loss:0.2328728482195364\n",
      "train loss:0.3597088574686043\n",
      "train loss:0.2986686213538934\n",
      "train loss:0.12168452970584509\n",
      "train loss:0.19583216834139716\n",
      "train loss:0.14157613638901687\n",
      "train loss:0.19859125269063393\n",
      "train loss:0.3848187425411976\n",
      "train loss:0.20688442945099797\n",
      "train loss:0.22141579008078147\n",
      "train loss:0.20310677597832996\n",
      "train loss:0.17509326409911835\n",
      "train loss:0.14823271392879175\n",
      "train loss:0.12434149407347665\n",
      "train loss:0.07301965910450325\n",
      "train loss:0.2406667893764576\n",
      "train loss:0.27752533272485713\n",
      "train loss:0.27760034990063553\n",
      "train loss:0.2555769135951281\n",
      "train loss:0.23049039406508898\n",
      "train loss:0.15801724263783343\n",
      "train loss:0.10094094338305906\n",
      "train loss:0.31112105639741683\n",
      "train loss:0.19726331170616557\n",
      "train loss:0.15585213904509784\n",
      "train loss:0.1608874762747873\n",
      "train loss:0.18180143740717403\n",
      "train loss:0.1975535110190274\n",
      "train loss:0.19606698187534022\n",
      "train loss:0.2512234518114858\n",
      "train loss:0.19722435903370933\n",
      "train loss:0.3006871045425958\n",
      "train loss:0.27543518082851737\n",
      "train loss:0.3581281280995573\n",
      "train loss:0.1391078104448067\n",
      "train loss:0.21801294421986747\n",
      "train loss:0.1659561108515595\n",
      "train loss:0.12701405121401213\n",
      "train loss:0.3750828117520518\n",
      "train loss:0.2037370976225017\n",
      "train loss:0.33454072690872194\n",
      "train loss:0.10210304327136316\n",
      "train loss:0.12256711848740713\n",
      "train loss:0.10546448359285661\n",
      "train loss:0.1444970428096225\n",
      "train loss:0.23860515449921682\n",
      "train loss:0.1715003376220182\n",
      "train loss:0.3497245902042953\n",
      "train loss:0.12742710459132112\n",
      "train loss:0.269901904458565\n",
      "train loss:0.22061217291401405\n",
      "train loss:0.10536123671832548\n",
      "train loss:0.15603479382629126\n",
      "train loss:0.2934135686802459\n",
      "train loss:0.22037263466739782\n",
      "train loss:0.31198225940343793\n",
      "train loss:0.23457325465619663\n",
      "train loss:0.17752850120877153\n",
      "train loss:0.22500685986805513\n",
      "train loss:0.13456280119219277\n",
      "train loss:0.1441541507108111\n",
      "train loss:0.19936826025298127\n",
      "train loss:0.1968099498900341\n",
      "train loss:0.2086341978350558\n",
      "train loss:0.1097596456272618\n",
      "train loss:0.20551793951307143\n",
      "train loss:0.14369881439234242\n",
      "train loss:0.29929594812917987\n",
      "train loss:0.2753600272439081\n",
      "train loss:0.07043184875782427\n",
      "train loss:0.17212207167926166\n",
      "train loss:0.14718467736703789\n",
      "train loss:0.4070133145960778\n",
      "train loss:0.3123972377662339\n",
      "train loss:0.12136196260691862\n",
      "train loss:0.32967141188258964\n",
      "train loss:0.2780268426917044\n",
      "train loss:0.2507741082208011\n",
      "train loss:0.13564842569820199\n",
      "train loss:0.15602948390988325\n",
      "train loss:0.24654716755672867\n",
      "train loss:0.21023509959412706\n",
      "train loss:0.1360592285808195\n",
      "train loss:0.2878918553271545\n",
      "train loss:0.13145185225402437\n",
      "train loss:0.20299271609716985\n",
      "train loss:0.2524217932541065\n",
      "train loss:0.172902016705703\n",
      "train loss:0.18322329089264283\n",
      "train loss:0.17166816008269145\n",
      "train loss:0.33250470364460094\n",
      "train loss:0.16314205309726235\n",
      "train loss:0.176101826457695\n",
      "train loss:0.21672257843354004\n",
      "train loss:0.1847320733731646\n",
      "train loss:0.2683390198447713\n",
      "train loss:0.15719039063185078\n",
      "train loss:0.2074799027446339\n",
      "train loss:0.2169923764795223\n",
      "train loss:0.14957459192703593\n",
      "train loss:0.2367130737383563\n",
      "train loss:0.22359549095313444\n",
      "train loss:0.11464664651804835\n",
      "train loss:0.12891553376861384\n",
      "train loss:0.18622481128439683\n",
      "train loss:0.24600590047271464\n",
      "train loss:0.15410707604425292\n",
      "train loss:0.1761078716437371\n",
      "train loss:0.18635954593009146\n",
      "train loss:0.14017170543170399\n",
      "train loss:0.12008758878208814\n",
      "train loss:0.2617718827661009\n",
      "train loss:0.2916550254164347\n",
      "train loss:0.19067444380713008\n",
      "train loss:0.20341781900406125\n",
      "train loss:0.22488033346326852\n",
      "train loss:0.14716643687217457\n",
      "train loss:0.12324165847539324\n",
      "train loss:0.3816784359852194\n",
      "train loss:0.27470343751685516\n",
      "train loss:0.1629384919489523\n",
      "train loss:0.21571275521790395\n",
      "train loss:0.15504713994371405\n",
      "train loss:0.1626228624711727\n",
      "train loss:0.18589456221624331\n",
      "train loss:0.2493085045492193\n",
      "train loss:0.16948496199193383\n",
      "train loss:0.16094320512588225\n",
      "train loss:0.12649239746964436\n",
      "train loss:0.12367489243253008\n",
      "train loss:0.1462970940174385\n",
      "train loss:0.1580883067884848\n",
      "train loss:0.2369747715917661\n",
      "train loss:0.18342735945671979\n",
      "train loss:0.27802954360359045\n",
      "train loss:0.16880130435137558\n",
      "train loss:0.23281433072901933\n",
      "train loss:0.20188809972051658\n",
      "train loss:0.27782391383821126\n",
      "train loss:0.28369086000153915\n",
      "train loss:0.20613021807750403\n",
      "train loss:0.23485712973422018\n",
      "train loss:0.26145696727998896\n",
      "train loss:0.14316025755180692\n",
      "train loss:0.1825568310051911\n",
      "train loss:0.20264847679295642\n",
      "train loss:0.13437694847149928\n",
      "train loss:0.1893719835515362\n",
      "train loss:0.13579683345035465\n",
      "train loss:0.10173586400930924\n",
      "train loss:0.29128513622865343\n",
      "train loss:0.09569312007541911\n",
      "train loss:0.2008564490034116\n",
      "train loss:0.3140274190649689\n",
      "train loss:0.26856944680809236\n",
      "train loss:0.1413948601659956\n",
      "train loss:0.21094879611820447\n",
      "train loss:0.18041989492405985\n",
      "train loss:0.14285685335161266\n",
      "train loss:0.1464731743584336\n",
      "train loss:0.17773666034007995\n",
      "train loss:0.10376490475526272\n",
      "train loss:0.14007451667860538\n",
      "train loss:0.25545327187004796\n",
      "train loss:0.2633122974737838\n",
      "train loss:0.23931027851675793\n",
      "train loss:0.3174922122758907\n",
      "train loss:0.1646351896884482\n",
      "train loss:0.2213702265580714\n",
      "train loss:0.15945253657977282\n",
      "train loss:0.2807565288403171\n",
      "train loss:0.18237845961988172\n",
      "train loss:0.2059848426195718\n",
      "train loss:0.18824783123453137\n",
      "train loss:0.14481453967892982\n",
      "train loss:0.2370739093007183\n",
      "train loss:0.25958373821968894\n",
      "train loss:0.12447319577364553\n",
      "train loss:0.15547993055049156\n",
      "train loss:0.1372027868903581\n",
      "train loss:0.10337436983066782\n",
      "train loss:0.2187368237378145\n",
      "train loss:0.15750802603771108\n",
      "train loss:0.15599265994156658\n",
      "train loss:0.13537654102241495\n",
      "train loss:0.16864211461313963\n",
      "train loss:0.20255071768251642\n",
      "train loss:0.18171007676654113\n",
      "train loss:0.12958083536519438\n",
      "train loss:0.17064557785083503\n",
      "train loss:0.14084887865556495\n",
      "train loss:0.2689798676081581\n",
      "train loss:0.14828421578948164\n",
      "train loss:0.10431188291830161\n",
      "train loss:0.11184407661273371\n",
      "train loss:0.19102675620299245\n",
      "train loss:0.17862742572402027\n",
      "train loss:0.19499785039728168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0717087041566315\n",
      "train loss:0.17574889275890498\n",
      "train loss:0.17421935727661852\n",
      "train loss:0.07453646384104426\n",
      "train loss:0.14905869274254527\n",
      "train loss:0.1621182830397979\n",
      "train loss:0.1111491262792804\n",
      "train loss:0.07495379394760862\n",
      "train loss:0.1665510606251175\n",
      "train loss:0.19184616629096804\n",
      "train loss:0.11881647104054492\n",
      "train loss:0.14543806337708676\n",
      "train loss:0.1472646397671361\n",
      "train loss:0.17513141738509932\n",
      "train loss:0.25910532747217\n",
      "train loss:0.21504025039277092\n",
      "train loss:0.16311443747591217\n",
      "train loss:0.20922131622063206\n",
      "train loss:0.16709329486700297\n",
      "train loss:0.1460988154093952\n",
      "train loss:0.17565235384436398\n",
      "train loss:0.16217512538627854\n",
      "train loss:0.09986358808874878\n",
      "train loss:0.0948818095222265\n",
      "train loss:0.15762859391263306\n",
      "train loss:0.19245245886419313\n",
      "train loss:0.13145422151545036\n",
      "train loss:0.33400131862994953\n",
      "train loss:0.3331172544848146\n",
      "train loss:0.11286903286175848\n",
      "train loss:0.16828149044855056\n",
      "train loss:0.09130247805976946\n",
      "train loss:0.058472209431858116\n",
      "train loss:0.1326059620126567\n",
      "train loss:0.16754329292131673\n",
      "train loss:0.24439772208156146\n",
      "train loss:0.23102524234536642\n",
      "train loss:0.173849180970543\n",
      "train loss:0.1089254631712809\n",
      "train loss:0.12856520595595547\n",
      "train loss:0.2533994054599232\n",
      "train loss:0.07484316146848945\n",
      "train loss:0.13654465763206813\n",
      "train loss:0.07618564813076328\n",
      "train loss:0.12595586458978464\n",
      "train loss:0.13842428589520725\n",
      "train loss:0.18665350891837698\n",
      "train loss:0.09140642832319296\n",
      "train loss:0.10568809917098522\n",
      "train loss:0.12393014180351032\n",
      "train loss:0.06921052787504924\n",
      "train loss:0.0629106566457073\n",
      "train loss:0.2109580739658473\n",
      "train loss:0.14046125339855645\n",
      "train loss:0.08183912627527075\n",
      "train loss:0.11386791678644118\n",
      "train loss:0.07519151081616368\n",
      "train loss:0.11072003590836448\n",
      "train loss:0.12303431480809884\n",
      "train loss:0.06025150042593139\n",
      "train loss:0.21395533744683382\n",
      "train loss:0.1330868411174156\n",
      "train loss:0.2722137903399806\n",
      "=== epoch:2, train acc:0.941, test acc:0.95 ===\n",
      "train loss:0.12580885156753194\n",
      "train loss:0.1825916668117256\n",
      "train loss:0.26875725744539913\n",
      "train loss:0.08711946878338592\n",
      "train loss:0.23443915347198352\n",
      "train loss:0.17399633058815836\n",
      "train loss:0.06062787699707731\n",
      "train loss:0.17798512729408286\n",
      "train loss:0.22625756281849604\n",
      "train loss:0.1752341386372741\n",
      "train loss:0.16142849638564674\n",
      "train loss:0.13934375876939212\n",
      "train loss:0.30981988532963856\n",
      "train loss:0.07049640703741411\n",
      "train loss:0.2544603147572452\n",
      "train loss:0.0993341810931088\n",
      "train loss:0.16536574048416575\n",
      "train loss:0.17377941488032791\n",
      "train loss:0.1968900794149066\n",
      "train loss:0.1979294590788701\n",
      "train loss:0.10888805142815987\n",
      "train loss:0.17028955212001073\n",
      "train loss:0.1646969693329045\n",
      "train loss:0.07539393170158216\n",
      "train loss:0.12616321745571002\n",
      "train loss:0.10263154305750208\n",
      "train loss:0.21535859853739875\n",
      "train loss:0.20791109375205108\n",
      "train loss:0.09275890914236032\n",
      "train loss:0.15751473247988726\n",
      "train loss:0.28717612473702453\n",
      "train loss:0.11089033388498962\n",
      "train loss:0.0427262323838745\n",
      "train loss:0.08627732795045284\n",
      "train loss:0.23464609377797213\n",
      "train loss:0.1079345614572266\n",
      "train loss:0.14366487376694892\n",
      "train loss:0.11696455988435606\n",
      "train loss:0.12040801552718904\n",
      "train loss:0.1966863566755267\n",
      "train loss:0.07004058591345395\n",
      "train loss:0.13641688745524658\n",
      "train loss:0.17241170502296008\n",
      "train loss:0.1324479056639892\n",
      "train loss:0.11902055483381054\n",
      "train loss:0.1261289090043359\n",
      "train loss:0.07982533474629236\n",
      "train loss:0.1090299898133173\n",
      "train loss:0.2075245036335943\n",
      "train loss:0.14777747931759413\n",
      "train loss:0.18301602437775577\n",
      "train loss:0.11779438780011466\n",
      "train loss:0.08120012092664833\n",
      "train loss:0.14726299151093142\n",
      "train loss:0.1591924244288466\n",
      "train loss:0.1362760349070853\n",
      "train loss:0.04430578106619104\n",
      "train loss:0.1372346124662181\n",
      "train loss:0.17957395454680164\n",
      "train loss:0.2670607402348588\n",
      "train loss:0.13138986267260938\n",
      "train loss:0.20328049138417145\n",
      "train loss:0.16380265603522054\n",
      "train loss:0.1025943507105806\n",
      "train loss:0.10873125732297853\n",
      "train loss:0.14442879648036888\n",
      "train loss:0.2554575724571796\n",
      "train loss:0.16373188897462118\n",
      "train loss:0.07550177374454145\n",
      "train loss:0.06545318628419022\n",
      "train loss:0.1468613978532643\n",
      "train loss:0.08104748831863122\n",
      "train loss:0.0951082429465809\n",
      "train loss:0.11710717051364633\n",
      "train loss:0.2663987145589082\n",
      "train loss:0.10072272501824249\n",
      "train loss:0.2971894447180154\n",
      "train loss:0.28718060246751803\n",
      "train loss:0.24549916944468234\n",
      "train loss:0.09001796150773801\n",
      "train loss:0.11226826725825723\n",
      "train loss:0.2402505939966089\n",
      "train loss:0.08217049173146135\n",
      "train loss:0.20365786985158724\n",
      "train loss:0.12487348241752715\n",
      "train loss:0.13483704415024816\n",
      "train loss:0.06795682088187281\n",
      "train loss:0.15826459409428348\n",
      "train loss:0.14466064002666743\n",
      "train loss:0.1597434377119542\n",
      "train loss:0.16144419458440237\n",
      "train loss:0.2142862646621923\n",
      "train loss:0.15549116989799405\n",
      "train loss:0.13901574416746393\n",
      "train loss:0.0923106795581721\n",
      "train loss:0.148054328523071\n",
      "train loss:0.10247655438568014\n",
      "train loss:0.09186310227360414\n",
      "train loss:0.061993138831503876\n",
      "train loss:0.07905715123038912\n",
      "train loss:0.10765134467125557\n",
      "train loss:0.24161701808796351\n",
      "train loss:0.05848693226166254\n",
      "train loss:0.1514285778116535\n",
      "train loss:0.13758618061918937\n",
      "train loss:0.09727324216792933\n",
      "train loss:0.1078297907222427\n",
      "train loss:0.2321098109751389\n",
      "train loss:0.11759971510248396\n",
      "train loss:0.09515519878489309\n",
      "train loss:0.11881204147463845\n",
      "train loss:0.18614849012157753\n",
      "train loss:0.20249800828448844\n",
      "train loss:0.10591805596646435\n",
      "train loss:0.1639953855967383\n",
      "train loss:0.0727200120467135\n",
      "train loss:0.12245055215868275\n",
      "train loss:0.16888604562543602\n",
      "train loss:0.12825685792415112\n",
      "train loss:0.10598448181165838\n",
      "train loss:0.18124778864779806\n",
      "train loss:0.13182461467377218\n",
      "train loss:0.18987174363373122\n",
      "train loss:0.15045260613069092\n",
      "train loss:0.14772152707711964\n",
      "train loss:0.20538271465535396\n",
      "train loss:0.13714445629786093\n",
      "train loss:0.1192161846360664\n",
      "train loss:0.06061488674325088\n",
      "train loss:0.09523568673222876\n",
      "train loss:0.14316063701954027\n",
      "train loss:0.13205623457586219\n",
      "train loss:0.07389325951326392\n",
      "train loss:0.051693722013674136\n",
      "train loss:0.07479897402184749\n",
      "train loss:0.1068263523712452\n",
      "train loss:0.11473503550659281\n",
      "train loss:0.12218801187355355\n",
      "train loss:0.1665874620561934\n",
      "train loss:0.062366277047568204\n",
      "train loss:0.11146671313289282\n",
      "train loss:0.07337922995283573\n",
      "train loss:0.10501909667930366\n",
      "train loss:0.11464954881454799\n",
      "train loss:0.10395585334196075\n",
      "train loss:0.0816626115945951\n",
      "train loss:0.116260020075394\n",
      "train loss:0.07807434203382119\n",
      "train loss:0.0982760453421662\n",
      "train loss:0.05336050020187351\n",
      "train loss:0.0813059901990722\n",
      "train loss:0.07765523759951412\n",
      "train loss:0.062380995474976934\n",
      "train loss:0.08614284664792496\n",
      "train loss:0.1304147757291336\n",
      "train loss:0.060907287224649005\n",
      "train loss:0.09719367392323561\n",
      "train loss:0.16220681769959427\n",
      "train loss:0.06925168039439637\n",
      "train loss:0.0925213598054186\n",
      "train loss:0.07102617247941147\n",
      "train loss:0.15288306496599147\n",
      "train loss:0.0627316627850813\n",
      "train loss:0.05931505324083207\n",
      "train loss:0.1353336900683548\n",
      "train loss:0.07725572970288837\n",
      "train loss:0.07236606229179937\n",
      "train loss:0.059218281723917264\n",
      "train loss:0.14324615784392267\n",
      "train loss:0.04561162557474522\n",
      "train loss:0.06727696482584782\n",
      "train loss:0.14197036799878998\n",
      "train loss:0.24011797704317342\n",
      "train loss:0.03855359210940736\n",
      "train loss:0.115935292842601\n",
      "train loss:0.07124843339272491\n",
      "train loss:0.11167895723904779\n",
      "train loss:0.07950935581041019\n",
      "train loss:0.11116868485540078\n",
      "train loss:0.1355964108832877\n",
      "train loss:0.0744339332231583\n",
      "train loss:0.15342591109338882\n",
      "train loss:0.11437529870558755\n",
      "train loss:0.07777707105484705\n",
      "train loss:0.1595873127835675\n",
      "train loss:0.12581547237044577\n",
      "train loss:0.049479087948662875\n",
      "train loss:0.18407072739648844\n",
      "train loss:0.048710265189642665\n",
      "train loss:0.16451228844700908\n",
      "train loss:0.12419743207016369\n",
      "train loss:0.0570767856799705\n",
      "train loss:0.16467269679784102\n",
      "train loss:0.12226625490832904\n",
      "train loss:0.1151429952670799\n",
      "train loss:0.1299921877291213\n",
      "train loss:0.11105652166352079\n",
      "train loss:0.1346725275665067\n",
      "train loss:0.08216460077811752\n",
      "train loss:0.09863620001136633\n",
      "train loss:0.1593837298242356\n",
      "train loss:0.10440623303016594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07161281053104213\n",
      "train loss:0.09781888115758526\n",
      "train loss:0.15628678493505574\n",
      "train loss:0.12919406942800218\n",
      "train loss:0.05898546890029495\n",
      "train loss:0.17527428861811908\n",
      "train loss:0.10336700022203338\n",
      "train loss:0.10393147238948015\n",
      "train loss:0.12772266938482157\n",
      "train loss:0.07664144249830102\n",
      "train loss:0.10280311802896065\n",
      "train loss:0.24172364530896842\n",
      "train loss:0.07226783356682369\n",
      "train loss:0.07777152417590724\n",
      "train loss:0.09108406912562268\n",
      "train loss:0.1809761483774961\n",
      "train loss:0.17885624279802928\n",
      "train loss:0.11842766538573983\n",
      "train loss:0.17273808496232376\n",
      "train loss:0.06761560693001688\n",
      "train loss:0.10801578047446114\n",
      "train loss:0.09344202902258149\n",
      "train loss:0.1338894678344843\n",
      "train loss:0.1544959410988396\n",
      "train loss:0.15565426866688076\n",
      "train loss:0.11233239211806412\n",
      "train loss:0.16255682638646668\n",
      "train loss:0.09728202488028803\n",
      "train loss:0.08790301327015747\n",
      "train loss:0.10964404344637453\n",
      "train loss:0.18719765292049903\n",
      "train loss:0.1017030969030897\n",
      "train loss:0.19198419711445272\n",
      "train loss:0.22221733163224378\n",
      "train loss:0.1412260385711809\n",
      "train loss:0.10299475245434524\n",
      "train loss:0.14549551119951923\n",
      "train loss:0.10676333936305779\n",
      "train loss:0.1540498223351239\n",
      "train loss:0.07070544596217371\n",
      "train loss:0.06097493065365266\n",
      "train loss:0.06239500548033848\n",
      "train loss:0.09105614080353706\n",
      "train loss:0.0802674889656133\n",
      "train loss:0.08741476629090737\n",
      "train loss:0.06447275063159288\n",
      "train loss:0.08218585169884113\n",
      "train loss:0.10905410382250588\n",
      "train loss:0.05784334485643201\n",
      "train loss:0.15980439541750438\n",
      "train loss:0.1342185383301406\n",
      "train loss:0.15707955984241118\n",
      "train loss:0.14492076315310473\n",
      "train loss:0.1108603404450021\n",
      "train loss:0.14849694322017112\n",
      "train loss:0.05901400801436871\n",
      "train loss:0.08093394663940405\n",
      "train loss:0.09690395093281562\n",
      "train loss:0.06744498791151173\n",
      "train loss:0.1409610296470816\n",
      "train loss:0.11758298912822558\n",
      "train loss:0.06709256766305426\n",
      "train loss:0.19470054467585796\n",
      "train loss:0.1170321904429038\n",
      "train loss:0.20639174554601022\n",
      "train loss:0.1032099600025375\n",
      "train loss:0.0700912703826115\n",
      "train loss:0.07360176848056434\n",
      "train loss:0.13154001700760065\n",
      "train loss:0.13599248067739464\n",
      "train loss:0.1752845981593342\n",
      "train loss:0.16638953051770555\n",
      "train loss:0.05663504690775135\n",
      "train loss:0.09302596505496201\n",
      "train loss:0.14409470747300104\n",
      "train loss:0.04998630994561425\n",
      "train loss:0.10914380219787351\n",
      "train loss:0.05560210890532985\n",
      "train loss:0.11087878374940856\n",
      "train loss:0.10334888059586583\n",
      "train loss:0.05076305640352549\n",
      "train loss:0.09558895204882417\n",
      "train loss:0.1583329486046999\n",
      "train loss:0.13469076805770108\n",
      "train loss:0.06770798890877675\n",
      "train loss:0.11390069918469395\n",
      "train loss:0.0815321510973544\n",
      "train loss:0.11532404367499902\n",
      "train loss:0.04874372847509685\n",
      "train loss:0.056853377082753474\n",
      "train loss:0.12810847895702626\n",
      "train loss:0.04438529041099083\n",
      "train loss:0.11849894737183066\n",
      "train loss:0.08283999191409913\n",
      "train loss:0.0332980279651927\n",
      "train loss:0.10687958144545495\n",
      "train loss:0.05255476473648829\n",
      "train loss:0.09054211388169957\n",
      "train loss:0.13243763849458473\n",
      "train loss:0.0954795019246125\n",
      "train loss:0.08491421270452562\n",
      "train loss:0.11479132067653394\n",
      "train loss:0.07024090498616398\n",
      "train loss:0.07079125566192845\n",
      "train loss:0.12249922616226361\n",
      "train loss:0.056297958135200464\n",
      "train loss:0.06360954259870172\n",
      "train loss:0.07255321666051583\n",
      "train loss:0.06215948093548886\n",
      "train loss:0.13774911081492935\n",
      "train loss:0.05276399815174137\n",
      "train loss:0.10993683931405342\n",
      "train loss:0.14732298590205004\n",
      "train loss:0.09603718402909074\n",
      "train loss:0.08956440585222498\n",
      "train loss:0.13999685252580918\n",
      "train loss:0.08400148842101876\n",
      "train loss:0.10538708070436133\n",
      "train loss:0.06979664516042952\n",
      "train loss:0.18537083230074264\n",
      "train loss:0.08867220235416419\n",
      "train loss:0.08559270100773203\n",
      "train loss:0.10401694425562372\n",
      "train loss:0.029695996319216905\n",
      "train loss:0.09867883741127632\n",
      "train loss:0.11477122058497262\n",
      "train loss:0.0601586431643066\n",
      "train loss:0.0948793531215799\n",
      "train loss:0.16353259166699985\n",
      "train loss:0.11928425847282159\n",
      "train loss:0.045026208417477225\n",
      "train loss:0.09018381353475856\n",
      "train loss:0.10447411776011538\n",
      "train loss:0.19528211818126118\n",
      "train loss:0.0630342429757849\n",
      "train loss:0.05622305322893974\n",
      "train loss:0.11433178697632985\n",
      "train loss:0.06588329083541235\n",
      "train loss:0.04046638330018148\n",
      "train loss:0.06734737653286199\n",
      "train loss:0.14003254021522527\n",
      "train loss:0.16199715729825795\n",
      "train loss:0.03489827865610404\n",
      "train loss:0.1375066282417839\n",
      "train loss:0.11796483683048146\n",
      "train loss:0.050139844258704235\n",
      "train loss:0.12133243532901879\n",
      "train loss:0.11769595846501786\n",
      "train loss:0.05878210850636073\n",
      "train loss:0.11111248977643182\n",
      "train loss:0.16584822794230597\n",
      "train loss:0.11655398547067629\n",
      "train loss:0.09759796344832779\n",
      "train loss:0.14495575220670417\n",
      "train loss:0.0973757507895262\n",
      "train loss:0.08284091534981963\n",
      "train loss:0.06273059941012199\n",
      "train loss:0.054212810587837695\n",
      "train loss:0.06122723827611067\n",
      "train loss:0.06326568087936518\n",
      "train loss:0.07706356568034675\n",
      "train loss:0.1204588261309253\n",
      "train loss:0.07900137268444304\n",
      "train loss:0.07924146342773661\n",
      "train loss:0.047089787452166465\n",
      "train loss:0.022903700580662326\n",
      "train loss:0.07996534212604124\n",
      "train loss:0.0642854588470482\n",
      "train loss:0.03130260654435888\n",
      "train loss:0.1571519296567256\n",
      "train loss:0.20546090433649147\n",
      "train loss:0.07629691107275696\n",
      "train loss:0.13428565292244987\n",
      "train loss:0.12891984582120677\n",
      "train loss:0.11253014937182121\n",
      "train loss:0.1447904198868439\n",
      "train loss:0.106279759682643\n",
      "train loss:0.08233470786850097\n",
      "train loss:0.13332605551583565\n",
      "train loss:0.09108570246180246\n",
      "train loss:0.08388762949681977\n",
      "train loss:0.1272866635676737\n",
      "train loss:0.13014327403677084\n",
      "train loss:0.11067787167014444\n",
      "train loss:0.13937335504594575\n",
      "train loss:0.10694503049055532\n",
      "train loss:0.16735179383571236\n",
      "train loss:0.05215387386961523\n",
      "train loss:0.04238867827889506\n",
      "train loss:0.11211150954579162\n",
      "train loss:0.0641947384450299\n",
      "train loss:0.09090173354155968\n",
      "train loss:0.16755578872651922\n",
      "train loss:0.08129274787468299\n",
      "train loss:0.07477669721764392\n",
      "train loss:0.03534418561224534\n",
      "train loss:0.07923754816461616\n",
      "train loss:0.1167160959646637\n",
      "train loss:0.023614086699814435\n",
      "train loss:0.0706767106916707\n",
      "train loss:0.1870723578768143\n",
      "train loss:0.10314644002003197\n",
      "train loss:0.05381995285279651\n",
      "train loss:0.16620541373546133\n",
      "train loss:0.12017756281950928\n",
      "train loss:0.10401642553152345\n",
      "train loss:0.1187257792705279\n",
      "train loss:0.04148061582661189\n",
      "train loss:0.04157150168684242\n",
      "train loss:0.05781730012767622\n",
      "train loss:0.19657258055065774\n",
      "train loss:0.08060727180797693\n",
      "train loss:0.037035514754929624\n",
      "train loss:0.06879618784735406\n",
      "train loss:0.11665549423704999\n",
      "train loss:0.13992904528161912\n",
      "train loss:0.0706251523476816\n",
      "train loss:0.07423608461124268\n",
      "train loss:0.07072764850764306\n",
      "train loss:0.10591703644309586\n",
      "train loss:0.044041913077004405\n",
      "train loss:0.08537176768070953\n",
      "train loss:0.14111404764013036\n",
      "train loss:0.17307183414734922\n",
      "train loss:0.05622837105220884\n",
      "train loss:0.07611526189393894\n",
      "train loss:0.06902177206029818\n",
      "train loss:0.10372944760815976\n",
      "train loss:0.07253747322098088\n",
      "train loss:0.20818101534900932\n",
      "train loss:0.05211026358805612\n",
      "train loss:0.05854708449643234\n",
      "train loss:0.04867115944774552\n",
      "train loss:0.09679042119103412\n",
      "train loss:0.06665129747107175\n",
      "train loss:0.02537925140957781\n",
      "train loss:0.04533104452436202\n",
      "train loss:0.05951619082760447\n",
      "train loss:0.04545423104547111\n",
      "train loss:0.08009497258459387\n",
      "train loss:0.08419797055564279\n",
      "train loss:0.023425174468339055\n",
      "train loss:0.0856570548624918\n",
      "train loss:0.1323739092249354\n",
      "train loss:0.06258646049756031\n",
      "train loss:0.050392600113130286\n",
      "train loss:0.022760053974894178\n",
      "train loss:0.08220984918629949\n",
      "train loss:0.1094416096434964\n",
      "train loss:0.2170591435747825\n",
      "train loss:0.045017220445810156\n",
      "train loss:0.0667473243606672\n",
      "train loss:0.084470671529606\n",
      "train loss:0.05572441859655666\n",
      "train loss:0.03303313654036641\n",
      "train loss:0.1464863031675441\n",
      "train loss:0.06858371482915626\n",
      "train loss:0.013923275728702248\n",
      "train loss:0.06094659323135519\n",
      "train loss:0.09841352193821237\n",
      "train loss:0.09258113557118387\n",
      "train loss:0.08745486764879896\n",
      "train loss:0.08651972140148097\n",
      "train loss:0.18767091995436602\n",
      "train loss:0.0266930926324016\n",
      "train loss:0.08853434578255122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07450065978822255\n",
      "train loss:0.043524274493729954\n",
      "train loss:0.035477760047197576\n",
      "train loss:0.06763234479701519\n",
      "train loss:0.03284047008170321\n",
      "train loss:0.09508351420386417\n",
      "train loss:0.10374441629448741\n",
      "train loss:0.05380861801099192\n",
      "train loss:0.0961919956410482\n",
      "train loss:0.0911734173353369\n",
      "train loss:0.04114851610974798\n",
      "train loss:0.04990559961480339\n",
      "train loss:0.05890058202209045\n",
      "train loss:0.0680889603966964\n",
      "train loss:0.09783887694955283\n",
      "train loss:0.10735596533123996\n",
      "train loss:0.046293564537870854\n",
      "train loss:0.06906533892013322\n",
      "train loss:0.13612544404665944\n",
      "train loss:0.05567186045032451\n",
      "train loss:0.0399570117291905\n",
      "train loss:0.011431861915002409\n",
      "train loss:0.07917107161190334\n",
      "train loss:0.11047063299569818\n",
      "train loss:0.1441320724641461\n",
      "train loss:0.12408418380994457\n",
      "train loss:0.09084549688763198\n",
      "train loss:0.030950872643529168\n",
      "train loss:0.057504138969016266\n",
      "train loss:0.019666420640414614\n",
      "train loss:0.21007351211154543\n",
      "train loss:0.0583201162280148\n",
      "train loss:0.0791351982502358\n",
      "train loss:0.07083250866453113\n",
      "train loss:0.031805913503738174\n",
      "train loss:0.11328209441239587\n",
      "train loss:0.03304590446594495\n",
      "train loss:0.02600080187714442\n",
      "train loss:0.05818508226579546\n",
      "train loss:0.06103824612003843\n",
      "train loss:0.06709078640026787\n",
      "train loss:0.11434436933293618\n",
      "train loss:0.10056361552800767\n",
      "train loss:0.07617242978651621\n",
      "train loss:0.13823566455132233\n",
      "train loss:0.06491109609221776\n",
      "train loss:0.04450520550569863\n",
      "train loss:0.05101776663981465\n",
      "train loss:0.040904167574610864\n",
      "train loss:0.0565933043079244\n",
      "train loss:0.04834718760131639\n",
      "train loss:0.02982604515757159\n",
      "train loss:0.08734737174504174\n",
      "train loss:0.03458859666821407\n",
      "train loss:0.05686325583556398\n",
      "train loss:0.029640727482806693\n",
      "train loss:0.05377726366448516\n",
      "train loss:0.03486598470308446\n",
      "train loss:0.059224013778474485\n",
      "train loss:0.15561426526932284\n",
      "train loss:0.07473071833651647\n",
      "train loss:0.039940903788085215\n",
      "train loss:0.08322342076919263\n",
      "train loss:0.12153815737898549\n",
      "train loss:0.08366108356341025\n",
      "train loss:0.0308329358206897\n",
      "train loss:0.026602328131403067\n",
      "train loss:0.043463742564489705\n",
      "train loss:0.0952829835396011\n",
      "train loss:0.11473105305541742\n",
      "train loss:0.055486723317844745\n",
      "train loss:0.04035957700037095\n",
      "train loss:0.13766622399583142\n",
      "train loss:0.04259954855208318\n",
      "train loss:0.031862124184686105\n",
      "train loss:0.0959343197327148\n",
      "train loss:0.016672179897018222\n",
      "train loss:0.24505987349431302\n",
      "train loss:0.05423878722872232\n",
      "train loss:0.05864176484474574\n",
      "train loss:0.08303303250006408\n",
      "train loss:0.08955765464467498\n",
      "train loss:0.07988949252315516\n",
      "train loss:0.022246981356609075\n",
      "train loss:0.03282696938320708\n",
      "train loss:0.02585092619743683\n",
      "train loss:0.012658550673328842\n",
      "train loss:0.054618271345995596\n",
      "train loss:0.07720680216003552\n",
      "train loss:0.07915624056983078\n",
      "train loss:0.06705770447586211\n",
      "train loss:0.07662764605227344\n",
      "train loss:0.023339588563980485\n",
      "train loss:0.04601734615690182\n",
      "train loss:0.16827965852177187\n",
      "train loss:0.0343871624907335\n",
      "train loss:0.06876838051830438\n",
      "train loss:0.03590491914384268\n",
      "train loss:0.09574735515246494\n",
      "train loss:0.04022926834397049\n",
      "train loss:0.1269438944597878\n",
      "train loss:0.06027849420276026\n",
      "train loss:0.06747654328010873\n",
      "train loss:0.060432676251182364\n",
      "train loss:0.07857976608960886\n",
      "train loss:0.07836353832481088\n",
      "train loss:0.060441986576893515\n",
      "train loss:0.08710111280592388\n",
      "train loss:0.04527498169549485\n",
      "train loss:0.06198224565543133\n",
      "train loss:0.09436687337432252\n",
      "train loss:0.04890115993242708\n",
      "train loss:0.16588643277395893\n",
      "train loss:0.038750779699551076\n",
      "train loss:0.1122387115766086\n",
      "train loss:0.030477077467359233\n",
      "train loss:0.05396856247871001\n",
      "train loss:0.034218720946624974\n",
      "train loss:0.10363197114165867\n",
      "train loss:0.07152483702303969\n",
      "train loss:0.0972143079103171\n",
      "train loss:0.06711233848320289\n",
      "train loss:0.06572006666816432\n",
      "train loss:0.05393066259550922\n",
      "train loss:0.10053421426813866\n",
      "train loss:0.12120593704591842\n",
      "train loss:0.05144192530504136\n",
      "train loss:0.07436767177486615\n",
      "train loss:0.05441462109505214\n",
      "train loss:0.07515177976881636\n",
      "train loss:0.10874833156024216\n",
      "train loss:0.08116080981459609\n",
      "=== epoch:3, train acc:0.972, test acc:0.973 ===\n",
      "train loss:0.04901547229713648\n",
      "train loss:0.11827663074980851\n",
      "train loss:0.04099143032262547\n",
      "train loss:0.036784780626127674\n",
      "train loss:0.024239646974575126\n",
      "train loss:0.009108763270588648\n",
      "train loss:0.07518583162455107\n",
      "train loss:0.06949801721535592\n",
      "train loss:0.10673212113960036\n",
      "train loss:0.1134703047251762\n",
      "train loss:0.04399090971651922\n",
      "train loss:0.12079336898523949\n",
      "train loss:0.03790778780655211\n",
      "train loss:0.10427615804052986\n",
      "train loss:0.1177123719660242\n",
      "train loss:0.06999455246304441\n",
      "train loss:0.03993611656314191\n",
      "train loss:0.1352641762452984\n",
      "train loss:0.05706260822462572\n",
      "train loss:0.17182215738116594\n",
      "train loss:0.053898235043912175\n",
      "train loss:0.09900944266364119\n",
      "train loss:0.07592468189562734\n",
      "train loss:0.048523359296065854\n",
      "train loss:0.10892975489597098\n",
      "train loss:0.02826079873556531\n",
      "train loss:0.07845881432636538\n",
      "train loss:0.028801998759800936\n",
      "train loss:0.05081821393824125\n",
      "train loss:0.049838614953908615\n",
      "train loss:0.05456995733498416\n",
      "train loss:0.16052929268332344\n",
      "train loss:0.07967664229374981\n",
      "train loss:0.09525502226157101\n",
      "train loss:0.018990651774087673\n",
      "train loss:0.06992046347333175\n",
      "train loss:0.1174651894672649\n",
      "train loss:0.04167534023546116\n",
      "train loss:0.021198330538962144\n",
      "train loss:0.07630077922175761\n",
      "train loss:0.02233590160020278\n",
      "train loss:0.09418840738813289\n",
      "train loss:0.044092186328374146\n",
      "train loss:0.051982242343456636\n",
      "train loss:0.21507561167467848\n",
      "train loss:0.06606898915130417\n",
      "train loss:0.06389444067756428\n",
      "train loss:0.03842488075605124\n",
      "train loss:0.08397231319792331\n",
      "train loss:0.06335157454172201\n",
      "train loss:0.046297070506433974\n",
      "train loss:0.06109075057109937\n",
      "train loss:0.07871880474216042\n",
      "train loss:0.09392049663469684\n",
      "train loss:0.04794337830647063\n",
      "train loss:0.10016290878746982\n",
      "train loss:0.025974944435016446\n",
      "train loss:0.05273094798229889\n",
      "train loss:0.12196418861393904\n",
      "train loss:0.11758170211258415\n",
      "train loss:0.05385655011089291\n",
      "train loss:0.032026113679438126\n",
      "train loss:0.1483818443241598\n",
      "train loss:0.08229072162711232\n",
      "train loss:0.09720556064780778\n",
      "train loss:0.025950911903883423\n",
      "train loss:0.06994971374338244\n",
      "train loss:0.022826485612514765\n",
      "train loss:0.06997766319299258\n",
      "train loss:0.0891928889107002\n",
      "train loss:0.051554224999315924\n",
      "train loss:0.1139459869420662\n",
      "train loss:0.03237634910841845\n",
      "train loss:0.04365382863200756\n",
      "train loss:0.008657206551087078\n",
      "train loss:0.05211499231859003\n",
      "train loss:0.08756671227929878\n",
      "train loss:0.08239139047142459\n",
      "train loss:0.016641464741047288\n",
      "train loss:0.017575462686143028\n",
      "train loss:0.026795027603053564\n",
      "train loss:0.09208396747474432\n",
      "train loss:0.06374484231069849\n",
      "train loss:0.07494187208555\n",
      "train loss:0.08731323338029963\n",
      "train loss:0.06030551407901686\n",
      "train loss:0.08711377953778916\n",
      "train loss:0.05775475346552348\n",
      "train loss:0.10580354579965229\n",
      "train loss:0.04730324397687185\n",
      "train loss:0.046204820331829294\n",
      "train loss:0.10435737521442981\n",
      "train loss:0.07997756642208585\n",
      "train loss:0.09208692967246829\n",
      "train loss:0.035426171083650294\n",
      "train loss:0.11274221905097068\n",
      "train loss:0.026448952375995757\n",
      "train loss:0.02112412892706053\n",
      "train loss:0.08888110820665698\n",
      "train loss:0.02252524180826549\n",
      "train loss:0.03647259978535602\n",
      "train loss:0.11332380845492311\n",
      "train loss:0.052690505175301265\n",
      "train loss:0.0231837044751775\n",
      "train loss:0.061434535920097046\n",
      "train loss:0.0967327009568314\n",
      "train loss:0.04882858738744643\n",
      "train loss:0.0739271978245771\n",
      "train loss:0.020581706607519065\n",
      "train loss:0.061025217134080025\n",
      "train loss:0.013983104970952419\n",
      "train loss:0.03486035432097524\n",
      "train loss:0.03999233308906213\n",
      "train loss:0.05391128531222805\n",
      "train loss:0.11044520395173521\n",
      "train loss:0.026116429630586354\n",
      "train loss:0.04695310395833643\n",
      "train loss:0.02504484390334219\n",
      "train loss:0.06481665023452247\n",
      "train loss:0.08693570791792583\n",
      "train loss:0.04152060286136216\n",
      "train loss:0.06254439435216742\n",
      "train loss:0.08198916215569688\n",
      "train loss:0.05354782121140539\n",
      "train loss:0.043064197174484474\n",
      "train loss:0.03592127486148308\n",
      "train loss:0.16103948475898722\n",
      "train loss:0.06691616064557745\n",
      "train loss:0.06031747744153824\n",
      "train loss:0.025919323359692097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.034955959689938504\n",
      "train loss:0.12995053845552185\n",
      "train loss:0.1343442322127417\n",
      "train loss:0.09065934804543574\n",
      "train loss:0.037647109040538335\n",
      "train loss:0.05728921085857913\n",
      "train loss:0.023521269005018944\n",
      "train loss:0.08132487455491855\n",
      "train loss:0.056474283733987864\n",
      "train loss:0.08629643444639118\n",
      "train loss:0.1235344914892711\n",
      "train loss:0.09473932867064376\n",
      "train loss:0.11750354495337609\n",
      "train loss:0.1104959162329243\n",
      "train loss:0.055134696086127505\n",
      "train loss:0.06073376869129198\n",
      "train loss:0.09081643097580909\n",
      "train loss:0.113748612372065\n",
      "train loss:0.11318935562341811\n",
      "train loss:0.03243845787928303\n",
      "train loss:0.040607096076337716\n",
      "train loss:0.06796263195535873\n",
      "train loss:0.07340832242370085\n",
      "train loss:0.08346091862697723\n",
      "train loss:0.1015412480312074\n",
      "train loss:0.07005412178023472\n",
      "train loss:0.02135728555241559\n",
      "train loss:0.06691358587124893\n",
      "train loss:0.06252385561101775\n",
      "train loss:0.021054624910258286\n",
      "train loss:0.04085202440102483\n",
      "train loss:0.09741856288708572\n",
      "train loss:0.057619186236172196\n",
      "train loss:0.06973664856588836\n",
      "train loss:0.02278023333411034\n",
      "train loss:0.022353430160170055\n",
      "train loss:0.07399046451573459\n",
      "train loss:0.08582895573465706\n",
      "train loss:0.03745442677742867\n",
      "train loss:0.03770770803179704\n",
      "train loss:0.03411258174139358\n",
      "train loss:0.03622339318880691\n",
      "train loss:0.02733711094490527\n",
      "train loss:0.027916736759419077\n",
      "train loss:0.06055837253538055\n",
      "train loss:0.0809219984109061\n",
      "train loss:0.10892372636777903\n",
      "train loss:0.05110057393306449\n",
      "train loss:0.1298521458246281\n",
      "train loss:0.054484399722573344\n",
      "train loss:0.022426698384467775\n",
      "train loss:0.06303314431142484\n",
      "train loss:0.08003016171458815\n",
      "train loss:0.09115056202529649\n",
      "train loss:0.02933382531036664\n",
      "train loss:0.032973247465928064\n",
      "train loss:0.04874248971997818\n",
      "train loss:0.089522414079255\n",
      "train loss:0.020947210190239787\n",
      "train loss:0.04694983082198448\n",
      "train loss:0.12805167988181854\n",
      "train loss:0.13327866496184987\n",
      "train loss:0.06795416561735981\n",
      "train loss:0.04306191626414171\n",
      "train loss:0.028544434929892133\n",
      "train loss:0.062258431765087614\n",
      "train loss:0.05624193228076299\n",
      "train loss:0.05517593832657553\n",
      "train loss:0.02888698882048334\n",
      "train loss:0.029135181496417858\n",
      "train loss:0.012172589813686751\n",
      "train loss:0.027607695660308615\n",
      "train loss:0.07172692269929795\n",
      "train loss:0.0410057032586525\n",
      "train loss:0.10631541069601144\n",
      "train loss:0.054338308573334916\n",
      "train loss:0.04188232356071866\n",
      "train loss:0.03821787064667377\n",
      "train loss:0.029976059806729044\n",
      "train loss:0.057074243247532463\n",
      "train loss:0.00613681260385341\n",
      "train loss:0.06394543299398758\n",
      "train loss:0.05112779652523715\n",
      "train loss:0.04773798608995095\n",
      "train loss:0.04278634863648326\n",
      "train loss:0.04032935080684296\n",
      "train loss:0.06953285327803944\n",
      "train loss:0.07925428696858984\n",
      "train loss:0.024245066637559386\n",
      "train loss:0.05235061627576477\n",
      "train loss:0.037152842569087165\n",
      "train loss:0.05038680333477611\n",
      "train loss:0.014781646216416424\n",
      "train loss:0.04111621788691751\n",
      "train loss:0.045573440910440445\n",
      "train loss:0.02561818404022163\n",
      "train loss:0.03952311206768914\n",
      "train loss:0.20667762007852494\n",
      "train loss:0.12728793972666858\n",
      "train loss:0.0873813363665665\n",
      "train loss:0.04824221819794179\n",
      "train loss:0.04836978626510341\n",
      "train loss:0.02568054519587987\n",
      "train loss:0.026182999145125573\n",
      "train loss:0.08553508210684942\n",
      "train loss:0.06934242764320434\n",
      "train loss:0.08076190396136822\n",
      "train loss:0.10882005760998079\n",
      "train loss:0.02136493165727755\n",
      "train loss:0.06230976729050743\n",
      "train loss:0.040088759349840825\n",
      "train loss:0.08872617722466897\n",
      "train loss:0.033695743537626374\n",
      "train loss:0.040482248528074284\n",
      "train loss:0.07612237159407896\n",
      "train loss:0.06134367806527375\n",
      "train loss:0.09203820338688166\n",
      "train loss:0.025847037635553353\n",
      "train loss:0.052346880450473234\n",
      "train loss:0.02960062678087245\n",
      "train loss:0.07905487968240503\n",
      "train loss:0.10078255456351631\n",
      "train loss:0.0324139614511902\n",
      "train loss:0.0708662348016363\n",
      "train loss:0.03358833505814304\n",
      "train loss:0.022447146197569146\n",
      "train loss:0.04050583101226734\n",
      "train loss:0.04394495680597745\n",
      "train loss:0.03414604229169307\n",
      "train loss:0.05800064636038066\n",
      "train loss:0.03706115884866492\n",
      "train loss:0.01976832696602338\n",
      "train loss:0.051438050333500476\n",
      "train loss:0.0457367390134493\n",
      "train loss:0.07787830347275976\n",
      "train loss:0.08272649835378904\n",
      "train loss:0.12604507554712002\n",
      "train loss:0.03602297006989631\n",
      "train loss:0.10040158261332202\n",
      "train loss:0.0336323932156537\n",
      "train loss:0.03260746850409698\n",
      "train loss:0.10747111013901575\n",
      "train loss:0.047483412527173086\n",
      "train loss:0.12057714476382511\n",
      "train loss:0.276244915263044\n",
      "train loss:0.037150299384881076\n",
      "train loss:0.05809383223640819\n",
      "train loss:0.043061544516061624\n",
      "train loss:0.012255444926536208\n",
      "train loss:0.06322426070816539\n",
      "train loss:0.043992112902026134\n",
      "train loss:0.05119229942211761\n",
      "train loss:0.06671625460102425\n",
      "train loss:0.04447457443177296\n",
      "train loss:0.03738677308164874\n",
      "train loss:0.08016546598591096\n",
      "train loss:0.02921985757278596\n",
      "train loss:0.043317214847692166\n",
      "train loss:0.05160433487846817\n",
      "train loss:0.07688167361455932\n",
      "train loss:0.00888460122002199\n",
      "train loss:0.12067062170631736\n",
      "train loss:0.06149476759336988\n",
      "train loss:0.05745192139888204\n",
      "train loss:0.04279712783889674\n",
      "train loss:0.0303608363525887\n",
      "train loss:0.09420548175903161\n",
      "train loss:0.01978535883904006\n",
      "train loss:0.06396248029358498\n",
      "train loss:0.06339933265967279\n",
      "train loss:0.03440237730466783\n",
      "train loss:0.0762429080481168\n",
      "train loss:0.03420794779814702\n",
      "train loss:0.03431939244393159\n",
      "train loss:0.0466939939629114\n",
      "train loss:0.033732280763658376\n",
      "train loss:0.04171266505194225\n",
      "train loss:0.04493657087330091\n",
      "train loss:0.018748461222201765\n",
      "train loss:0.06510643150122959\n",
      "train loss:0.06787030192776912\n",
      "train loss:0.01762439057082248\n",
      "train loss:0.04892832199931608\n",
      "train loss:0.03149280275315248\n",
      "train loss:0.0883285365821998\n",
      "train loss:0.05607818556205971\n",
      "train loss:0.032777178273523895\n",
      "train loss:0.06391362113591198\n",
      "train loss:0.019707886634528847\n",
      "train loss:0.05911289192760379\n",
      "train loss:0.15513351166707812\n",
      "train loss:0.04175604173959673\n",
      "train loss:0.03969573600628268\n",
      "train loss:0.08017686150201979\n",
      "train loss:0.05789591544041226\n",
      "train loss:0.044353255803796815\n",
      "train loss:0.04214441781669145\n",
      "train loss:0.05576176846584335\n",
      "train loss:0.021737402913544406\n",
      "train loss:0.04607135315700421\n",
      "train loss:0.04982955202124163\n",
      "train loss:0.03961495895764759\n",
      "train loss:0.0788350412448826\n",
      "train loss:0.07985384513543473\n",
      "train loss:0.07750014305357478\n",
      "train loss:0.059808413790846754\n",
      "train loss:0.12455491920534262\n",
      "train loss:0.026867123301299298\n",
      "train loss:0.06290094674813253\n",
      "train loss:0.06564877627725975\n",
      "train loss:0.08459171863102588\n",
      "train loss:0.14305601958618352\n",
      "train loss:0.08536026429579487\n",
      "train loss:0.04684056021400775\n",
      "train loss:0.01687320676454581\n",
      "train loss:0.056895446845411514\n",
      "train loss:0.03754325976583874\n",
      "train loss:0.13802588066013508\n",
      "train loss:0.10779783452818643\n",
      "train loss:0.06695751236609046\n",
      "train loss:0.04588699171480116\n",
      "train loss:0.05621179601791915\n",
      "train loss:0.05468706543495535\n",
      "train loss:0.027857727630142985\n",
      "train loss:0.16406311488297265\n",
      "train loss:0.07074702383500255\n",
      "train loss:0.019902638900462635\n",
      "train loss:0.049989740684565055\n",
      "train loss:0.04823873189347839\n",
      "train loss:0.07968313525168094\n",
      "train loss:0.0794295560902065\n",
      "train loss:0.10834443005268782\n",
      "train loss:0.14133497611776039\n",
      "train loss:0.01752098562121627\n",
      "train loss:0.030824196895414744\n",
      "train loss:0.07969879105884166\n",
      "train loss:0.033892349998019884\n",
      "train loss:0.04277262866492815\n",
      "train loss:0.09864767904642713\n",
      "train loss:0.07199400813161996\n",
      "train loss:0.01963328034972702\n",
      "train loss:0.02853250809432941\n",
      "train loss:0.04867157970104344\n",
      "train loss:0.07762856579460962\n",
      "train loss:0.1028916023444707\n",
      "train loss:0.14439528433687362\n",
      "train loss:0.092310217714332\n",
      "train loss:0.06402990698994637\n",
      "train loss:0.04027134110909104\n",
      "train loss:0.022805080884868073\n",
      "train loss:0.032658072322020365\n",
      "train loss:0.07854968084446662\n",
      "train loss:0.057654391035207385\n",
      "train loss:0.13148141383315204\n",
      "train loss:0.021853325051959926\n",
      "train loss:0.056216838301156334\n",
      "train loss:0.02997915121806467\n",
      "train loss:0.052805205979734336\n",
      "train loss:0.043178389220846276\n",
      "train loss:0.06416260564780502\n",
      "train loss:0.016675351520601935\n",
      "train loss:0.07142893342362261\n",
      "train loss:0.06789842096153709\n",
      "train loss:0.017470637130602838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05744910224814518\n",
      "train loss:0.039934553467432535\n",
      "train loss:0.06332254474033341\n",
      "train loss:0.0801194707528161\n",
      "train loss:0.034650936998780975\n",
      "train loss:0.08619861946008714\n",
      "train loss:0.1064724177395673\n",
      "train loss:0.03347772839860843\n",
      "train loss:0.05071750765433256\n",
      "train loss:0.0567470511144649\n",
      "train loss:0.05209722962349668\n",
      "train loss:0.03597478291346214\n",
      "train loss:0.15058327342240838\n",
      "train loss:0.02846728950882825\n",
      "train loss:0.04014084978621382\n",
      "train loss:0.03268094895975926\n",
      "train loss:0.02905920346325241\n",
      "train loss:0.05054477890388667\n",
      "train loss:0.018491747313749547\n",
      "train loss:0.020754138474838486\n",
      "train loss:0.025626100295063493\n",
      "train loss:0.019921620487145752\n",
      "train loss:0.03655981601000306\n",
      "train loss:0.114025128037993\n",
      "train loss:0.07092207878736552\n",
      "train loss:0.025207580591395825\n",
      "train loss:0.03576939549812873\n",
      "train loss:0.06414385368131746\n",
      "train loss:0.025407892307748252\n",
      "train loss:0.09606016015272059\n",
      "train loss:0.04980895921806109\n",
      "train loss:0.0953530965198601\n",
      "train loss:0.046384768789032825\n",
      "train loss:0.0308901353141681\n",
      "train loss:0.04891781237959618\n",
      "train loss:0.08768034973434549\n",
      "train loss:0.04598831180313173\n",
      "train loss:0.061032584828823434\n",
      "train loss:0.0426857711265511\n",
      "train loss:0.0652325230371677\n",
      "train loss:0.047642330820252134\n",
      "train loss:0.023379643602692922\n",
      "train loss:0.15759979810087163\n",
      "train loss:0.035333423069476934\n",
      "train loss:0.06239120127423532\n",
      "train loss:0.0726216432779806\n",
      "train loss:0.030180376196027044\n",
      "train loss:0.06009153386515277\n",
      "train loss:0.06872638102345124\n",
      "train loss:0.030889186554166916\n",
      "train loss:0.038195189820200724\n",
      "train loss:0.04077291207518763\n",
      "train loss:0.016510084501515216\n",
      "train loss:0.013665829724915009\n",
      "train loss:0.01840420904952541\n",
      "train loss:0.03013935241401883\n",
      "train loss:0.0745387920784909\n",
      "train loss:0.019849911484752025\n",
      "train loss:0.021228437570504344\n",
      "train loss:0.03802834320280917\n",
      "train loss:0.11592362991565537\n",
      "train loss:0.05747631110782451\n",
      "train loss:0.09328974580062477\n",
      "train loss:0.06737683257458917\n",
      "train loss:0.09440702627336403\n",
      "train loss:0.009893978268540172\n",
      "train loss:0.018822289755803794\n",
      "train loss:0.047757987847644824\n",
      "train loss:0.05855948779097948\n",
      "train loss:0.09906792718023541\n",
      "train loss:0.048578763666903335\n",
      "train loss:0.07550560171582288\n",
      "train loss:0.06381011228614776\n",
      "train loss:0.01841197661026356\n",
      "train loss:0.04367520858402037\n",
      "train loss:0.07792912979897229\n",
      "train loss:0.052401530978082846\n",
      "train loss:0.0494668906809145\n",
      "train loss:0.03908840748352786\n",
      "train loss:0.034112100112257474\n",
      "train loss:0.046380840796163676\n",
      "train loss:0.015686141280163223\n",
      "train loss:0.006864581394869345\n",
      "train loss:0.039835785820001364\n",
      "train loss:0.13465679014646936\n",
      "train loss:0.08111258418239725\n",
      "train loss:0.04891823014970229\n",
      "train loss:0.10476089506037894\n",
      "train loss:0.11824431562727915\n",
      "train loss:0.07845503233338084\n",
      "train loss:0.08585870950461676\n",
      "train loss:0.036373965309977975\n",
      "train loss:0.08090774219562329\n",
      "train loss:0.02907140495193187\n",
      "train loss:0.01979358811201693\n",
      "train loss:0.04409167385364912\n",
      "train loss:0.07482933223495171\n",
      "train loss:0.046459661733117656\n",
      "train loss:0.09028441303035391\n",
      "train loss:0.038171945867023716\n",
      "train loss:0.026531879828853903\n",
      "train loss:0.02825663823382023\n",
      "train loss:0.0711644381902295\n",
      "train loss:0.029265976805085313\n",
      "train loss:0.07347888162927343\n",
      "train loss:0.10631759256961816\n",
      "train loss:0.07782649455400076\n",
      "train loss:0.09761359159655499\n",
      "train loss:0.030629839514390085\n",
      "train loss:0.038129355025109\n",
      "train loss:0.012981621286396051\n",
      "train loss:0.05559310374753237\n",
      "train loss:0.023637765745945342\n",
      "train loss:0.08460526372125032\n",
      "train loss:0.0623317432287072\n",
      "train loss:0.039701261943904574\n",
      "train loss:0.040631169728912314\n",
      "train loss:0.07478812665194161\n",
      "train loss:0.04381772517169437\n",
      "train loss:0.06108480656522567\n",
      "train loss:0.052433995941965586\n",
      "train loss:0.05654642673674034\n",
      "train loss:0.020532492640049384\n",
      "train loss:0.03495585989676707\n",
      "train loss:0.029972396029582384\n",
      "train loss:0.033110756595325114\n",
      "train loss:0.02502907618285359\n",
      "train loss:0.05068129631995277\n",
      "train loss:0.0929584463349706\n",
      "train loss:0.03941924678002846\n",
      "train loss:0.05640160621094623\n",
      "train loss:0.07180358940843137\n",
      "train loss:0.026795982726214973\n",
      "train loss:0.02882546007459884\n",
      "train loss:0.012808153428834457\n",
      "train loss:0.05839723770725751\n",
      "train loss:0.09854885218352141\n",
      "train loss:0.022032814586851822\n",
      "train loss:0.008373090100076093\n",
      "train loss:0.028416376418336022\n",
      "train loss:0.028263934034023254\n",
      "train loss:0.011489971508682709\n",
      "train loss:0.027852132192231614\n",
      "train loss:0.028663944194414395\n",
      "train loss:0.10769584241824948\n",
      "train loss:0.07426752732455616\n",
      "train loss:0.039712168112072524\n",
      "train loss:0.06355026905512333\n",
      "train loss:0.03359903861590423\n",
      "train loss:0.029266457231552315\n",
      "train loss:0.1533236847382381\n",
      "train loss:0.07179493253398253\n",
      "train loss:0.06657131226388817\n",
      "train loss:0.026800726502377536\n",
      "train loss:0.04035406840448995\n",
      "train loss:0.024651533542468972\n",
      "train loss:0.007718489124267487\n",
      "train loss:0.046740269450349696\n",
      "train loss:0.03964871994618378\n",
      "train loss:0.06620483615446132\n",
      "train loss:0.02534750999876868\n",
      "train loss:0.03566775844484467\n",
      "train loss:0.02281797217230525\n",
      "train loss:0.029961326243129506\n",
      "train loss:0.010536607558811329\n",
      "train loss:0.10172168666101411\n",
      "train loss:0.012187785986385933\n",
      "train loss:0.09739587078115317\n",
      "train loss:0.03587640618726134\n",
      "train loss:0.09302275617490252\n",
      "train loss:0.019797534237352955\n",
      "train loss:0.026379400974602035\n",
      "train loss:0.05912514371800433\n",
      "train loss:0.06846351055815275\n",
      "train loss:0.01558673577370949\n",
      "train loss:0.032373809305349\n",
      "train loss:0.03671855749673475\n",
      "train loss:0.01980982514737097\n",
      "train loss:0.02245096844005834\n",
      "train loss:0.03380562868583157\n",
      "train loss:0.042708395127579825\n",
      "train loss:0.0944934292225712\n",
      "train loss:0.013162435559313878\n",
      "train loss:0.06491287537792634\n",
      "train loss:0.03407354276494004\n",
      "train loss:0.058691646757743826\n",
      "train loss:0.028032514473553687\n",
      "train loss:0.0522355498004511\n",
      "train loss:0.07796796461280973\n",
      "train loss:0.0866907977787857\n",
      "train loss:0.11737358378981398\n",
      "train loss:0.04199003513880771\n",
      "train loss:0.062272873320443435\n",
      "train loss:0.0241072924351275\n",
      "train loss:0.0291920205039643\n",
      "train loss:0.042160990715111986\n",
      "train loss:0.04755551198563263\n",
      "train loss:0.1476848977517256\n",
      "train loss:0.050411120261242254\n",
      "train loss:0.03732094080803361\n",
      "train loss:0.061267681928677514\n",
      "train loss:0.039204395218705466\n",
      "train loss:0.024133116415764194\n",
      "train loss:0.04279387152434136\n",
      "train loss:0.02050963689473332\n",
      "train loss:0.021263353652813115\n",
      "=== epoch:4, train acc:0.986, test acc:0.979 ===\n",
      "train loss:0.1296452580304838\n",
      "train loss:0.024795863922176968\n",
      "train loss:0.016480600425267018\n",
      "train loss:0.018431013649499055\n",
      "train loss:0.014366673830208511\n",
      "train loss:0.049359332398490496\n",
      "train loss:0.04147202866391139\n",
      "train loss:0.028010256398332573\n",
      "train loss:0.03127967240709271\n",
      "train loss:0.018440542821455404\n",
      "train loss:0.05300777476660837\n",
      "train loss:0.05600044534359329\n",
      "train loss:0.12150150034454071\n",
      "train loss:0.0036623986065489004\n",
      "train loss:0.03810038008218568\n",
      "train loss:0.10658923305362517\n",
      "train loss:0.08381993579194776\n",
      "train loss:0.07037454296570031\n",
      "train loss:0.038735010709415145\n",
      "train loss:0.01886606843301183\n",
      "train loss:0.10006268805735262\n",
      "train loss:0.0668543107237483\n",
      "train loss:0.09943822218444963\n",
      "train loss:0.014300596773627544\n",
      "train loss:0.016544971021190635\n",
      "train loss:0.09892170963978603\n",
      "train loss:0.015918543311924188\n",
      "train loss:0.053812685741009635\n",
      "train loss:0.09427481133426063\n",
      "train loss:0.05967466370641014\n",
      "train loss:0.06856493567363493\n",
      "train loss:0.029836546410760407\n",
      "train loss:0.010848596947715268\n",
      "train loss:0.06126279103871237\n",
      "train loss:0.09499208101389771\n",
      "train loss:0.02783562001791641\n",
      "train loss:0.07934937657159136\n",
      "train loss:0.013207436340654126\n",
      "train loss:0.04046095837549088\n",
      "train loss:0.024213551087501627\n",
      "train loss:0.04348925082890194\n",
      "train loss:0.05044600621773022\n",
      "train loss:0.01833283620786997\n",
      "train loss:0.03324104706827549\n",
      "train loss:0.02873536585955099\n",
      "train loss:0.12592192155590548\n",
      "train loss:0.07654301145385246\n",
      "train loss:0.0168515584965772\n",
      "train loss:0.03829140069403121\n",
      "train loss:0.02191652103310296\n",
      "train loss:0.0380917603107577\n",
      "train loss:0.026932292803489383\n",
      "train loss:0.05212624855182422\n",
      "train loss:0.013639487280394168\n",
      "train loss:0.0478228196983595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03392418650991886\n",
      "train loss:0.03232975390453764\n",
      "train loss:0.06172426470802025\n",
      "train loss:0.13706033323630942\n",
      "train loss:0.0966297786777597\n",
      "train loss:0.041046379156986834\n",
      "train loss:0.024203680013567846\n",
      "train loss:0.02547617745196743\n",
      "train loss:0.016970932337747963\n",
      "train loss:0.027341254323572695\n",
      "train loss:0.029258582469514353\n",
      "train loss:0.03235206185224343\n",
      "train loss:0.08762428506519747\n",
      "train loss:0.07590732971439076\n",
      "train loss:0.03808336561174817\n",
      "train loss:0.044702102951580856\n",
      "train loss:0.053950407242996504\n",
      "train loss:0.005251756944894619\n",
      "train loss:0.028097296779565895\n",
      "train loss:0.01699605277335512\n",
      "train loss:0.049324832880190336\n",
      "train loss:0.037649568409307735\n",
      "train loss:0.050461283452226884\n",
      "train loss:0.08974161431725448\n",
      "train loss:0.02443144845539616\n",
      "train loss:0.024080983519864464\n",
      "train loss:0.025322336035885854\n",
      "train loss:0.033800866891192695\n",
      "train loss:0.032133818650486395\n",
      "train loss:0.035777917345090136\n",
      "train loss:0.04354330426957267\n",
      "train loss:0.10567567759903772\n",
      "train loss:0.01661545434759728\n",
      "train loss:0.024115297620943735\n",
      "train loss:0.048485227693734645\n",
      "train loss:0.04735418616948392\n",
      "train loss:0.07471500095322754\n",
      "train loss:0.05951013611909506\n",
      "train loss:0.04471504952786822\n",
      "train loss:0.055366447034354636\n",
      "train loss:0.051963881060105674\n",
      "train loss:0.04489819376714546\n",
      "train loss:0.010502182110814029\n",
      "train loss:0.03354222747675307\n",
      "train loss:0.029443699669867422\n",
      "train loss:0.06055249829220781\n",
      "train loss:0.02202169820505018\n",
      "train loss:0.08275784500568972\n",
      "train loss:0.07752049763807063\n",
      "train loss:0.022106723823537292\n",
      "train loss:0.009836792984230265\n",
      "train loss:0.025317788472272923\n",
      "train loss:0.04154427447710141\n",
      "train loss:0.039765779645375886\n",
      "train loss:0.056499588328039516\n",
      "train loss:0.04431248549966718\n",
      "train loss:0.017729254507745106\n",
      "train loss:0.03945143490156083\n",
      "train loss:0.04300450385625117\n",
      "train loss:0.027108547588602382\n",
      "train loss:0.047428796269083584\n",
      "train loss:0.04092662970135787\n",
      "train loss:0.026884910359218184\n",
      "train loss:0.03637617998346801\n",
      "train loss:0.0910170524532446\n",
      "train loss:0.03437098162331321\n",
      "train loss:0.06971041805333099\n",
      "train loss:0.03522325353129799\n",
      "train loss:0.03719653771674736\n",
      "train loss:0.02801123917793537\n",
      "train loss:0.045590887251010986\n",
      "train loss:0.049433555488802995\n",
      "train loss:0.04504669380209265\n",
      "train loss:0.03931504088870537\n",
      "train loss:0.03570202212975418\n",
      "train loss:0.04630118107199345\n",
      "train loss:0.016459193638219106\n",
      "train loss:0.039184193956909835\n",
      "train loss:0.03252622808756676\n",
      "train loss:0.0058506577316187105\n",
      "train loss:0.08783030562402519\n",
      "train loss:0.01322527102330097\n",
      "train loss:0.031500239324381715\n",
      "train loss:0.01581725606930485\n",
      "train loss:0.053731529333655006\n",
      "train loss:0.031579872586737584\n",
      "train loss:0.0475549894454074\n",
      "train loss:0.05836244642237868\n",
      "train loss:0.03686393150627873\n",
      "train loss:0.060566091528054325\n",
      "train loss:0.016680338656955344\n",
      "train loss:0.01175641411838273\n",
      "train loss:0.0436330491823558\n",
      "train loss:0.010796593857589918\n",
      "train loss:0.07705783648107535\n",
      "train loss:0.05267423012490173\n",
      "train loss:0.03575128820332445\n",
      "train loss:0.01713057732550274\n",
      "train loss:0.05123642903080758\n",
      "train loss:0.01747265349375783\n",
      "train loss:0.02392939691994506\n",
      "train loss:0.040538172185804563\n",
      "train loss:0.017438254089865723\n",
      "train loss:0.03978874379871205\n",
      "train loss:0.030942223956641524\n",
      "train loss:0.030086831648567455\n",
      "train loss:0.02198418118735341\n",
      "train loss:0.018673804599180648\n",
      "train loss:0.015724219677574064\n",
      "train loss:0.07809448586239479\n",
      "train loss:0.015826317170898586\n",
      "train loss:0.0787850895925763\n",
      "train loss:0.0484390276437128\n",
      "train loss:0.036857680681321274\n",
      "train loss:0.04042859154543366\n",
      "train loss:0.05290402604038186\n",
      "train loss:0.07899157402643879\n",
      "train loss:0.07358277668970598\n",
      "train loss:0.07319786617301997\n",
      "train loss:0.05669077235229028\n",
      "train loss:0.014997801423340604\n",
      "train loss:0.020005181634189437\n",
      "train loss:0.018107620333108435\n",
      "train loss:0.09364686725765176\n",
      "train loss:0.019921281023785188\n",
      "train loss:0.04188922749711424\n",
      "train loss:0.048407772925111336\n",
      "train loss:0.0452809682842253\n",
      "train loss:0.0691101736179977\n",
      "train loss:0.10712853044985522\n",
      "train loss:0.1406853490784783\n",
      "train loss:0.015341221364419138\n",
      "train loss:0.01125803173496715\n",
      "train loss:0.026048470122253725\n",
      "train loss:0.040299486717097016\n",
      "train loss:0.062346399964483\n",
      "train loss:0.02162087250270829\n",
      "train loss:0.01612959974069539\n",
      "train loss:0.018440393177232377\n",
      "train loss:0.028376432277819635\n",
      "train loss:0.05523328100669391\n",
      "train loss:0.032588427601319324\n",
      "train loss:0.038653889011462404\n",
      "train loss:0.05219755479597426\n",
      "train loss:0.09042742094266265\n",
      "train loss:0.10020928208454626\n",
      "train loss:0.03673298860383287\n",
      "train loss:0.015582786222040687\n",
      "train loss:0.05143492592822904\n",
      "train loss:0.02150396847699574\n",
      "train loss:0.021936932547817325\n",
      "train loss:0.03232244104302606\n",
      "train loss:0.036997979629016894\n",
      "train loss:0.05035610618972436\n",
      "train loss:0.06891900246632328\n",
      "train loss:0.012322332556665736\n",
      "train loss:0.02442177378138899\n",
      "train loss:0.11402189450402749\n",
      "train loss:0.027545706446966096\n",
      "train loss:0.02634918134976007\n",
      "train loss:0.042805093258293\n",
      "train loss:0.01718937466777409\n",
      "train loss:0.08334274869675638\n",
      "train loss:0.036941902139537935\n",
      "train loss:0.030677152111893854\n",
      "train loss:0.07738424896332376\n",
      "train loss:0.03873001791392014\n",
      "train loss:0.05784162647724223\n",
      "train loss:0.060916227455234395\n",
      "train loss:0.025922250813155107\n",
      "train loss:0.0856883055068106\n",
      "train loss:0.17331345248986932\n",
      "train loss:0.08416382639880697\n",
      "train loss:0.02274714552424959\n",
      "train loss:0.03662344113080588\n",
      "train loss:0.023750321533978005\n",
      "train loss:0.0378658233330611\n",
      "train loss:0.03504986445443091\n",
      "train loss:0.06485750425032479\n",
      "train loss:0.04438275404588467\n",
      "train loss:0.015181488938837383\n",
      "train loss:0.031147149856643686\n",
      "train loss:0.011716828489757343\n",
      "train loss:0.04947938307607082\n",
      "train loss:0.022109760158092427\n",
      "train loss:0.03724865666323019\n",
      "train loss:0.021308307274365515\n",
      "train loss:0.06142194683138149\n",
      "train loss:0.024175237120022994\n",
      "train loss:0.023468281245634638\n",
      "train loss:0.02522935721586966\n",
      "train loss:0.03998992041823894\n",
      "train loss:0.06069729246757022\n",
      "train loss:0.0592627230929496\n",
      "train loss:0.013805773549333222\n",
      "train loss:0.09018142370218567\n",
      "train loss:0.047923399654652366\n",
      "train loss:0.03728990917788835\n",
      "train loss:0.10276280356362752\n",
      "train loss:0.021096254220340716\n",
      "train loss:0.03007539258190999\n",
      "train loss:0.028780305857251217\n",
      "train loss:0.04142336522702335\n",
      "train loss:0.014474328191120808\n",
      "train loss:0.04421221342167502\n",
      "train loss:0.014846709929916711\n",
      "train loss:0.022194373531407713\n",
      "train loss:0.019332779039706163\n",
      "train loss:0.033537252102993735\n",
      "train loss:0.06402534784116606\n",
      "train loss:0.019151620065796883\n",
      "train loss:0.013171700024530816\n",
      "train loss:0.1225801096207616\n",
      "train loss:0.0275383723475234\n",
      "train loss:0.0942977102528082\n",
      "train loss:0.00849158244214871\n",
      "train loss:0.11697160314766332\n",
      "train loss:0.0671927478119488\n",
      "train loss:0.04833691083943902\n",
      "train loss:0.05981085726979127\n",
      "train loss:0.0312879921904846\n",
      "train loss:0.07660864181560817\n",
      "train loss:0.053065007585102346\n",
      "train loss:0.019589260243693615\n",
      "train loss:0.042111876073140195\n",
      "train loss:0.04169183773805818\n",
      "train loss:0.01982502887382476\n",
      "train loss:0.01449657904608765\n",
      "train loss:0.019727156242222797\n",
      "train loss:0.02496600196275467\n",
      "train loss:0.0174782349331811\n",
      "train loss:0.07586640146281858\n",
      "train loss:0.04277877885768953\n",
      "train loss:0.0268847524205486\n",
      "train loss:0.0416138842945802\n",
      "train loss:0.022293061784242132\n",
      "train loss:0.04331826992124441\n",
      "train loss:0.030608306359803827\n",
      "train loss:0.011990508327794335\n",
      "train loss:0.021899887800878193\n",
      "train loss:0.010076132315069876\n",
      "train loss:0.0785036183261522\n",
      "train loss:0.0141230326517437\n",
      "train loss:0.03238834643086603\n",
      "train loss:0.025281460377426943\n",
      "train loss:0.010299089630612646\n",
      "train loss:0.04212580759057857\n",
      "train loss:0.014169634438893585\n",
      "train loss:0.025638460778224917\n",
      "train loss:0.024051174909944337\n",
      "train loss:0.014819950705148794\n",
      "train loss:0.04230388677480914\n",
      "train loss:0.016162090565929085\n",
      "train loss:0.009652320870461566\n",
      "train loss:0.030827771990282398\n",
      "train loss:0.02047517073428438\n",
      "train loss:0.054280132462312496\n",
      "train loss:0.043857103045564304\n",
      "train loss:0.06893420797969577\n",
      "train loss:0.12909478697496288\n",
      "train loss:0.027436003902544467\n",
      "train loss:0.033260730925459676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03897316558672472\n",
      "train loss:0.03852037858924745\n",
      "train loss:0.04319623322840609\n",
      "train loss:0.0961870386408156\n",
      "train loss:0.07770113239425135\n",
      "train loss:0.07054385414066078\n",
      "train loss:0.02072563429628143\n",
      "train loss:0.06518759783324633\n",
      "train loss:0.0911875425584692\n",
      "train loss:0.050234306364357446\n",
      "train loss:0.06844006596673925\n",
      "train loss:0.04181533894146124\n",
      "train loss:0.09109754300827819\n",
      "train loss:0.0443811300671028\n",
      "train loss:0.043647442741502236\n",
      "train loss:0.032410085958152625\n",
      "train loss:0.01189805369185015\n",
      "train loss:0.04309466376393096\n",
      "train loss:0.01736362588463108\n",
      "train loss:0.019424556330518705\n",
      "train loss:0.05556785825163766\n",
      "train loss:0.10296017117840897\n",
      "train loss:0.014119106805580308\n",
      "train loss:0.0514422593294043\n",
      "train loss:0.06362412604530626\n",
      "train loss:0.026672269931562687\n",
      "train loss:0.02997203882440223\n",
      "train loss:0.01901541100269203\n",
      "train loss:0.040910910226821195\n",
      "train loss:0.024514903118118832\n",
      "train loss:0.016878451358097995\n",
      "train loss:0.1322448991009499\n",
      "train loss:0.021749427927957393\n",
      "train loss:0.05663522207907905\n",
      "train loss:0.04016659744225087\n",
      "train loss:0.02883117313318738\n",
      "train loss:0.02527031139623464\n",
      "train loss:0.025035120219732258\n",
      "train loss:0.01565267214272588\n",
      "train loss:0.04480845535673059\n",
      "train loss:0.02720142340410108\n",
      "train loss:0.03657151891436407\n",
      "train loss:0.03962148160401666\n",
      "train loss:0.040507426143047746\n",
      "train loss:0.03907607065644575\n",
      "train loss:0.06360508474314773\n",
      "train loss:0.09169735199668567\n",
      "train loss:0.024319386032517033\n",
      "train loss:0.04920834620276587\n",
      "train loss:0.02052683824693489\n",
      "train loss:0.04074714442588609\n",
      "train loss:0.03921219789742221\n",
      "train loss:0.011432129182273303\n",
      "train loss:0.03167756531385199\n",
      "train loss:0.007667795694210227\n",
      "train loss:0.03752744516171566\n",
      "train loss:0.02186843225969032\n",
      "train loss:0.05274344761715232\n",
      "train loss:0.04657654904294589\n",
      "train loss:0.13024445685815758\n",
      "train loss:0.05301050441402264\n",
      "train loss:0.007791572631556124\n",
      "train loss:0.026767914556573104\n",
      "train loss:0.036681938206980125\n",
      "train loss:0.0342284865049115\n",
      "train loss:0.023360223778561194\n",
      "train loss:0.07680282503134155\n",
      "train loss:0.02814029113334972\n",
      "train loss:0.03168656507496087\n",
      "train loss:0.06358014097157798\n",
      "train loss:0.0034271699019124955\n",
      "train loss:0.06799765535340475\n",
      "train loss:0.02659631890120688\n",
      "train loss:0.09761809456459984\n",
      "train loss:0.013812170344439285\n",
      "train loss:0.058426386736253305\n",
      "train loss:0.005999310101391735\n",
      "train loss:0.016530980583703586\n",
      "train loss:0.00731248944221668\n",
      "train loss:0.01615659419568913\n",
      "train loss:0.03896571109089974\n",
      "train loss:0.08157803080738392\n",
      "train loss:0.03027483190697118\n",
      "train loss:0.12806296467135386\n",
      "train loss:0.020009038617572746\n",
      "train loss:0.035244638234930493\n",
      "train loss:0.0688921338978285\n",
      "train loss:0.0830860750966585\n",
      "train loss:0.021600350140164707\n",
      "train loss:0.019011989472217473\n",
      "train loss:0.04453527989878756\n",
      "train loss:0.022928528711666125\n",
      "train loss:0.009586999724131996\n",
      "train loss:0.018326751597213354\n",
      "train loss:0.01739952230743965\n",
      "train loss:0.014630340585551193\n",
      "train loss:0.030601648856323726\n",
      "train loss:0.15917299203484614\n",
      "train loss:0.01681020912562784\n",
      "train loss:0.0257191720616262\n",
      "train loss:0.03262341400839186\n",
      "train loss:0.03533431427885309\n",
      "train loss:0.03139037501947906\n",
      "train loss:0.011224875981246631\n",
      "train loss:0.0047879405561981215\n",
      "train loss:0.025532651688492117\n",
      "train loss:0.011474787985356536\n",
      "train loss:0.0042591722572366455\n",
      "train loss:0.08026756518986687\n",
      "train loss:0.013779283253744749\n",
      "train loss:0.030321377003942183\n",
      "train loss:0.027710968016316815\n",
      "train loss:0.047910481314402766\n",
      "train loss:0.007221892010142295\n",
      "train loss:0.03681164170334981\n",
      "train loss:0.03572368539630135\n",
      "train loss:0.017979816539116733\n",
      "train loss:0.02717635686794405\n",
      "train loss:0.00408307352132957\n",
      "train loss:0.01880839242906162\n",
      "train loss:0.035584640089234315\n",
      "train loss:0.042420660750373936\n",
      "train loss:0.06695948070038803\n",
      "train loss:0.025299784025970554\n",
      "train loss:0.01492882440645483\n",
      "train loss:0.04389183838296752\n",
      "train loss:0.023725889483640045\n",
      "train loss:0.022642183358099404\n",
      "train loss:0.07174413402248322\n",
      "train loss:0.036489091204993766\n",
      "train loss:0.044706555027183466\n",
      "train loss:0.02160511546057574\n",
      "train loss:0.010970073751442634\n",
      "train loss:0.008847876950203176\n",
      "train loss:0.039099121915446726\n",
      "train loss:0.03840045019231909\n",
      "train loss:0.052151798671065314\n",
      "train loss:0.014121230750939824\n",
      "train loss:0.02980477585250614\n",
      "train loss:0.09540708828975167\n",
      "train loss:0.03459816210078784\n",
      "train loss:0.022197494709321072\n",
      "train loss:0.013733944966047573\n",
      "train loss:0.08608152097430814\n",
      "train loss:0.015076092737289479\n",
      "train loss:0.03145209758252794\n",
      "train loss:0.1373023242816206\n",
      "train loss:0.027613131817711946\n",
      "train loss:0.011755282655433512\n",
      "train loss:0.018413610984405228\n",
      "train loss:0.020107830064968902\n",
      "train loss:0.08832721829292645\n",
      "train loss:0.042618527028164224\n",
      "train loss:0.022465242801610247\n",
      "train loss:0.02432384707881349\n",
      "train loss:0.0072075761991828345\n",
      "train loss:0.03446874736918753\n",
      "train loss:0.0272524992658342\n",
      "train loss:0.032656879597350176\n",
      "train loss:0.011713974097617066\n",
      "train loss:0.05296071737918037\n",
      "train loss:0.013476936907685986\n",
      "train loss:0.038524533360053466\n",
      "train loss:0.009650409832923739\n",
      "train loss:0.01050916072863894\n",
      "train loss:0.02524321022321961\n",
      "train loss:0.020673713623828888\n",
      "train loss:0.08181293658019854\n",
      "train loss:0.024874122296847486\n",
      "train loss:0.019564956950001586\n",
      "train loss:0.046228357889869204\n",
      "train loss:0.009898839960841415\n",
      "train loss:0.021685084251771423\n",
      "train loss:0.016673683077307665\n",
      "train loss:0.007083925455768335\n",
      "train loss:0.0268515762898202\n",
      "train loss:0.027784988019280282\n",
      "train loss:0.02570810529454554\n",
      "train loss:0.04680958823715029\n",
      "train loss:0.1335450260384721\n",
      "train loss:0.03501526558179712\n",
      "train loss:0.07259445684043846\n",
      "train loss:0.03310078212753819\n",
      "train loss:0.009452174481924126\n",
      "train loss:0.0407778634244893\n",
      "train loss:0.017022665841364398\n",
      "train loss:0.029483222778255942\n",
      "train loss:0.04614744289211985\n",
      "train loss:0.07800575860558942\n",
      "train loss:0.037169487397230846\n",
      "train loss:0.016778469431125168\n",
      "train loss:0.0851129836959062\n",
      "train loss:0.0836170958804814\n",
      "train loss:0.030045054155039157\n",
      "train loss:0.01217958399100435\n",
      "train loss:0.02508020340416036\n",
      "train loss:0.03527029149395665\n",
      "train loss:0.04056387477077903\n",
      "train loss:0.14803033841942012\n",
      "train loss:0.008552302459226484\n",
      "train loss:0.02028735641418665\n",
      "train loss:0.07004645828707638\n",
      "train loss:0.01823847913719982\n",
      "train loss:0.054416382281515956\n",
      "train loss:0.07171187421667066\n",
      "train loss:0.03686099591450716\n",
      "train loss:0.03008645054370734\n",
      "train loss:0.03887068279534194\n",
      "train loss:0.04101344508522854\n",
      "train loss:0.021393513540615007\n",
      "train loss:0.012216253227949492\n",
      "train loss:0.0651599754182205\n",
      "train loss:0.015962098028775264\n",
      "train loss:0.022768031357175547\n",
      "train loss:0.03931394515806998\n",
      "train loss:0.03887449578623954\n",
      "train loss:0.04799004698666496\n",
      "train loss:0.022771300860081178\n",
      "train loss:0.07990422623308696\n",
      "train loss:0.03743861754039836\n",
      "train loss:0.009410890630531079\n",
      "train loss:0.044475673521897345\n",
      "train loss:0.06178568994685163\n",
      "train loss:0.03152575545079234\n",
      "train loss:0.0670252783555097\n",
      "train loss:0.03105406774721439\n",
      "train loss:0.07895614917997479\n",
      "train loss:0.021280562750773297\n",
      "train loss:0.035914438957632154\n",
      "train loss:0.011245910303075568\n",
      "train loss:0.030808779214981423\n",
      "train loss:0.014927291261865228\n",
      "train loss:0.013757235349801649\n",
      "train loss:0.04859176828954797\n",
      "train loss:0.05192604955551422\n",
      "train loss:0.0538459095698283\n",
      "train loss:0.01135300512945069\n",
      "train loss:0.036631867443214255\n",
      "train loss:0.014809001346971109\n",
      "train loss:0.008582599803464354\n",
      "train loss:0.03858434021724614\n",
      "train loss:0.04107126657993056\n",
      "train loss:0.04618375044520687\n",
      "train loss:0.05146872833305543\n",
      "train loss:0.03754246862908586\n",
      "train loss:0.017197970165609627\n",
      "train loss:0.007584231909847963\n",
      "train loss:0.022293130949483323\n",
      "train loss:0.04267021994784661\n",
      "train loss:0.023626080985016885\n",
      "train loss:0.02824259236931085\n",
      "train loss:0.04438055414743543\n",
      "train loss:0.031810434585403155\n",
      "train loss:0.04027429073752289\n",
      "train loss:0.01887001042941493\n",
      "train loss:0.0167008448504771\n",
      "train loss:0.008377420709692985\n",
      "train loss:0.00918167659416921\n",
      "train loss:0.012770615882504223\n",
      "train loss:0.019522674713778665\n",
      "train loss:0.030355961521352715\n",
      "train loss:0.014060125472256595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08254920089603049\n",
      "train loss:0.04254457784945762\n",
      "train loss:0.029114974379479793\n",
      "train loss:0.008159005595434542\n",
      "train loss:0.0074854432452929505\n",
      "train loss:0.06194064534869752\n",
      "train loss:0.015497338946533337\n",
      "train loss:0.014461075899732518\n",
      "train loss:0.016361410195772103\n",
      "train loss:0.034516582512119434\n",
      "train loss:0.007278178669863893\n",
      "train loss:0.010104825548483944\n",
      "train loss:0.010835011737536662\n",
      "train loss:0.021257119215142242\n",
      "train loss:0.02505981470875356\n",
      "train loss:0.08282024856072483\n",
      "train loss:0.018634953939472575\n",
      "train loss:0.030340309174917895\n",
      "train loss:0.027327715806845503\n",
      "train loss:0.037348496514377896\n",
      "train loss:0.009482620486809666\n",
      "=== epoch:5, train acc:0.988, test acc:0.98 ===\n",
      "train loss:0.04992857205406387\n",
      "train loss:0.025703361427663666\n",
      "train loss:0.033934465369203276\n",
      "train loss:0.00789175942169779\n",
      "train loss:0.058583520928559486\n",
      "train loss:0.019603292788342188\n",
      "train loss:0.023889511799194928\n",
      "train loss:0.011335778470573437\n",
      "train loss:0.01141424289606784\n",
      "train loss:0.08089220718793129\n",
      "train loss:0.019515651287688243\n",
      "train loss:0.04031608028765105\n",
      "train loss:0.019869777812445266\n",
      "train loss:0.04071874442030017\n",
      "train loss:0.02567639525224235\n",
      "train loss:0.032135101883980006\n",
      "train loss:0.04558933005888394\n",
      "train loss:0.029548661260807373\n",
      "train loss:0.01479184067067685\n",
      "train loss:0.05906567993069769\n",
      "train loss:0.009246653599188158\n",
      "train loss:0.029187482956427528\n",
      "train loss:0.04126872207335599\n",
      "train loss:0.012450451590297132\n",
      "train loss:0.04197217318765769\n",
      "train loss:0.017218244845680485\n",
      "train loss:0.03460711767061743\n",
      "train loss:0.014134921318140621\n",
      "train loss:0.027665553074294462\n",
      "train loss:0.06711648842934628\n",
      "train loss:0.017477289090131305\n",
      "train loss:0.059756251339963325\n",
      "train loss:0.014155643059120409\n",
      "train loss:0.013934810368356136\n",
      "train loss:0.06452671147127076\n",
      "train loss:0.013679190997230837\n",
      "train loss:0.10062125103111282\n",
      "train loss:0.12850198553206454\n",
      "train loss:0.01821846569624692\n",
      "train loss:0.09241488830333623\n",
      "train loss:0.01859765524110866\n",
      "train loss:0.026340469562220258\n",
      "train loss:0.019248179991598283\n",
      "train loss:0.019911259222958194\n",
      "train loss:0.020499425564003387\n",
      "train loss:0.0101151568706795\n",
      "train loss:0.08629583531388951\n",
      "train loss:0.023781660586639827\n",
      "train loss:0.03581170564085679\n",
      "train loss:0.023525673344427372\n",
      "train loss:0.08738168956698152\n",
      "train loss:0.018585612067040982\n",
      "train loss:0.016662309622657714\n",
      "train loss:0.01328924450182415\n",
      "train loss:0.009968242383261152\n",
      "train loss:0.012620383490940253\n",
      "train loss:0.028571953135504122\n",
      "train loss:0.03396625264889598\n",
      "train loss:0.017522291247947002\n",
      "train loss:0.0034861456487727312\n",
      "train loss:0.05942858760620716\n",
      "train loss:0.024549332913479223\n",
      "train loss:0.0124386581535649\n",
      "train loss:0.042428886101781256\n",
      "train loss:0.027116506799992085\n",
      "train loss:0.04903905130835544\n",
      "train loss:0.025193029994590593\n",
      "train loss:0.01188145324130259\n",
      "train loss:0.004222219812725654\n",
      "train loss:0.007698106535160538\n",
      "train loss:0.032811142619963186\n",
      "train loss:0.06080761059057696\n",
      "train loss:0.04663120688968509\n",
      "train loss:0.045494579485940656\n",
      "train loss:0.036558279628196105\n",
      "train loss:0.015733879944375487\n",
      "train loss:0.04520117842752835\n",
      "train loss:0.01236171953931544\n",
      "train loss:0.031785552004300784\n",
      "train loss:0.005608029567564061\n",
      "train loss:0.010693862889929106\n",
      "train loss:0.026839807518416227\n",
      "train loss:0.015682627669063302\n",
      "train loss:0.0042021531830149705\n",
      "train loss:0.036866080891100175\n",
      "train loss:0.07691284528486224\n",
      "train loss:0.02182403709025365\n",
      "train loss:0.09486560518618298\n",
      "train loss:0.024759611988130162\n",
      "train loss:0.050273527582858454\n",
      "train loss:0.004590078210618476\n",
      "train loss:0.013246282925910546\n",
      "train loss:0.010598478625436576\n",
      "train loss:0.010767799410249503\n",
      "train loss:0.03996063703214519\n",
      "train loss:0.030635110948827114\n",
      "train loss:0.008187285618074986\n",
      "train loss:0.03223849611390075\n",
      "train loss:0.024849728338275826\n",
      "train loss:0.024692225429722253\n",
      "train loss:0.00587170514399577\n",
      "train loss:0.029645603265055626\n",
      "train loss:0.018168144396475797\n",
      "train loss:0.007348345274827592\n",
      "train loss:0.12382126692097613\n",
      "train loss:0.004789720291843575\n",
      "train loss:0.006672918896266763\n",
      "train loss:0.03377296294988808\n",
      "train loss:0.029064882003114727\n",
      "train loss:0.010429385579805084\n",
      "train loss:0.015046397160387076\n",
      "train loss:0.004029103315650525\n",
      "train loss:0.04680169877395003\n",
      "train loss:0.018332681489924913\n",
      "train loss:0.014060988266523317\n",
      "train loss:0.017804531752042864\n",
      "train loss:0.02175706070212876\n",
      "train loss:0.021421637249499484\n",
      "train loss:0.017256642336810936\n",
      "train loss:0.04039588707967454\n",
      "train loss:0.028790270089273647\n",
      "train loss:0.00832601637957506\n",
      "train loss:0.03236443667030962\n",
      "train loss:0.008639828013955153\n",
      "train loss:0.011964874971606407\n",
      "train loss:0.017986725452618507\n",
      "train loss:0.05873986126691009\n",
      "train loss:0.010062951660725832\n",
      "train loss:0.016163328229313545\n",
      "train loss:0.02232519517475084\n",
      "train loss:0.00719557760969576\n",
      "train loss:0.017578700089953943\n",
      "train loss:0.029417737359084567\n",
      "train loss:0.044662059261744824\n",
      "train loss:0.04135909434808715\n",
      "train loss:0.021144295008029213\n",
      "train loss:0.016113569478391623\n",
      "train loss:0.03376186422469399\n",
      "train loss:0.013907717412644398\n",
      "train loss:0.019891967931796765\n",
      "train loss:0.022154867980768694\n",
      "train loss:0.05027603042746548\n",
      "train loss:0.02551677846156783\n",
      "train loss:0.03544849303295658\n",
      "train loss:0.012932782607752795\n",
      "train loss:0.009740524031172017\n",
      "train loss:0.11461548044301706\n",
      "train loss:0.0014858561842415608\n",
      "train loss:0.027485886877425824\n",
      "train loss:0.01191354772626856\n",
      "train loss:0.019815929598306536\n",
      "train loss:0.01386419646819113\n",
      "train loss:0.010297218736071794\n",
      "train loss:0.04900966760903763\n",
      "train loss:0.0315624697677576\n",
      "train loss:0.03126049626110534\n",
      "train loss:0.009907869314219444\n",
      "train loss:0.009821558376565532\n",
      "train loss:0.010400170678392788\n",
      "train loss:0.00753435057759004\n",
      "train loss:0.15100286249609707\n",
      "train loss:0.0702843432789956\n",
      "train loss:0.017333789492580017\n",
      "train loss:0.006113374544426909\n",
      "train loss:0.014504565178028651\n",
      "train loss:0.035478262870391006\n",
      "train loss:0.0140942104809889\n",
      "train loss:0.0292293731726843\n",
      "train loss:0.03420671545181356\n",
      "train loss:0.011707905089619972\n",
      "train loss:0.016012607031042958\n",
      "train loss:0.03647924965796221\n",
      "train loss:0.053617534879802496\n",
      "train loss:0.039433768913765405\n",
      "train loss:0.014618026060792336\n",
      "train loss:0.017974645334523236\n",
      "train loss:0.02205984910109905\n",
      "train loss:0.009922927737817312\n",
      "train loss:0.05103578675820215\n",
      "train loss:0.05840394253515261\n",
      "train loss:0.018879618589081947\n",
      "train loss:0.02668954591911726\n",
      "train loss:0.03568962266773949\n",
      "train loss:0.023868957617326172\n",
      "train loss:0.03459606209724684\n",
      "train loss:0.028595556753813714\n",
      "train loss:0.03419327920422131\n",
      "train loss:0.013595147248494319\n",
      "train loss:0.11548464954420934\n",
      "train loss:0.016944896425887493\n",
      "train loss:0.05025416251200141\n",
      "train loss:0.016406849869137242\n",
      "train loss:0.013501984361495618\n",
      "train loss:0.008464712401456508\n",
      "train loss:0.008114569023099597\n",
      "train loss:0.01377571065505627\n",
      "train loss:0.01912261893200686\n",
      "train loss:0.006874536619666336\n",
      "train loss:0.0063156476923654555\n",
      "train loss:0.009601036404968361\n",
      "train loss:0.022676871575217056\n",
      "train loss:0.009084887155437576\n",
      "train loss:0.028331645463737593\n",
      "train loss:0.030399462070134393\n",
      "train loss:0.031805016911555\n",
      "train loss:0.011106812189754022\n",
      "train loss:0.02116716584001342\n",
      "train loss:0.004910280334282619\n",
      "train loss:0.03003369068435567\n",
      "train loss:0.04213458398471501\n",
      "train loss:0.0037496714602438773\n",
      "train loss:0.011969376729851615\n",
      "train loss:0.022483597770448262\n",
      "train loss:0.03564346118446342\n",
      "train loss:0.03241938123094001\n",
      "train loss:0.00496026551212574\n",
      "train loss:0.00540100215663687\n",
      "train loss:0.016500328710467478\n",
      "train loss:0.015023130533991912\n",
      "train loss:0.003912369818621093\n",
      "train loss:0.04795608882984844\n",
      "train loss:0.006958529801404296\n",
      "train loss:0.03234681305187678\n",
      "train loss:0.17029710197702067\n",
      "train loss:0.08654928915861941\n",
      "train loss:0.009905318513440543\n",
      "train loss:0.013651227885564648\n",
      "train loss:0.03196548809730476\n",
      "train loss:0.010255072225642554\n",
      "train loss:0.04237063969316532\n",
      "train loss:0.012778929629620673\n",
      "train loss:0.03617937667226394\n",
      "train loss:0.0422504066937005\n",
      "train loss:0.011329773220389066\n",
      "train loss:0.009431346772525552\n",
      "train loss:0.018380743439776574\n",
      "train loss:0.03734074382288874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006047484059036027\n",
      "train loss:0.007835239430118567\n",
      "train loss:0.0257471958669736\n",
      "train loss:0.015922770122043885\n",
      "train loss:0.01472922240939353\n",
      "train loss:0.02147935865208651\n",
      "train loss:0.0069453521944912895\n",
      "train loss:0.0760659170094021\n",
      "train loss:0.022726751873543945\n",
      "train loss:0.01170989912371135\n",
      "train loss:0.016595968648364975\n",
      "train loss:0.007448665964023607\n",
      "train loss:0.011335619706048601\n",
      "train loss:0.04623019036974876\n",
      "train loss:0.042215059564338187\n",
      "train loss:0.023166068926006096\n",
      "train loss:0.05691518723293151\n",
      "train loss:0.060166643079172265\n",
      "train loss:0.023934921772902067\n",
      "train loss:0.022355516353626648\n",
      "train loss:0.012658804598304894\n",
      "train loss:0.016323979425990984\n",
      "train loss:0.0529552553640332\n",
      "train loss:0.05940631149944298\n",
      "train loss:0.04396301865992286\n",
      "train loss:0.039236325240141506\n",
      "train loss:0.013956015614806376\n",
      "train loss:0.013427152026075553\n",
      "train loss:0.07404877012398031\n",
      "train loss:0.05051846434312006\n",
      "train loss:0.006457522726200501\n",
      "train loss:0.010473138135344905\n",
      "train loss:0.017302533155496534\n",
      "train loss:0.0442781617503235\n",
      "train loss:0.012093892167234572\n",
      "train loss:0.025474742329201886\n",
      "train loss:0.04570526294883763\n",
      "train loss:0.03522091335812554\n",
      "train loss:0.03159837664464336\n",
      "train loss:0.006869667223064891\n",
      "train loss:0.015642619094742127\n",
      "train loss:0.03974509192029117\n",
      "train loss:0.013240632665372627\n",
      "train loss:0.018012265098280383\n",
      "train loss:0.0317431754412206\n",
      "train loss:0.11724065882229566\n",
      "train loss:0.022664059629681897\n",
      "train loss:0.007230384069921172\n",
      "train loss:0.013125287557199524\n",
      "train loss:0.01922105669739421\n",
      "train loss:0.017003066640184826\n",
      "train loss:0.05734789130464818\n",
      "train loss:0.011159761401574986\n",
      "train loss:0.025044570897990077\n",
      "train loss:0.013548528340028168\n",
      "train loss:0.0751058137534791\n",
      "train loss:0.006218223031494806\n",
      "train loss:0.00904734029976503\n",
      "train loss:0.013291034163831645\n",
      "train loss:0.014916873706192029\n",
      "train loss:0.014077016837556982\n",
      "train loss:0.01301291738139966\n",
      "train loss:0.02334918024469177\n",
      "train loss:0.016708938984348748\n",
      "train loss:0.02534488187314004\n",
      "train loss:0.03896955193773566\n",
      "train loss:0.049053580535259836\n",
      "train loss:0.008577346508057604\n",
      "train loss:0.025531265881927875\n",
      "train loss:0.03633591807301124\n",
      "train loss:0.007440244057659637\n",
      "train loss:0.0051772451552212625\n",
      "train loss:0.012915790600832507\n",
      "train loss:0.04374503194394636\n",
      "train loss:0.05769752971682001\n",
      "train loss:0.024290469311610944\n",
      "train loss:0.023400824772020417\n",
      "train loss:0.009627327421997005\n",
      "train loss:0.040890186355011196\n",
      "train loss:0.024392718281142072\n",
      "train loss:0.025003592413719168\n",
      "train loss:0.0387503607058221\n",
      "train loss:0.07238127212478256\n",
      "train loss:0.010818135891680025\n",
      "train loss:0.015631400220245242\n",
      "train loss:0.015673438177815267\n",
      "train loss:0.06110870845522634\n",
      "train loss:0.02338690226978978\n",
      "train loss:0.006412931834425031\n",
      "train loss:0.05115979620909204\n",
      "train loss:0.024524221295091343\n",
      "train loss:0.022102774098887886\n",
      "train loss:0.020181313577203625\n",
      "train loss:0.005622423381259526\n",
      "train loss:0.06216819278445294\n",
      "train loss:0.0050375372257623315\n",
      "train loss:0.08506129961121464\n",
      "train loss:0.02132471420340142\n",
      "train loss:0.02148935828340802\n",
      "train loss:0.011030499501484175\n",
      "train loss:0.03837054195011955\n",
      "train loss:0.0413711873147108\n",
      "train loss:0.04648173932198223\n",
      "train loss:0.0031476869300629084\n",
      "train loss:0.021256062707567178\n",
      "train loss:0.024476116678416645\n",
      "train loss:0.010802448319097366\n",
      "train loss:0.065396607683678\n",
      "train loss:0.025235899698877823\n",
      "train loss:0.047464067858202015\n",
      "train loss:0.0138959037626366\n",
      "train loss:0.00860653323770143\n",
      "train loss:0.028034888620672434\n",
      "train loss:0.01004427387486012\n",
      "train loss:0.01665546882706476\n",
      "train loss:0.010969079541950397\n",
      "train loss:0.021275307370579734\n",
      "train loss:0.02276529180120617\n",
      "train loss:0.014705075654294006\n",
      "train loss:0.01497012217456211\n",
      "train loss:0.009905818432391167\n",
      "train loss:0.018160122676827043\n",
      "train loss:0.046318090734425874\n",
      "train loss:0.009748179509783248\n",
      "train loss:0.0092676151541931\n",
      "train loss:0.021722098761333176\n",
      "train loss:0.014469384471248544\n",
      "train loss:0.06579324861221188\n",
      "train loss:0.007022427585912221\n",
      "train loss:0.013130212523060989\n",
      "train loss:0.03840223237941271\n",
      "train loss:0.04509805473235838\n",
      "train loss:0.01953252571591702\n",
      "train loss:0.04406153177691201\n",
      "train loss:0.01711655216722675\n",
      "train loss:0.015246545800323627\n",
      "train loss:0.013834233283607085\n",
      "train loss:0.049443648960730856\n",
      "train loss:0.025715685458577255\n",
      "train loss:0.00354610739911784\n",
      "train loss:0.02914017736568377\n",
      "train loss:0.005036489005559144\n",
      "train loss:0.060753203391498166\n",
      "train loss:0.016921084609341462\n",
      "train loss:0.03442839646023947\n",
      "train loss:0.01524048479410853\n",
      "train loss:0.01626183726053905\n",
      "train loss:0.03167039908692179\n",
      "train loss:0.06752738156578035\n",
      "train loss:0.028124725458114383\n",
      "train loss:0.0402831249844747\n",
      "train loss:0.059551577932404315\n",
      "train loss:0.006919568634207088\n",
      "train loss:0.024471618173900825\n",
      "train loss:0.050851487463126566\n",
      "train loss:0.023239815324017185\n",
      "train loss:0.009207713217424859\n",
      "train loss:0.034772003617372337\n",
      "train loss:0.032728802458894195\n",
      "train loss:0.021812407983765582\n",
      "train loss:0.045007695968181195\n",
      "train loss:0.03809803821767983\n",
      "train loss:0.03063698800249013\n",
      "train loss:0.011767539986501175\n",
      "train loss:0.0301584743808769\n",
      "train loss:0.02559257606016415\n",
      "train loss:0.019589523283075592\n",
      "train loss:0.036644425732317416\n",
      "train loss:0.08242398085908871\n",
      "train loss:0.03192021789748977\n",
      "train loss:0.01993503769856373\n",
      "train loss:0.04878438980029269\n",
      "train loss:0.042878772272273595\n",
      "train loss:0.009127948517958262\n",
      "train loss:0.0351075563368105\n",
      "train loss:0.06378627646927824\n",
      "train loss:0.028325741437323915\n",
      "train loss:0.0442385130803108\n",
      "train loss:0.018810115722235527\n",
      "train loss:0.008958029792453404\n",
      "train loss:0.013469958065158256\n",
      "train loss:0.008463182016078014\n",
      "train loss:0.013340603515732963\n",
      "train loss:0.01899518596838513\n",
      "train loss:0.03693159931885771\n",
      "train loss:0.030926993430389082\n",
      "train loss:0.047335258371054956\n",
      "train loss:0.06883489678115827\n",
      "train loss:0.084107465293347\n",
      "train loss:0.01670923926658512\n",
      "train loss:0.009192606781158295\n",
      "train loss:0.02050050380586477\n",
      "train loss:0.022479491378920156\n",
      "train loss:0.02271502234205087\n",
      "train loss:0.03530254280677061\n",
      "train loss:0.07368988125358694\n",
      "train loss:0.02193264360526724\n",
      "train loss:0.03392946538409167\n",
      "train loss:0.026034695253084814\n",
      "train loss:0.026587600684086988\n",
      "train loss:0.014837136330689882\n",
      "train loss:0.04026226067259466\n",
      "train loss:0.016372717141273887\n",
      "train loss:0.005008105141945216\n",
      "train loss:0.009054916016823391\n",
      "train loss:0.04257663149388717\n",
      "train loss:0.015706222876796246\n",
      "train loss:0.10065587287828588\n",
      "train loss:0.004009411120636925\n",
      "train loss:0.020097460221862096\n",
      "train loss:0.017171377520944955\n",
      "train loss:0.025515061017575662\n",
      "train loss:0.01676284307788935\n",
      "train loss:0.011313696169215954\n",
      "train loss:0.14312306938019942\n",
      "train loss:0.03470460353093811\n",
      "train loss:0.009766216377832962\n",
      "train loss:0.024938299931013503\n",
      "train loss:0.010530720467372315\n",
      "train loss:0.015453583397989181\n",
      "train loss:0.06217727403928516\n",
      "train loss:0.014698051186262068\n",
      "train loss:0.024613693900293526\n",
      "train loss:0.04246868175140189\n",
      "train loss:0.10608271506300654\n",
      "train loss:0.05355543596484725\n",
      "train loss:0.0599803521185843\n",
      "train loss:0.016752577769049128\n",
      "train loss:0.03292491782999366\n",
      "train loss:0.02981206957546756\n",
      "train loss:0.015729269826627302\n",
      "train loss:0.012921715298520516\n",
      "train loss:0.016093736603910936\n",
      "train loss:0.05242562105457866\n",
      "train loss:0.01682512164314234\n",
      "train loss:0.00590179335331039\n",
      "train loss:0.004097820318964366\n",
      "train loss:0.02941704021313475\n",
      "train loss:0.007798799541809994\n",
      "train loss:0.014912883534865265\n",
      "train loss:0.04401407200135174\n",
      "train loss:0.03511083110541938\n",
      "train loss:0.017730871542507562\n",
      "train loss:0.037862317460837645\n",
      "train loss:0.021617576313374482\n",
      "train loss:0.08817624069648344\n",
      "train loss:0.017777346812655897\n",
      "train loss:0.0990112024232108\n",
      "train loss:0.013761414642984611\n",
      "train loss:0.02608307076253171\n",
      "train loss:0.01673253656446944\n",
      "train loss:0.018573429853143034\n",
      "train loss:0.011460774614212979\n",
      "train loss:0.010632751506972507\n",
      "train loss:0.01999787272155933\n",
      "train loss:0.048783469081451744\n",
      "train loss:0.011255333080423367\n",
      "train loss:0.06665319500199378\n",
      "train loss:0.028435264420493236\n",
      "train loss:0.011107500689744252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013891685486025446\n",
      "train loss:0.009016636545962388\n",
      "train loss:0.04473315493795105\n",
      "train loss:0.04904104512005118\n",
      "train loss:0.02721696143332355\n",
      "train loss:0.046819730423808714\n",
      "train loss:0.0338731895081122\n",
      "train loss:0.0068125253637779\n",
      "train loss:0.010356979251807402\n",
      "train loss:0.018081670918018756\n",
      "train loss:0.027702556551804678\n",
      "train loss:0.023434254887102948\n",
      "train loss:0.053221493707245694\n",
      "train loss:0.009258096167548944\n",
      "train loss:0.010593451073055744\n",
      "train loss:0.03164501488749004\n",
      "train loss:0.04959000319214463\n",
      "train loss:0.021236824734086068\n",
      "train loss:0.015812085337794875\n",
      "train loss:0.010521515955205006\n",
      "train loss:0.062354456682819304\n",
      "train loss:0.010391859928696724\n",
      "train loss:0.030359906223499145\n",
      "train loss:0.009805139869335299\n",
      "train loss:0.04894799778845198\n",
      "train loss:0.030479255240491512\n",
      "train loss:0.058772344784832446\n",
      "train loss:0.05816143613349447\n",
      "train loss:0.05074213061880736\n",
      "train loss:0.05497121613318536\n",
      "train loss:0.027084490941280574\n",
      "train loss:0.037728994060637386\n",
      "train loss:0.009687637390343328\n",
      "train loss:0.006579765373671667\n",
      "train loss:0.09083778809528323\n",
      "train loss:0.013752644067841132\n",
      "train loss:0.010536676155423688\n",
      "train loss:0.025362005895267718\n",
      "train loss:0.05157484883330592\n",
      "train loss:0.03916624837487247\n",
      "train loss:0.02428793391718076\n",
      "train loss:0.05287672610671303\n",
      "train loss:0.012214646461818525\n",
      "train loss:0.006130251583889151\n",
      "train loss:0.00943594917102367\n",
      "train loss:0.022324836111123805\n",
      "train loss:0.08251763798435094\n",
      "train loss:0.01826457627940458\n",
      "train loss:0.05991584697984912\n",
      "train loss:0.03772420265109691\n",
      "train loss:0.03357789178678284\n",
      "train loss:0.010226294440926178\n",
      "train loss:0.011998065386393988\n",
      "train loss:0.010266847861598271\n",
      "train loss:0.09997912943778915\n",
      "train loss:0.05657598704072794\n",
      "train loss:0.03281338154083108\n",
      "train loss:0.03916647490396869\n",
      "train loss:0.014639707580204903\n",
      "train loss:0.06778352900856308\n",
      "train loss:0.015899206137982298\n",
      "train loss:0.014349115878641999\n",
      "train loss:0.017547664805494134\n",
      "train loss:0.04684362883307384\n",
      "train loss:0.017623204799424818\n",
      "train loss:0.017501646927915462\n",
      "train loss:0.026325101357149668\n",
      "train loss:0.0761794850109766\n",
      "train loss:0.02097514376167098\n",
      "train loss:0.025707136639039584\n",
      "train loss:0.03552471802936013\n",
      "train loss:0.0421504512676719\n",
      "train loss:0.012757403533136893\n",
      "train loss:0.02044084037730286\n",
      "train loss:0.025432281142285178\n",
      "train loss:0.008739330552081374\n",
      "train loss:0.017401800035325307\n",
      "train loss:0.005353628918520792\n",
      "train loss:0.03025248364048732\n",
      "train loss:0.03890254718352107\n",
      "train loss:0.020781900574687272\n",
      "train loss:0.057748945178013315\n",
      "train loss:0.01952008052277551\n",
      "train loss:0.019329395715962802\n",
      "train loss:0.02336467469946154\n",
      "train loss:0.07478876739156357\n",
      "train loss:0.043150017085373964\n",
      "train loss:0.019087209556576782\n",
      "train loss:0.010918012322618138\n",
      "train loss:0.011145795487141043\n",
      "train loss:0.016945396762979424\n",
      "train loss:0.03515442186391625\n",
      "train loss:0.01714069247221503\n",
      "train loss:0.05377435891786935\n",
      "train loss:0.008362919485561839\n",
      "train loss:0.014606934169824679\n",
      "train loss:0.045807108520418624\n",
      "train loss:0.00471102033319319\n",
      "train loss:0.017951024755140675\n",
      "train loss:0.005109932291131548\n",
      "train loss:0.022492312638748763\n",
      "train loss:0.01028775928506118\n",
      "train loss:0.009467254553882577\n",
      "=== epoch:6, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.022110511397458316\n",
      "train loss:0.016186148347133823\n",
      "train loss:0.00705054744836105\n",
      "train loss:0.02544736671765457\n",
      "train loss:0.07247058665775427\n",
      "train loss:0.014863053957008486\n",
      "train loss:0.021753723180181747\n",
      "train loss:0.007776790847235656\n",
      "train loss:0.009035628565037425\n",
      "train loss:0.06569113432888236\n",
      "train loss:0.01927443885963347\n",
      "train loss:0.02562506873887454\n",
      "train loss:0.01316641248066948\n",
      "train loss:0.004139025151885299\n",
      "train loss:0.03691414279557574\n",
      "train loss:0.010522045807576565\n",
      "train loss:0.008203102222191484\n",
      "train loss:0.012676423693351724\n",
      "train loss:0.027810941851571604\n",
      "train loss:0.028938653533297803\n",
      "train loss:0.017073212407990746\n",
      "train loss:0.06281805241780752\n",
      "train loss:0.02549801884030301\n",
      "train loss:0.003203862964286019\n",
      "train loss:0.04465134579428845\n",
      "train loss:0.06002727207021549\n",
      "train loss:0.0021826177679189628\n",
      "train loss:0.005092813584037535\n",
      "train loss:0.013740674839576807\n",
      "train loss:0.007307886517473379\n",
      "train loss:0.014211183964824842\n",
      "train loss:0.023263206897118725\n",
      "train loss:0.021490155861128332\n",
      "train loss:0.006905709315152088\n",
      "train loss:0.03856656515243419\n",
      "train loss:0.008084231834776679\n",
      "train loss:0.016064206902067026\n",
      "train loss:0.02759879522970771\n",
      "train loss:0.015535384730540567\n",
      "train loss:0.029890272692654752\n",
      "train loss:0.06666324037185638\n",
      "train loss:0.011356029759396894\n",
      "train loss:0.08385209775683049\n",
      "train loss:0.020561698900728915\n",
      "train loss:0.024625435830208327\n",
      "train loss:0.01597070719475894\n",
      "train loss:0.010231773351849613\n",
      "train loss:0.013799913969442969\n",
      "train loss:0.015746372789044547\n",
      "train loss:0.0440418683873609\n",
      "train loss:0.014877560495696395\n",
      "train loss:0.01946011951470655\n",
      "train loss:0.05550666625851622\n",
      "train loss:0.010157199914399445\n",
      "train loss:0.03870666480615974\n",
      "train loss:0.023760842669074078\n",
      "train loss:0.046021551362653616\n",
      "train loss:0.004062371476783215\n",
      "train loss:0.021846866452036987\n",
      "train loss:0.019409884517267238\n",
      "train loss:0.007763923861016206\n",
      "train loss:0.005173804503658876\n",
      "train loss:0.011803077879483766\n",
      "train loss:0.029393871391905795\n",
      "train loss:0.011715543485057855\n",
      "train loss:0.006632014805667357\n",
      "train loss:0.006584575764375985\n",
      "train loss:0.019002785240992706\n",
      "train loss:0.03040632229439193\n",
      "train loss:0.027732751449933767\n",
      "train loss:0.03651770264594204\n",
      "train loss:0.02644967960359357\n",
      "train loss:0.008611059887919572\n",
      "train loss:0.0334587084652094\n",
      "train loss:0.012941115527270388\n",
      "train loss:0.009523422730223895\n",
      "train loss:0.055084853149418994\n",
      "train loss:0.004411467503518018\n",
      "train loss:0.006595500945566718\n",
      "train loss:0.02026687864615024\n",
      "train loss:0.011327482804532312\n",
      "train loss:0.007173970817014343\n",
      "train loss:0.0044071524196095824\n",
      "train loss:0.013055212369858888\n",
      "train loss:0.026779087557262885\n",
      "train loss:0.03202161330617705\n",
      "train loss:0.03153320400742428\n",
      "train loss:0.026364347291044265\n",
      "train loss:0.00919974953920736\n",
      "train loss:0.019848374998839527\n",
      "train loss:0.05473111423910738\n",
      "train loss:0.038205749377407415\n",
      "train loss:0.02069549081537114\n",
      "train loss:0.021834649964898013\n",
      "train loss:0.024797172989717016\n",
      "train loss:0.0320129647629529\n",
      "train loss:0.006496973714044923\n",
      "train loss:0.0058464144359434\n",
      "train loss:0.020561209804506545\n",
      "train loss:0.07054447495594525\n",
      "train loss:0.015204385174157007\n",
      "train loss:0.00756269414456695\n",
      "train loss:0.039324326840737105\n",
      "train loss:0.009790169797078793\n",
      "train loss:0.030467005710369408\n",
      "train loss:0.13236857165733115\n",
      "train loss:0.0731240404589063\n",
      "train loss:0.011593504389610342\n",
      "train loss:0.012948168333965678\n",
      "train loss:0.017306774052507766\n",
      "train loss:0.012226825491393947\n",
      "train loss:0.024518163415634318\n",
      "train loss:0.013378642527085345\n",
      "train loss:0.007867289409334623\n",
      "train loss:0.012228967244390149\n",
      "train loss:0.0193744951103298\n",
      "train loss:0.01918486375428778\n",
      "train loss:0.013168599757314398\n",
      "train loss:0.008720162984697664\n",
      "train loss:0.02349810748958357\n",
      "train loss:0.02212759652062849\n",
      "train loss:0.028662513543204177\n",
      "train loss:0.014540403222149145\n",
      "train loss:0.008801955022315948\n",
      "train loss:0.006977831478345451\n",
      "train loss:0.01640196196891472\n",
      "train loss:0.060759597679917565\n",
      "train loss:0.006095469505898245\n",
      "train loss:0.01231888225006289\n",
      "train loss:0.008413988756306447\n",
      "train loss:0.0027463889479649507\n",
      "train loss:0.01971585991380595\n",
      "train loss:0.007948680857957368\n",
      "train loss:0.01356767799067267\n",
      "train loss:0.012715775971867255\n",
      "train loss:0.031329772366470825\n",
      "train loss:0.0218518876128408\n",
      "train loss:0.05885487460588194\n",
      "train loss:0.027651713124540712\n",
      "train loss:0.020712201617361356\n",
      "train loss:0.12066311789645305\n",
      "train loss:0.014834131359193687\n",
      "train loss:0.003962515814502583\n",
      "train loss:0.007385823207261309\n",
      "train loss:0.0051495381409324345\n",
      "train loss:0.031092714561388804\n",
      "train loss:0.02365156838743039\n",
      "train loss:0.0200319332128493\n",
      "train loss:0.024559571791352184\n",
      "train loss:0.01940245133885172\n",
      "train loss:0.014189002436969085\n",
      "train loss:0.002159725448025808\n",
      "train loss:0.006529732171859972\n",
      "train loss:0.0125561154674099\n",
      "train loss:0.016889808882499725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017541774646367487\n",
      "train loss:0.029780289610987408\n",
      "train loss:0.009097301081514308\n",
      "train loss:0.018716476759758408\n",
      "train loss:0.009240344314199745\n",
      "train loss:0.012004185044422539\n",
      "train loss:0.014386161495836935\n",
      "train loss:0.022941285406349068\n",
      "train loss:0.01984815239239969\n",
      "train loss:0.014578673817231245\n",
      "train loss:0.0072744393050189786\n",
      "train loss:0.011904914499885191\n",
      "train loss:0.021478677234914114\n",
      "train loss:0.02583285985550782\n",
      "train loss:0.011881845602151293\n",
      "train loss:0.04445999088680469\n",
      "train loss:0.010882314777778153\n",
      "train loss:0.02038076570577227\n",
      "train loss:0.02664924981449742\n",
      "train loss:0.004798221190067962\n",
      "train loss:0.016612217453433758\n",
      "train loss:0.008278810656081655\n",
      "train loss:0.009556068474694725\n",
      "train loss:0.018191465605975673\n",
      "train loss:0.019228372881935855\n",
      "train loss:0.023778603210269943\n",
      "train loss:0.028387750209681456\n",
      "train loss:0.05373147142488072\n",
      "train loss:0.025669615140205496\n",
      "train loss:0.02540741614553269\n",
      "train loss:0.012041756779700373\n",
      "train loss:0.03369987874065901\n",
      "train loss:0.0027420128108641127\n",
      "train loss:0.0027997040915043203\n",
      "train loss:0.0020160578109370466\n",
      "train loss:0.04545137910411579\n",
      "train loss:0.016678673208888762\n",
      "train loss:0.011550337482646767\n",
      "train loss:0.009239110637824274\n",
      "train loss:0.008843182773888337\n",
      "train loss:0.03304377995168731\n",
      "train loss:0.017419819129569646\n",
      "train loss:0.003215172625943162\n",
      "train loss:0.02620138276820538\n",
      "train loss:0.020864160346452755\n",
      "train loss:0.03541755502623087\n",
      "train loss:0.0376415844302565\n",
      "train loss:0.04707627336879263\n",
      "train loss:0.022736393010271704\n",
      "train loss:0.07100372303317888\n",
      "train loss:0.001206995712143434\n",
      "train loss:0.011894031898260755\n",
      "train loss:0.011134962934125737\n",
      "train loss:0.009107076245145623\n",
      "train loss:0.007122105952394213\n",
      "train loss:0.02819664396816995\n",
      "train loss:0.01793505379664351\n",
      "train loss:0.04232553227127123\n",
      "train loss:0.09284582807758758\n",
      "train loss:0.011450377360718505\n",
      "train loss:0.017589773753422706\n",
      "train loss:0.008326861315280093\n",
      "train loss:0.05189124060775599\n",
      "train loss:0.00912304475255144\n",
      "train loss:0.026776722210881926\n",
      "train loss:0.0026304092926409312\n",
      "train loss:0.014267539509492794\n",
      "train loss:0.10017101534507804\n",
      "train loss:0.00611802831240447\n",
      "train loss:0.03393941145069706\n",
      "train loss:0.015012079638487129\n",
      "train loss:0.025607526877462806\n",
      "train loss:0.006712101554898158\n",
      "train loss:0.023376542970795725\n",
      "train loss:0.024606317016523726\n",
      "train loss:0.00898613884686576\n",
      "train loss:0.005517177625736525\n",
      "train loss:0.0377907098224267\n",
      "train loss:0.0017951111448189802\n",
      "train loss:0.007112155621971845\n",
      "train loss:0.007294635171758803\n",
      "train loss:0.0068338287236555705\n",
      "train loss:0.02558609292966182\n",
      "train loss:0.005706273555281765\n",
      "train loss:0.007982478059137125\n",
      "train loss:0.02343573818567379\n",
      "train loss:0.020410637047670148\n",
      "train loss:0.06478094470086353\n",
      "train loss:0.07409669829573111\n",
      "train loss:0.05445700356193726\n",
      "train loss:0.030869868141083213\n",
      "train loss:0.0270715641558846\n",
      "train loss:0.002993429037394441\n",
      "train loss:0.016382763461854466\n",
      "train loss:0.014532174447861042\n",
      "train loss:0.03663763686972435\n",
      "train loss:0.03911770386002987\n",
      "train loss:0.010704416685227749\n",
      "train loss:0.04051279825808394\n",
      "train loss:0.04698897513677454\n",
      "train loss:0.018550161461031858\n",
      "train loss:0.025047867408971292\n",
      "train loss:0.023748983386299934\n",
      "train loss:0.05378444602041034\n",
      "train loss:0.006020704574912128\n",
      "train loss:0.026672910027561104\n",
      "train loss:0.03929904350567354\n",
      "train loss:0.01369952507281138\n",
      "train loss:0.05523870704215311\n",
      "train loss:0.02007802303809608\n",
      "train loss:0.005094419744399674\n",
      "train loss:0.013304019948881871\n",
      "train loss:0.0675542171620549\n",
      "train loss:0.027563415402179103\n",
      "train loss:0.052591531035872434\n",
      "train loss:0.06481466242146747\n",
      "train loss:0.014723773164183851\n",
      "train loss:0.06220995623193442\n",
      "train loss:0.021595505348901978\n",
      "train loss:0.029110375318628815\n",
      "train loss:0.003850599720613432\n",
      "train loss:0.011966610017964967\n",
      "train loss:0.04584683209585103\n",
      "train loss:0.01637351532627936\n",
      "train loss:0.003836306319957306\n",
      "train loss:0.062122235863811964\n",
      "train loss:0.012305803666885414\n",
      "train loss:0.011806517399339323\n",
      "train loss:0.08519899558786018\n",
      "train loss:0.022212554326248867\n",
      "train loss:0.03390223432008083\n",
      "train loss:0.02130551594511686\n",
      "train loss:0.012801244000996964\n",
      "train loss:0.0409546690462457\n",
      "train loss:0.03964547579353193\n",
      "train loss:0.027702041585754903\n",
      "train loss:0.005532486527335777\n",
      "train loss:0.023398981768632497\n",
      "train loss:0.03704011630906861\n",
      "train loss:0.03633708373260822\n",
      "train loss:0.008114813472446376\n",
      "train loss:0.04091875147139877\n",
      "train loss:0.02126010422150907\n",
      "train loss:0.021358708781681272\n",
      "train loss:0.04785282980349362\n",
      "train loss:0.034213706773135955\n",
      "train loss:0.007132621129955361\n",
      "train loss:0.03261606442837846\n",
      "train loss:0.01969175102433896\n",
      "train loss:0.026726347864421313\n",
      "train loss:0.015221730447353359\n",
      "train loss:0.0363305385132711\n",
      "train loss:0.03282898210729106\n",
      "train loss:0.055048386137729215\n",
      "train loss:0.014433453288556006\n",
      "train loss:0.009996177276733248\n",
      "train loss:0.033646690833091054\n",
      "train loss:0.007743172373821341\n",
      "train loss:0.028483908588962933\n",
      "train loss:0.013021348766733552\n",
      "train loss:0.02629285597036536\n",
      "train loss:0.01730079788516378\n",
      "train loss:0.007361402785906927\n",
      "train loss:0.11480910648099595\n",
      "train loss:0.025877148704727695\n",
      "train loss:0.030629345803356512\n",
      "train loss:0.06973262773847547\n",
      "train loss:0.005187513132955505\n",
      "train loss:0.027365191045148004\n",
      "train loss:0.01649419500748614\n",
      "train loss:0.01336631706852932\n",
      "train loss:0.02452166101730212\n",
      "train loss:0.018571463825661515\n",
      "train loss:0.028374112801817716\n",
      "train loss:0.06488583266219533\n",
      "train loss:0.02915221580199228\n",
      "train loss:0.022055183145948513\n",
      "train loss:0.09387366309044408\n",
      "train loss:0.02995521557257977\n",
      "train loss:0.025662485924652513\n",
      "train loss:0.03506765930265138\n",
      "train loss:0.03972120921335121\n",
      "train loss:0.025954353270986198\n",
      "train loss:0.018908232793597615\n",
      "train loss:0.015521414151320865\n",
      "train loss:0.04409549792547099\n",
      "train loss:0.019116196644399577\n",
      "train loss:0.009954913986993693\n",
      "train loss:0.028769374488536358\n",
      "train loss:0.014370758251290187\n",
      "train loss:0.010893428566885457\n",
      "train loss:0.03612125859057633\n",
      "train loss:0.006926922511305249\n",
      "train loss:0.015224811202952064\n",
      "train loss:0.007653471994536049\n",
      "train loss:0.01269339709178849\n",
      "train loss:0.02043515300659008\n",
      "train loss:0.015691543848126356\n",
      "train loss:0.012183823413768089\n",
      "train loss:0.01834099340490047\n",
      "train loss:0.0054006418530714315\n",
      "train loss:0.01970320054803868\n",
      "train loss:0.0300351553189043\n",
      "train loss:0.013106517447262924\n",
      "train loss:0.007172901416705387\n",
      "train loss:0.004786853449062109\n",
      "train loss:0.0714737203127877\n",
      "train loss:0.01441145753753237\n",
      "train loss:0.11382617480739819\n",
      "train loss:0.006257173714816937\n",
      "train loss:0.011829968663386233\n",
      "train loss:0.017714763791138413\n",
      "train loss:0.0024216785316552606\n",
      "train loss:0.01347811979060793\n",
      "train loss:0.030441999976645803\n",
      "train loss:0.048458359097729414\n",
      "train loss:0.01403339485160814\n",
      "train loss:0.049519833922835724\n",
      "train loss:0.0062209886115662215\n",
      "train loss:0.033556786717973144\n",
      "train loss:0.017187990640036725\n",
      "train loss:0.017033773800957292\n",
      "train loss:0.047457186908810595\n",
      "train loss:0.00850102254776143\n",
      "train loss:0.006752132447709537\n",
      "train loss:0.008583564302772266\n",
      "train loss:0.031011131307690624\n",
      "train loss:0.009742892204534462\n",
      "train loss:0.010037999861956864\n",
      "train loss:0.005457975200037954\n",
      "train loss:0.007774566986987285\n",
      "train loss:0.02453221059466112\n",
      "train loss:0.01855511135953863\n",
      "train loss:0.016421231763136927\n",
      "train loss:0.040016017819776616\n",
      "train loss:0.016056482297558784\n",
      "train loss:0.05386184992847209\n",
      "train loss:0.07913962111808226\n",
      "train loss:0.016788879000474658\n",
      "train loss:0.0696868906594567\n",
      "train loss:0.03636569730711172\n",
      "train loss:0.023572805432500905\n",
      "train loss:0.01516391716874624\n",
      "train loss:0.01579833014479739\n",
      "train loss:0.026676519901875594\n",
      "train loss:0.034260794164275146\n",
      "train loss:0.036286496960023694\n",
      "train loss:0.013107879881097134\n",
      "train loss:0.01290795168800566\n",
      "train loss:0.08751025225539623\n",
      "train loss:0.030988438979111715\n",
      "train loss:0.005343030409308622\n",
      "train loss:0.0034991947102283576\n",
      "train loss:0.05486633443070455\n",
      "train loss:0.024249502231539682\n",
      "train loss:0.04109589317944039\n",
      "train loss:0.1515148805709436\n",
      "train loss:0.08144060105879021\n",
      "train loss:0.005470607891383629\n",
      "train loss:0.015138995034296393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.028835843835986644\n",
      "train loss:0.0173609826218396\n",
      "train loss:0.0034924246286126242\n",
      "train loss:0.028887868483371403\n",
      "train loss:0.02488855623915929\n",
      "train loss:0.008796153194780072\n",
      "train loss:0.0092332618644677\n",
      "train loss:0.011671942473746717\n",
      "train loss:0.009772040488301777\n",
      "train loss:0.011106865193281842\n",
      "train loss:0.009393391517261394\n",
      "train loss:0.019071781391833444\n",
      "train loss:0.006651983387716904\n",
      "train loss:0.013748286680163273\n",
      "train loss:0.044800347970380405\n",
      "train loss:0.009688379719683561\n",
      "train loss:0.01857316015232871\n",
      "train loss:0.020530235520531882\n",
      "train loss:0.005408241409767458\n",
      "train loss:0.009150963644233517\n",
      "train loss:0.0065658613668264565\n",
      "train loss:0.002686405284078172\n",
      "train loss:0.0298529855616594\n",
      "train loss:0.04976425421122893\n",
      "train loss:0.00867150676800301\n",
      "train loss:0.008396869627610212\n",
      "train loss:0.01821307578025755\n",
      "train loss:0.05640487595679314\n",
      "train loss:0.0366668629436079\n",
      "train loss:0.010953361322430431\n",
      "train loss:0.026966924542379988\n",
      "train loss:0.05136097056738643\n",
      "train loss:0.015384129871685715\n",
      "train loss:0.010237319118640776\n",
      "train loss:0.05941126549892986\n",
      "train loss:0.009456630393351343\n",
      "train loss:0.05213650990251662\n",
      "train loss:0.009552359798157653\n",
      "train loss:0.012355685868662324\n",
      "train loss:0.018915360775689904\n",
      "train loss:0.008049748780047165\n",
      "train loss:0.08216195938200052\n",
      "train loss:0.021469401375981554\n",
      "train loss:0.008370688314077722\n",
      "train loss:0.050866294634782816\n",
      "train loss:0.012378793663120446\n",
      "train loss:0.019871103987977166\n",
      "train loss:0.004757230825103869\n",
      "train loss:0.013405832978826037\n",
      "train loss:0.0489763344528905\n",
      "train loss:0.014350455508772864\n",
      "train loss:0.04938381235030831\n",
      "train loss:0.0036811501515154493\n",
      "train loss:0.1037212102471995\n",
      "train loss:0.04289859524917235\n",
      "train loss:0.023557352270921483\n",
      "train loss:0.024488216485940444\n",
      "train loss:0.0032967001748092414\n",
      "train loss:0.008079002120981248\n",
      "train loss:0.03172454630333398\n",
      "train loss:0.02001098580681525\n",
      "train loss:0.021170131295830882\n",
      "train loss:0.05215626621711565\n",
      "train loss:0.030482091873906058\n",
      "train loss:0.011796162505415562\n",
      "train loss:0.045806512479106026\n",
      "train loss:0.009766746224047777\n",
      "train loss:0.009546135069698133\n",
      "train loss:0.03542646377765011\n",
      "train loss:0.042320169904218156\n",
      "train loss:0.03015832959643366\n",
      "train loss:0.007241273500478689\n",
      "train loss:0.02483911699061504\n",
      "train loss:0.05540320981746539\n",
      "train loss:0.010344720805041346\n",
      "train loss:0.006642795725408998\n",
      "train loss:0.035818870942681186\n",
      "train loss:0.02569577570414619\n",
      "train loss:0.013680491860300934\n",
      "train loss:0.006542435567610646\n",
      "train loss:0.05911208599371931\n",
      "train loss:0.014184592000328188\n",
      "train loss:0.011740451616098088\n",
      "train loss:0.08036656248412928\n",
      "train loss:0.019157239353702248\n",
      "train loss:0.02321222647704816\n",
      "train loss:0.10654341872654216\n",
      "train loss:0.007624120984540176\n",
      "train loss:0.015544623720726083\n",
      "train loss:0.012009764769646063\n",
      "train loss:0.057875243406559494\n",
      "train loss:0.006244913706976365\n",
      "train loss:0.05517489978987409\n",
      "train loss:0.008990241274835943\n",
      "train loss:0.028496173324829774\n",
      "train loss:0.018626739025387407\n",
      "train loss:0.008845783000840773\n",
      "train loss:0.0035805936358665118\n",
      "train loss:0.010475525584306627\n",
      "train loss:0.01319128560014174\n",
      "train loss:0.004661990041979528\n",
      "train loss:0.02592616829787675\n",
      "train loss:0.01435934149319209\n",
      "train loss:0.006091940057076563\n",
      "train loss:0.02241640810979588\n",
      "train loss:0.013110040099006477\n",
      "train loss:0.0052419236981213115\n",
      "train loss:0.014933157836304894\n",
      "train loss:0.003859035304376629\n",
      "train loss:0.011449900449277142\n",
      "train loss:0.008376455886323539\n",
      "train loss:0.005787928511353347\n",
      "train loss:0.013096499328179927\n",
      "train loss:0.006495396784400694\n",
      "train loss:0.016234609252052935\n",
      "train loss:0.01984963598117739\n",
      "train loss:0.016634359720057258\n",
      "train loss:0.024869183806221832\n",
      "train loss:0.006235786605463749\n",
      "train loss:0.00485872061059512\n",
      "train loss:0.011225371602607998\n",
      "train loss:0.015209806901938022\n",
      "train loss:0.026508782000534213\n",
      "train loss:0.014689794266507556\n",
      "train loss:0.00909648559649408\n",
      "train loss:0.019807116902408436\n",
      "train loss:0.019550783305052256\n",
      "train loss:0.03499485256508117\n",
      "train loss:0.13198693434262196\n",
      "train loss:0.02247314300600054\n",
      "train loss:0.012160784371430575\n",
      "train loss:0.01432940767007691\n",
      "train loss:0.056955351520301886\n",
      "train loss:0.054891021177459594\n",
      "train loss:0.00787283408539317\n",
      "train loss:0.027906369028052515\n",
      "train loss:0.07907536247420097\n",
      "train loss:0.0061634745209243145\n",
      "train loss:0.007568950945963299\n",
      "train loss:0.008410216638089713\n",
      "train loss:0.032884645724045786\n",
      "train loss:0.018522133898363758\n",
      "train loss:0.01279015050280413\n",
      "train loss:0.015462859546254619\n",
      "train loss:0.01722890950023954\n",
      "train loss:0.09631875088181566\n",
      "train loss:0.028757945746793977\n",
      "train loss:0.0028430504458732803\n",
      "train loss:0.010129134861220327\n",
      "train loss:0.00405580527636485\n",
      "train loss:0.014822735183510832\n",
      "train loss:0.023518754411027465\n",
      "train loss:0.03433761569994193\n",
      "train loss:0.004266321087718146\n",
      "train loss:0.029943676012026375\n",
      "train loss:0.005431916565356612\n",
      "train loss:0.004501344555811892\n",
      "train loss:0.00354851665066753\n",
      "train loss:0.020089702479712562\n",
      "train loss:0.02071321221205767\n",
      "train loss:0.007176788835845092\n",
      "train loss:0.030915530641855867\n",
      "train loss:0.04485265226239978\n",
      "train loss:0.012011883743385384\n",
      "train loss:0.009578132007381597\n",
      "train loss:0.021102143724462855\n",
      "train loss:0.04440501705291593\n",
      "train loss:0.010655615853408837\n",
      "train loss:0.010644338611289375\n",
      "train loss:0.01104856130994083\n",
      "train loss:0.02576071788887375\n",
      "train loss:0.01239832723095587\n",
      "train loss:0.11669127375876487\n",
      "train loss:0.003150290234817534\n",
      "train loss:0.0908950220225119\n",
      "train loss:0.004317469043252277\n",
      "train loss:0.012193041825572536\n",
      "train loss:0.006148246340834843\n",
      "train loss:0.010836069765730295\n",
      "train loss:0.014112555309636777\n",
      "train loss:0.023566295936465177\n",
      "train loss:0.009152182102004785\n",
      "train loss:0.030085445409153987\n",
      "train loss:0.007299973297328234\n",
      "train loss:0.03192566995653151\n",
      "=== epoch:7, train acc:0.992, test acc:0.987 ===\n",
      "train loss:0.02007659961202419\n",
      "train loss:0.025283435921394128\n",
      "train loss:0.014075639257475608\n",
      "train loss:0.002914106058140346\n",
      "train loss:0.012257198269649706\n",
      "train loss:0.008833071844052404\n",
      "train loss:0.01226773644770195\n",
      "train loss:0.032459784932902684\n",
      "train loss:0.060430329493150386\n",
      "train loss:0.04717848714965783\n",
      "train loss:0.009342841667001384\n",
      "train loss:0.008005206152079659\n",
      "train loss:0.026291254068118105\n",
      "train loss:0.0053745201437063565\n",
      "train loss:0.014661344986428293\n",
      "train loss:0.021614694253385566\n",
      "train loss:0.0198575884533717\n",
      "train loss:0.049199288180277106\n",
      "train loss:0.009519694730027582\n",
      "train loss:0.018991030186361658\n",
      "train loss:0.02725890129907209\n",
      "train loss:0.03975073787802294\n",
      "train loss:0.009443935568328551\n",
      "train loss:0.013456166047486754\n",
      "train loss:0.0030513407243950336\n",
      "train loss:0.017201110538140805\n",
      "train loss:0.012236131394344176\n",
      "train loss:0.0020825169848651555\n",
      "train loss:0.010281885417338448\n",
      "train loss:0.009308491066160725\n",
      "train loss:0.04475810447566181\n",
      "train loss:0.030940626377243933\n",
      "train loss:0.022285342993716636\n",
      "train loss:0.008345772759436135\n",
      "train loss:0.011368290740521658\n",
      "train loss:0.04094700586273171\n",
      "train loss:0.026045161217067566\n",
      "train loss:0.006235014997626521\n",
      "train loss:0.006329199615855199\n",
      "train loss:0.03179023689490447\n",
      "train loss:0.01656903783219977\n",
      "train loss:0.020621246262674225\n",
      "train loss:0.004264688459026864\n",
      "train loss:0.0027470924150315777\n",
      "train loss:0.022237554058231416\n",
      "train loss:0.007948068325043994\n",
      "train loss:0.007720455409519419\n",
      "train loss:0.006087501487522976\n",
      "train loss:0.028589579235355118\n",
      "train loss:0.04179595738291412\n",
      "train loss:0.016913962733962725\n",
      "train loss:0.011685487709199105\n",
      "train loss:0.028671374877956728\n",
      "train loss:0.0031838681079394237\n",
      "train loss:0.009317181674703969\n",
      "train loss:0.020318598470075454\n",
      "train loss:0.012414653575380795\n",
      "train loss:0.006639983555999797\n",
      "train loss:0.007701525992806\n",
      "train loss:0.01199464962394112\n",
      "train loss:0.00799865313169817\n",
      "train loss:0.0167042315895594\n",
      "train loss:0.01444098391922436\n",
      "train loss:0.007510300283608994\n",
      "train loss:0.004575468855627276\n",
      "train loss:0.016017999301400784\n",
      "train loss:0.005753947023152557\n",
      "train loss:0.004202086547512595\n",
      "train loss:0.006852489031106084\n",
      "train loss:0.012389582355441827\n",
      "train loss:0.016267718801908724\n",
      "train loss:0.025609696637439835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002327622265618381\n",
      "train loss:0.017872309521241372\n",
      "train loss:0.04295036139303025\n",
      "train loss:0.00541173841953541\n",
      "train loss:0.018484442456426754\n",
      "train loss:0.011796213021757911\n",
      "train loss:0.046299060897714475\n",
      "train loss:0.021854417313455388\n",
      "train loss:0.011250534578262122\n",
      "train loss:0.04388270555240378\n",
      "train loss:0.06539264401029027\n",
      "train loss:0.015310241659718565\n",
      "train loss:0.00657514183490549\n",
      "train loss:0.188790608626301\n",
      "train loss:0.0019163998307681835\n",
      "train loss:0.010248154726075424\n",
      "train loss:0.009856463348912605\n",
      "train loss:0.06249335573507293\n",
      "train loss:0.049752010869672986\n",
      "train loss:0.013603166026100679\n",
      "train loss:0.017576833567231786\n",
      "train loss:0.012821515220860613\n",
      "train loss:0.002963079730782835\n",
      "train loss:0.014244381459641747\n",
      "train loss:0.005627349631290047\n",
      "train loss:0.009519176722343507\n",
      "train loss:0.012280327032169918\n",
      "train loss:0.007147316784637829\n",
      "train loss:0.028099600583759363\n",
      "train loss:0.006662998177731278\n",
      "train loss:0.0038019157406153285\n",
      "train loss:0.021175808898705087\n",
      "train loss:0.053548673397831675\n",
      "train loss:0.0036496797125522245\n",
      "train loss:0.009871410253383561\n",
      "train loss:0.01180327583928339\n",
      "train loss:0.008209794977453416\n",
      "train loss:0.013302806287405466\n",
      "train loss:0.03307111973954083\n",
      "train loss:0.019610058733654217\n",
      "train loss:0.005189914468865959\n",
      "train loss:0.006912718256464108\n",
      "train loss:0.028759007121954255\n",
      "train loss:0.017877768748378837\n",
      "train loss:0.01361223217737023\n",
      "train loss:0.015371649658899122\n",
      "train loss:0.016730350106167045\n",
      "train loss:0.04358768531574912\n",
      "train loss:0.009597553455110928\n",
      "train loss:0.033487219343562157\n",
      "train loss:0.019313037831755944\n",
      "train loss:0.01006410417428175\n",
      "train loss:0.016839949176244776\n",
      "train loss:0.029895371977499193\n",
      "train loss:0.020495050045254017\n",
      "train loss:0.008426998930528359\n",
      "train loss:0.009429327323435105\n",
      "train loss:0.0025367331105616187\n",
      "train loss:0.05929822231994319\n",
      "train loss:0.0045981990466075736\n",
      "train loss:0.034787750416093347\n",
      "train loss:0.006096512763301976\n",
      "train loss:0.01343318517003177\n",
      "train loss:0.006683585599610386\n",
      "train loss:0.02637959792231273\n",
      "train loss:0.010080920477434377\n",
      "train loss:0.010126798922135418\n",
      "train loss:0.05437714435970434\n",
      "train loss:0.017096696755621775\n",
      "train loss:0.01291507347537999\n",
      "train loss:0.013932790930666237\n",
      "train loss:0.013400588197834146\n",
      "train loss:0.00934529014144589\n",
      "train loss:0.028837698291815657\n",
      "train loss:0.04829340817131514\n",
      "train loss:0.036765040228681996\n",
      "train loss:0.010626455794563392\n",
      "train loss:0.029742128019064694\n",
      "train loss:0.009719813838230507\n",
      "train loss:0.04154889050178021\n",
      "train loss:0.002156114235318008\n",
      "train loss:0.024437887972106206\n",
      "train loss:0.011586452660678854\n",
      "train loss:0.02351739750573819\n",
      "train loss:0.03364996205349441\n",
      "train loss:0.005502643209674494\n",
      "train loss:0.015185830675966027\n",
      "train loss:0.03275445118045257\n",
      "train loss:0.02049319242696836\n",
      "train loss:0.00618477991580018\n",
      "train loss:0.012449386519114843\n",
      "train loss:0.02973283099085444\n",
      "train loss:0.006080230771306519\n",
      "train loss:0.01690448237694817\n",
      "train loss:0.0039259578723654254\n",
      "train loss:0.04382342686372702\n",
      "train loss:0.02136951588544571\n",
      "train loss:0.01908879253942425\n",
      "train loss:0.017362184555460455\n",
      "train loss:0.07885013998922341\n",
      "train loss:0.007096510336390571\n",
      "train loss:0.017479796921428363\n",
      "train loss:0.00784736637701969\n",
      "train loss:0.023038382975009496\n",
      "train loss:0.01992248330306009\n",
      "train loss:0.019310247458597597\n",
      "train loss:0.008079113825468992\n",
      "train loss:0.020054706331456573\n",
      "train loss:0.012142430816506294\n",
      "train loss:0.003738715492030809\n",
      "train loss:0.05376147920387901\n",
      "train loss:0.00310125921141115\n",
      "train loss:0.020976729216847952\n",
      "train loss:0.015138352626827088\n",
      "train loss:0.01217827839400184\n",
      "train loss:0.01227088102388963\n",
      "train loss:0.013520014017603126\n",
      "train loss:0.007343944650092609\n",
      "train loss:0.017201933516752855\n",
      "train loss:0.018119709173587406\n",
      "train loss:0.017726392562631046\n",
      "train loss:0.053443082544626395\n",
      "train loss:0.026776694243333468\n",
      "train loss:0.005258586333479111\n",
      "train loss:0.024531614656724994\n",
      "train loss:0.02941063932544051\n",
      "train loss:0.009589772201446738\n",
      "train loss:0.014413741714249959\n",
      "train loss:0.01211898220096327\n",
      "train loss:0.011929953796206929\n",
      "train loss:0.0032809040434207243\n",
      "train loss:0.018287661803799864\n",
      "train loss:0.0034437452339748436\n",
      "train loss:0.004981814968033024\n",
      "train loss:0.012068177381214185\n",
      "train loss:0.013725151490689818\n",
      "train loss:0.07363388765606538\n",
      "train loss:0.013140058124730658\n",
      "train loss:0.05983151609906183\n",
      "train loss:0.004019697435530815\n",
      "train loss:0.014220488659994528\n",
      "train loss:0.007566211407481687\n",
      "train loss:0.01687397818706056\n",
      "train loss:0.028781946554067118\n",
      "train loss:0.021592079601162606\n",
      "train loss:0.004584897218481479\n",
      "train loss:0.07814684457408662\n",
      "train loss:0.017074864638339408\n",
      "train loss:0.03698597125497964\n",
      "train loss:0.005086533378983098\n",
      "train loss:0.008553238786278713\n",
      "train loss:0.002913264236813115\n",
      "train loss:0.015916882932465678\n",
      "train loss:0.019807642764918507\n",
      "train loss:0.008322630854671872\n",
      "train loss:0.006068995548887274\n",
      "train loss:0.013764551144605723\n",
      "train loss:0.01307823148565153\n",
      "train loss:0.026885442887990295\n",
      "train loss:0.0029154533936850456\n",
      "train loss:0.007050983974979731\n",
      "train loss:0.0014784850564285002\n",
      "train loss:0.015219365445208239\n",
      "train loss:0.005707355554176852\n",
      "train loss:0.005442016339561186\n",
      "train loss:0.012051348907062385\n",
      "train loss:0.006946794623471649\n",
      "train loss:0.044309112107804166\n",
      "train loss:0.006482659377619025\n",
      "train loss:0.0026922149324556514\n",
      "train loss:0.04559186653314475\n",
      "train loss:0.032345300272069916\n",
      "train loss:0.01440504062828546\n",
      "train loss:0.00241373894215022\n",
      "train loss:0.012996721138681333\n",
      "train loss:0.011292058371073957\n",
      "train loss:0.014430441868521453\n",
      "train loss:0.02220148307179841\n",
      "train loss:0.0019463676146479127\n",
      "train loss:0.0029764911573197887\n",
      "train loss:0.015303219425928638\n",
      "train loss:0.009144448343689344\n",
      "train loss:0.021427497110668922\n",
      "train loss:0.002060764814352849\n",
      "train loss:0.0342692167446442\n",
      "train loss:0.01292929377329627\n",
      "train loss:0.004532192678831607\n",
      "train loss:0.016195026770609137\n",
      "train loss:0.008142962907218493\n",
      "train loss:0.016909144452915498\n",
      "train loss:0.0055685049184985925\n",
      "train loss:0.008074879480539697\n",
      "train loss:0.011667337119315608\n",
      "train loss:0.003119703387724003\n",
      "train loss:0.015946074258988342\n",
      "train loss:0.007528180127010032\n",
      "train loss:0.01862605135748552\n",
      "train loss:0.017697104980403104\n",
      "train loss:0.006621261940554182\n",
      "train loss:0.01946130297739307\n",
      "train loss:0.011733052497393964\n",
      "train loss:0.012349395875038062\n",
      "train loss:0.017807298881854453\n",
      "train loss:0.06720731764983899\n",
      "train loss:0.011326458219788192\n",
      "train loss:0.005354912435936787\n",
      "train loss:0.010997760343176762\n",
      "train loss:0.016966179786103815\n",
      "train loss:0.003679784603447534\n",
      "train loss:0.03134021108293028\n",
      "train loss:0.08890059426990395\n",
      "train loss:0.016594440675055402\n",
      "train loss:0.005205383811731654\n",
      "train loss:0.014152440363485013\n",
      "train loss:0.008601680859933411\n",
      "train loss:0.03219539803213994\n",
      "train loss:0.010620845091318174\n",
      "train loss:0.060134804457706775\n",
      "train loss:0.01695629868990606\n",
      "train loss:0.010340142321709576\n",
      "train loss:0.0023641125573017736\n",
      "train loss:0.049843763790234336\n",
      "train loss:0.1030386177012481\n",
      "train loss:0.005803684168257682\n",
      "train loss:0.0039044542512188655\n",
      "train loss:0.006651386151580255\n",
      "train loss:0.006916127344200948\n",
      "train loss:0.007429744571649974\n",
      "train loss:0.001340966090383175\n",
      "train loss:0.006239304360641205\n",
      "train loss:0.034192264575917786\n",
      "train loss:0.0725376988685918\n",
      "train loss:0.009159749974649588\n",
      "train loss:0.01643745080084743\n",
      "train loss:0.004338564219075913\n",
      "train loss:0.030198057040108986\n",
      "train loss:0.010958753915616532\n",
      "train loss:0.008467290140695248\n",
      "train loss:0.04175898323814188\n",
      "train loss:0.004488693678730058\n",
      "train loss:0.0022591941223312965\n",
      "train loss:0.0045249754822745255\n",
      "train loss:0.006597767204139193\n",
      "train loss:0.05005080827427728\n",
      "train loss:0.009269103460406429\n",
      "train loss:0.012320102358936871\n",
      "train loss:0.00740746022149232\n",
      "train loss:0.024686094827619347\n",
      "train loss:0.010796322239537963\n",
      "train loss:0.008633040534047716\n",
      "train loss:0.008776022504357136\n",
      "train loss:0.008726570917503727\n",
      "train loss:0.0017651271835133267\n",
      "train loss:0.01141179669845347\n",
      "train loss:0.0023814180250154647\n",
      "train loss:0.020427371257152514\n",
      "train loss:0.03139329014240508\n",
      "train loss:0.018234953883912733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.027291997518859103\n",
      "train loss:0.016036648235791998\n",
      "train loss:0.06464606770420424\n",
      "train loss:0.013278390923651018\n",
      "train loss:0.009517086930734844\n",
      "train loss:0.026420114735655115\n",
      "train loss:0.004566194616021572\n",
      "train loss:0.024099110990508585\n",
      "train loss:0.006914746736180226\n",
      "train loss:0.02267563148180612\n",
      "train loss:0.0037971214175560298\n",
      "train loss:0.017340240546661573\n",
      "train loss:0.012076762806659662\n",
      "train loss:0.0006933932854539264\n",
      "train loss:0.020356868663518775\n",
      "train loss:0.007335268195274294\n",
      "train loss:0.009586062035364253\n",
      "train loss:0.011890813782103422\n",
      "train loss:0.006175738943815947\n",
      "train loss:0.0117901295393258\n",
      "train loss:0.014856390315990602\n",
      "train loss:0.012669070268883142\n",
      "train loss:0.007603026743158061\n",
      "train loss:0.002456677558529301\n",
      "train loss:0.016984006632400513\n",
      "train loss:0.022264265220853785\n",
      "train loss:0.026571156467064934\n",
      "train loss:0.00508644689551758\n",
      "train loss:0.00518472699583078\n",
      "train loss:0.044838096926177434\n",
      "train loss:0.0071858494451859855\n",
      "train loss:0.01790191568880501\n",
      "train loss:0.010274268993191438\n",
      "train loss:0.010288916205596417\n",
      "train loss:0.005675393791069414\n",
      "train loss:0.0202914044127172\n",
      "train loss:0.03727639254247887\n",
      "train loss:0.007915369198431561\n",
      "train loss:0.0050425995090755205\n",
      "train loss:0.01685176421441379\n",
      "train loss:0.05354708776851263\n",
      "train loss:0.05262968687307865\n",
      "train loss:0.010964865007796802\n",
      "train loss:0.04485154336045212\n",
      "train loss:0.017268141779925843\n",
      "train loss:0.004544698615118672\n",
      "train loss:0.02244015436992277\n",
      "train loss:0.022709335119911828\n",
      "train loss:0.01357014177615554\n",
      "train loss:0.01999619308144733\n",
      "train loss:0.03167392057297663\n",
      "train loss:0.003558398186731472\n",
      "train loss:0.0780077083180282\n",
      "train loss:0.016730205226113758\n",
      "train loss:0.017776080248336868\n",
      "train loss:0.018960800362422415\n",
      "train loss:0.007613309619224176\n",
      "train loss:0.0024403135034487145\n",
      "train loss:0.004815548609552366\n",
      "train loss:0.019894748307193975\n",
      "train loss:0.01561859852804604\n",
      "train loss:0.004411441557578835\n",
      "train loss:0.014062711779212528\n",
      "train loss:0.003583289584064826\n",
      "train loss:0.00767235329425482\n",
      "train loss:0.007103603166746707\n",
      "train loss:0.015971254726849567\n",
      "train loss:0.04000161853916772\n",
      "train loss:0.011581380869139917\n",
      "train loss:0.014913665377757805\n",
      "train loss:0.056971248247662115\n",
      "train loss:0.00463073322356324\n",
      "train loss:0.005513079578090375\n",
      "train loss:0.011152521668958915\n",
      "train loss:0.06757000017811331\n",
      "train loss:0.0273090063085951\n",
      "train loss:0.025961842449147867\n",
      "train loss:0.0029461976734203583\n",
      "train loss:0.008403309339569549\n",
      "train loss:0.005609728477274251\n",
      "train loss:0.009099779146279064\n",
      "train loss:0.06593917741833843\n",
      "train loss:0.00573995963448303\n",
      "train loss:0.0074330265915754715\n",
      "train loss:0.019766355970385514\n",
      "train loss:0.018358040172156257\n",
      "train loss:0.021893230883948095\n",
      "train loss:0.015405262707595386\n",
      "train loss:0.009178719096530064\n",
      "train loss:0.01952674637965543\n",
      "train loss:0.021155779276429976\n",
      "train loss:0.014409362165535223\n",
      "train loss:0.028707899511475975\n",
      "train loss:0.00677253842628604\n",
      "train loss:0.021328676542556012\n",
      "train loss:0.011979390188236046\n",
      "train loss:0.01168058997020922\n",
      "train loss:0.007925927001438092\n",
      "train loss:0.00851355346158702\n",
      "train loss:0.08508072803416156\n",
      "train loss:0.026166007921083336\n",
      "train loss:0.007123364392466339\n",
      "train loss:0.0362765565228856\n",
      "train loss:0.006807912994555202\n",
      "train loss:0.00990822932256004\n",
      "train loss:0.016557775143950012\n",
      "train loss:0.020966800601836658\n",
      "train loss:0.012138689230475008\n",
      "train loss:0.03613634097285917\n",
      "train loss:0.010279703108921075\n",
      "train loss:0.01496230100521217\n",
      "train loss:0.020630779902475624\n",
      "train loss:0.011959172345313246\n",
      "train loss:0.013963449469437943\n",
      "train loss:0.007319717338723126\n",
      "train loss:0.06964136322918174\n",
      "train loss:0.13168729953584443\n",
      "train loss:0.012342535033425995\n",
      "train loss:0.0022927184876132467\n",
      "train loss:0.015030831749189583\n",
      "train loss:0.018137280591126327\n",
      "train loss:0.031195352108010558\n",
      "train loss:0.006175213093313908\n",
      "train loss:0.007386065592421604\n",
      "train loss:0.010370205153632205\n",
      "train loss:0.011966331626540053\n",
      "train loss:0.020479567150985964\n",
      "train loss:0.003418471416566304\n",
      "train loss:0.002247524229349147\n",
      "train loss:0.05012298149556862\n",
      "train loss:0.0196639806031916\n",
      "train loss:0.020483449471004046\n",
      "train loss:0.005948035677178574\n",
      "train loss:0.008801879810705078\n",
      "train loss:0.011631780839605562\n",
      "train loss:0.013103681942601173\n",
      "train loss:0.045405862505079275\n",
      "train loss:0.03617444220842582\n",
      "train loss:0.006572261977222076\n",
      "train loss:0.03189078905828196\n",
      "train loss:0.005211790617129481\n",
      "train loss:0.01530001712390785\n",
      "train loss:0.013344305594400044\n",
      "train loss:0.018068504602897165\n",
      "train loss:0.0242187366183993\n",
      "train loss:0.0054734825721125206\n",
      "train loss:0.01770847827961387\n",
      "train loss:0.011746244369346298\n",
      "train loss:0.013010633523173398\n",
      "train loss:0.024671498899875383\n",
      "train loss:0.013802982212903363\n",
      "train loss:0.047829922269007986\n",
      "train loss:0.01509973097741305\n",
      "train loss:0.011965122607129485\n",
      "train loss:0.0033945508471940307\n",
      "train loss:0.049639298870853554\n",
      "train loss:0.03437455107203752\n",
      "train loss:0.0047339019732586755\n",
      "train loss:0.041373859763552207\n",
      "train loss:0.014843535419754073\n",
      "train loss:0.012679521404195138\n",
      "train loss:0.005640885490207977\n",
      "train loss:0.008266599159281476\n",
      "train loss:0.01411663117763558\n",
      "train loss:0.008353420964265773\n",
      "train loss:0.008537864518013182\n",
      "train loss:0.03304281085107344\n",
      "train loss:0.0013773602717836303\n",
      "train loss:0.008864698742472442\n",
      "train loss:0.004913318634716402\n",
      "train loss:0.01737572488963583\n",
      "train loss:0.02072586825041606\n",
      "train loss:0.03553666897010045\n",
      "train loss:0.025345360278195794\n",
      "train loss:0.016226461161619358\n",
      "train loss:0.004411281364379519\n",
      "train loss:0.022822945100449833\n",
      "train loss:0.00523409408457972\n",
      "train loss:0.05249681444003057\n",
      "train loss:0.006498132819800201\n",
      "train loss:0.009315688637719399\n",
      "train loss:0.02606605979377397\n",
      "train loss:0.015589229466428458\n",
      "train loss:0.007649299352150723\n",
      "train loss:0.011943039494446844\n",
      "train loss:0.047903380823451525\n",
      "train loss:0.009019448318031862\n",
      "train loss:0.01057921732597096\n",
      "train loss:0.011020051040631237\n",
      "train loss:0.007730264694230853\n",
      "train loss:0.01582446446053578\n",
      "train loss:0.024720624320620613\n",
      "train loss:0.008453716738677054\n",
      "train loss:0.016943360752084028\n",
      "train loss:0.003857508190948863\n",
      "train loss:0.0033984046423860765\n",
      "train loss:0.009965958157455298\n",
      "train loss:0.016426049229781442\n",
      "train loss:0.006852185923916499\n",
      "train loss:0.005763139502836568\n",
      "train loss:0.015304068411476192\n",
      "train loss:0.003148628366642282\n",
      "train loss:0.07550075219632349\n",
      "train loss:0.03293434396416515\n",
      "train loss:0.010598929312089061\n",
      "train loss:0.02085134226251262\n",
      "train loss:0.013117159837571883\n",
      "train loss:0.017784821304684114\n",
      "train loss:0.014735111520588522\n",
      "train loss:0.02356899592520115\n",
      "train loss:0.0039216158337231286\n",
      "train loss:0.011834216281891826\n",
      "train loss:0.002978199721751816\n",
      "train loss:0.11316050178884135\n",
      "train loss:0.0036714377177734184\n",
      "train loss:0.05415413563754551\n",
      "train loss:0.027321052996658803\n",
      "train loss:0.012978061478093566\n",
      "train loss:0.002877443513807153\n",
      "train loss:0.008874814016305294\n",
      "train loss:0.0043987291562732865\n",
      "train loss:0.0024057383569593095\n",
      "train loss:0.003008827095917523\n",
      "train loss:0.01598733894456005\n",
      "train loss:0.06968704621210647\n",
      "train loss:0.00984233202951159\n",
      "train loss:0.014236399494310159\n",
      "train loss:0.027959067047575982\n",
      "train loss:0.07152476253700746\n",
      "train loss:0.006651689169492016\n",
      "train loss:0.006127490965517425\n",
      "train loss:0.011076403746908624\n",
      "train loss:0.012124906167479245\n",
      "train loss:0.012670176967699332\n",
      "train loss:0.009950513232354753\n",
      "train loss:0.006329336716329668\n",
      "train loss:0.016271857868514716\n",
      "train loss:0.012657884654918712\n",
      "train loss:0.018945085977497327\n",
      "train loss:0.01953646709405359\n",
      "train loss:0.011625096351772356\n",
      "train loss:0.004544897914054467\n",
      "train loss:0.0024857623852691723\n",
      "train loss:0.011364983634545444\n",
      "train loss:0.015590552379706267\n",
      "train loss:0.004776676078824848\n",
      "train loss:0.00954962693139577\n",
      "train loss:0.012404268964771314\n",
      "train loss:0.006396638172677437\n",
      "train loss:0.016026340537594906\n",
      "train loss:0.02118860817404449\n",
      "train loss:0.02074588036248444\n",
      "train loss:0.0073261815658398855\n",
      "train loss:0.01595885485541788\n",
      "train loss:0.015303236463036907\n",
      "train loss:0.006391104549771332\n",
      "train loss:0.004775776813725355\n",
      "train loss:0.014203867690603389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013182664019131995\n",
      "train loss:0.04278195681832048\n",
      "train loss:0.016085939702129223\n",
      "train loss:0.004070813127851925\n",
      "train loss:0.005735970213598004\n",
      "train loss:0.032184338774875934\n",
      "train loss:0.009165978147298389\n",
      "train loss:0.043303850370727426\n",
      "train loss:0.0670552840389796\n",
      "train loss:0.005507917796688125\n",
      "train loss:0.021814405360287826\n",
      "train loss:0.01773905624433711\n",
      "=== epoch:8, train acc:0.993, test acc:0.983 ===\n",
      "train loss:0.01235304459253493\n",
      "train loss:0.006095411355283837\n",
      "train loss:0.005986125279169519\n",
      "train loss:0.011541127445045263\n",
      "train loss:0.0015224086793332481\n",
      "train loss:0.024487926582246966\n",
      "train loss:0.013372959405474106\n",
      "train loss:0.012180383603248364\n",
      "train loss:0.00949995894403191\n",
      "train loss:0.009571831914382673\n",
      "train loss:0.0030556366772656967\n",
      "train loss:0.036839956050231104\n",
      "train loss:0.031163015134830222\n",
      "train loss:0.06554441639173074\n",
      "train loss:0.008138155907797895\n",
      "train loss:0.011608104671682284\n",
      "train loss:0.005683662902053249\n",
      "train loss:0.0036922536541968104\n",
      "train loss:0.03477921035448043\n",
      "train loss:0.027829571913477506\n",
      "train loss:0.011829427587450522\n",
      "train loss:0.00892892537006207\n",
      "train loss:0.002419750655107355\n",
      "train loss:0.020256400087993613\n",
      "train loss:0.0023461523952747042\n",
      "train loss:0.011111885510997151\n",
      "train loss:0.01594879736041829\n",
      "train loss:0.014594430663249645\n",
      "train loss:0.0030126620624123875\n",
      "train loss:0.006834885856743977\n",
      "train loss:0.0025723475639719815\n",
      "train loss:0.05458664368274105\n",
      "train loss:0.027782910357467556\n",
      "train loss:0.008791871217564551\n",
      "train loss:0.021086617483577697\n",
      "train loss:0.024438791575966245\n",
      "train loss:0.01810928880790229\n",
      "train loss:0.051094703491974446\n",
      "train loss:0.009415259676134762\n",
      "train loss:0.003040877804906575\n",
      "train loss:0.007381905213034402\n",
      "train loss:0.03516769150094014\n",
      "train loss:0.0123301534352648\n",
      "train loss:0.012461841556982647\n",
      "train loss:0.006077375245927249\n",
      "train loss:0.011790397610207726\n",
      "train loss:0.00211897471816177\n",
      "train loss:0.033900117421557414\n",
      "train loss:0.017442235478203966\n",
      "train loss:0.009862499207328951\n",
      "train loss:0.013073922744286127\n",
      "train loss:0.0037668863123743895\n",
      "train loss:0.034555574728491516\n",
      "train loss:0.009567863923302835\n",
      "train loss:0.05614860630130876\n",
      "train loss:0.02106994983094206\n",
      "train loss:0.020383227974831795\n",
      "train loss:0.005742284557961541\n",
      "train loss:0.002695106443080735\n",
      "train loss:0.015473252579640846\n",
      "train loss:0.03956631502037779\n",
      "train loss:0.00736767472092557\n",
      "train loss:0.016601833086048835\n",
      "train loss:0.002815349990713639\n",
      "train loss:0.014083603043613217\n",
      "train loss:0.018046572710043535\n",
      "train loss:0.007323471313653842\n",
      "train loss:0.04006424860600859\n",
      "train loss:0.0044183815570649175\n",
      "train loss:0.008223990096843832\n",
      "train loss:0.020328416898135127\n",
      "train loss:0.008550205913934673\n",
      "train loss:0.004972195068794143\n",
      "train loss:0.014509183560731127\n",
      "train loss:0.017242009005885354\n",
      "train loss:0.01490402427281196\n",
      "train loss:0.018072942762820364\n",
      "train loss:0.006993842220262163\n",
      "train loss:0.0042197409685836565\n",
      "train loss:0.0056819785595613025\n",
      "train loss:0.005279101123373123\n",
      "train loss:0.0187351859585505\n",
      "train loss:0.009411693810956325\n",
      "train loss:0.023893810779443952\n",
      "train loss:0.0237719325776929\n",
      "train loss:0.01171220460031072\n",
      "train loss:0.03777015666503333\n",
      "train loss:0.0021337684746968923\n",
      "train loss:0.008997550140784474\n",
      "train loss:0.016034652592904822\n",
      "train loss:0.00858544296736509\n",
      "train loss:0.017774494085898\n",
      "train loss:0.01605735719136035\n",
      "train loss:0.005153517039066624\n",
      "train loss:0.003334545121135094\n",
      "train loss:0.009841232688095334\n",
      "train loss:0.02240040606660041\n",
      "train loss:0.02063334945501575\n",
      "train loss:0.016923921910181727\n",
      "train loss:0.008265292571001354\n",
      "train loss:0.005431615959810288\n",
      "train loss:0.03369911190544888\n",
      "train loss:0.000956010253275023\n",
      "train loss:0.009393997937669556\n",
      "train loss:0.005727924309346223\n",
      "train loss:0.004069822757535042\n",
      "train loss:0.023342606385939914\n",
      "train loss:0.0021433375276876995\n",
      "train loss:0.009798762967632971\n",
      "train loss:0.040154908228848506\n",
      "train loss:0.014345188628799245\n",
      "train loss:0.006152609850731474\n",
      "train loss:0.012951081691113671\n",
      "train loss:0.006041110464231011\n",
      "train loss:0.009656016065522903\n",
      "train loss:0.005130309595836218\n",
      "train loss:0.061301664225593716\n",
      "train loss:0.0034721219689424327\n",
      "train loss:0.009882098587722106\n",
      "train loss:0.04671015592017566\n",
      "train loss:0.03019349949033602\n",
      "train loss:0.015850999111992486\n",
      "train loss:0.02599291153769641\n",
      "train loss:0.03022991056110623\n",
      "train loss:0.003213558753644672\n",
      "train loss:0.04239101000436213\n",
      "train loss:0.013196209754000779\n",
      "train loss:0.0027289109351684433\n",
      "train loss:0.005093183417338495\n",
      "train loss:0.0032236181308325546\n",
      "train loss:0.03138740926436346\n",
      "train loss:0.005836514768350068\n",
      "train loss:0.017368594009110554\n",
      "train loss:0.007349919591183156\n",
      "train loss:0.024267899030005955\n",
      "train loss:0.020486278609095306\n",
      "train loss:0.011545583499355399\n",
      "train loss:0.009579194258615403\n",
      "train loss:0.04386767704780079\n",
      "train loss:0.005351901886257945\n",
      "train loss:0.0034142098988355456\n",
      "train loss:0.004932858825450462\n",
      "train loss:0.004437427920429215\n",
      "train loss:0.003463739216635278\n",
      "train loss:0.010800370872744602\n",
      "train loss:0.003897874216972882\n",
      "train loss:0.0024105795043398164\n",
      "train loss:0.04713643617600003\n",
      "train loss:0.009116813909006196\n",
      "train loss:0.008480602861883265\n",
      "train loss:0.014329771393530099\n",
      "train loss:0.007578478384183014\n",
      "train loss:0.006248898387777943\n",
      "train loss:0.015841992026943794\n",
      "train loss:0.011296090421073735\n",
      "train loss:0.009662677380091897\n",
      "train loss:0.0016592561461124138\n",
      "train loss:0.002115570668151982\n",
      "train loss:0.010219553606585495\n",
      "train loss:0.006461109500326692\n",
      "train loss:0.015160222420947602\n",
      "train loss:0.0030641028481838296\n",
      "train loss:0.004067734810474718\n",
      "train loss:0.010226207591320608\n",
      "train loss:0.01254920220867524\n",
      "train loss:0.0024757886200842834\n",
      "train loss:0.004455622466314245\n",
      "train loss:0.0016045150077629788\n",
      "train loss:0.017930550527005255\n",
      "train loss:0.004079834078221589\n",
      "train loss:0.005872633852463794\n",
      "train loss:0.010812320776155647\n",
      "train loss:0.012157355023170571\n",
      "train loss:0.022760878686759987\n",
      "train loss:0.014014388939752962\n",
      "train loss:0.016711560330644457\n",
      "train loss:0.001309421823735654\n",
      "train loss:0.013346637728155183\n",
      "train loss:0.010723760823628699\n",
      "train loss:0.003168921538722356\n",
      "train loss:0.009462888254904146\n",
      "train loss:0.024502064074371197\n",
      "train loss:0.01348781459358438\n",
      "train loss:0.006596262978822523\n",
      "train loss:0.02939052070391807\n",
      "train loss:0.010180225503335994\n",
      "train loss:0.014723759608266789\n",
      "train loss:0.007234082628599699\n",
      "train loss:0.0078002373590021065\n",
      "train loss:0.001834987740977781\n",
      "train loss:0.03227580841476403\n",
      "train loss:0.008560071339555135\n",
      "train loss:0.0037293974565237612\n",
      "train loss:0.007545544518016001\n",
      "train loss:0.017499564550375733\n",
      "train loss:0.023544315710519247\n",
      "train loss:0.04871343960723054\n",
      "train loss:0.04374738348410662\n",
      "train loss:0.021116892162130186\n",
      "train loss:0.02884780895920778\n",
      "train loss:0.003579955479209231\n",
      "train loss:0.009328335953920753\n",
      "train loss:0.0243659803969642\n",
      "train loss:0.006852431716296371\n",
      "train loss:0.0048689900810450545\n",
      "train loss:0.01517916399202146\n",
      "train loss:0.009982367968160136\n",
      "train loss:0.017840660689198196\n",
      "train loss:0.025745607721550056\n",
      "train loss:0.002713354327609215\n",
      "train loss:0.014092877840918297\n",
      "train loss:0.028704236512514084\n",
      "train loss:0.006878355196151781\n",
      "train loss:0.008313068194829243\n",
      "train loss:0.00793292957871676\n",
      "train loss:0.060024204177920294\n",
      "train loss:0.004384694732430406\n",
      "train loss:0.014202423279300191\n",
      "train loss:0.012457200442092427\n",
      "train loss:0.0017038360750699253\n",
      "train loss:0.008789780229365635\n",
      "train loss:0.012029228776473649\n",
      "train loss:0.003812563199738411\n",
      "train loss:0.015485023967860357\n",
      "train loss:0.02806983051285932\n",
      "train loss:0.05389566509795673\n",
      "train loss:0.004112478448056817\n",
      "train loss:0.04747044950490201\n",
      "train loss:0.01257684916221699\n",
      "train loss:0.012663163898996138\n",
      "train loss:0.009140194761437072\n",
      "train loss:0.005443043202813116\n",
      "train loss:0.011038299101838771\n",
      "train loss:0.002358065624683429\n",
      "train loss:0.0064102421052239286\n",
      "train loss:0.0021020420862083453\n",
      "train loss:0.007927729510573286\n",
      "train loss:0.01733699395325865\n",
      "train loss:0.020353302966040047\n",
      "train loss:0.002619347237675096\n",
      "train loss:0.05005048184470054\n",
      "train loss:0.02302383628527733\n",
      "train loss:0.019515402370423623\n",
      "train loss:0.016742172941369603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012496449197134336\n",
      "train loss:0.048832155872028264\n",
      "train loss:0.03318647849520163\n",
      "train loss:0.022770618068413982\n",
      "train loss:0.007151655587148423\n",
      "train loss:0.016506510393213866\n",
      "train loss:0.031161600188186776\n",
      "train loss:0.02670567110997616\n",
      "train loss:0.016854399852977774\n",
      "train loss:0.008995544734770058\n",
      "train loss:0.035279691469055505\n",
      "train loss:0.01161508487580134\n",
      "train loss:0.023407028597354235\n",
      "train loss:0.048752390483738264\n",
      "train loss:0.00647421877464592\n",
      "train loss:0.016981412349533577\n",
      "train loss:0.005301177264402422\n",
      "train loss:0.018126796320863444\n",
      "train loss:0.01943500142806955\n",
      "train loss:0.004383338311786582\n",
      "train loss:0.02586347001031347\n",
      "train loss:0.0064006672628298625\n",
      "train loss:0.01163127716463596\n",
      "train loss:0.03296566962684591\n",
      "train loss:0.03010500687689885\n",
      "train loss:0.007172512793605574\n",
      "train loss:0.0062253772705926115\n",
      "train loss:0.007184714315145248\n",
      "train loss:0.019202895660494587\n",
      "train loss:0.022915830031456856\n",
      "train loss:0.0019263099140056927\n",
      "train loss:0.0055608863579655245\n",
      "train loss:0.0032883733459893273\n",
      "train loss:0.013252318235838778\n",
      "train loss:0.01694662796630956\n",
      "train loss:0.0037758555419265044\n",
      "train loss:0.015071746025144448\n",
      "train loss:0.023276316477347927\n",
      "train loss:0.019887237261962513\n",
      "train loss:0.02286455326649806\n",
      "train loss:0.03934952916506542\n",
      "train loss:0.004777852126882292\n",
      "train loss:0.002383762356662454\n",
      "train loss:0.012007877388788033\n",
      "train loss:0.006067058361593883\n",
      "train loss:0.0062354872765211285\n",
      "train loss:0.005513793935681815\n",
      "train loss:0.009718683203215088\n",
      "train loss:0.00741255374144495\n",
      "train loss:0.003478149997185633\n",
      "train loss:0.002436435515656706\n",
      "train loss:0.004930732555413225\n",
      "train loss:0.003806706071913074\n",
      "train loss:0.0025423552366962755\n",
      "train loss:0.0029026063269620905\n",
      "train loss:0.0032450023720623834\n",
      "train loss:0.019492340881078853\n",
      "train loss:0.010200663873628788\n",
      "train loss:0.014651074258634498\n",
      "train loss:0.003852617688759851\n",
      "train loss:0.030347109842387997\n",
      "train loss:0.007365118047541808\n",
      "train loss:0.046415402841537154\n",
      "train loss:0.05407555295049189\n",
      "train loss:0.00249991448302188\n",
      "train loss:0.0004808958961591557\n",
      "train loss:0.06796301147789972\n",
      "train loss:0.013669253694595998\n",
      "train loss:0.012877221364035211\n",
      "train loss:0.019940794004912648\n",
      "train loss:0.005602301729535019\n",
      "train loss:0.03215847146446288\n",
      "train loss:0.005428096916023964\n",
      "train loss:0.051417388749585714\n",
      "train loss:0.059888921147679346\n",
      "train loss:0.004608861125305862\n",
      "train loss:0.005052556259432859\n",
      "train loss:0.010279840166125154\n",
      "train loss:0.0031213734345253543\n",
      "train loss:0.004381328024470027\n",
      "train loss:0.0036052033400468904\n",
      "train loss:0.0058022939614250715\n",
      "train loss:0.0017897922681108084\n",
      "train loss:0.002392074719630217\n",
      "train loss:0.043203437999359634\n",
      "train loss:0.013573807679995028\n",
      "train loss:0.003354882324212642\n",
      "train loss:0.010793416682483176\n",
      "train loss:0.05619037766750295\n",
      "train loss:0.013839539025153738\n",
      "train loss:0.020208435067594063\n",
      "train loss:0.017505368315919933\n",
      "train loss:0.005956363512330112\n",
      "train loss:0.0051260283645774615\n",
      "train loss:0.021556628196962368\n",
      "train loss:0.005223347382849935\n",
      "train loss:0.011634954939119313\n",
      "train loss:0.022249631700596777\n",
      "train loss:0.003636150140760977\n",
      "train loss:0.004273170013491705\n",
      "train loss:0.0036932506095448043\n",
      "train loss:0.017200540979705872\n",
      "train loss:0.05420552128095414\n",
      "train loss:0.015502638702857303\n",
      "train loss:0.005432307772742126\n",
      "train loss:0.005798688571481949\n",
      "train loss:0.016866085221959884\n",
      "train loss:0.006835896056245964\n",
      "train loss:0.015935909949362462\n",
      "train loss:0.01616222195878473\n",
      "train loss:0.001567621942235558\n",
      "train loss:0.02351011695246557\n",
      "train loss:0.01683798045776667\n",
      "train loss:0.00900007870642229\n",
      "train loss:0.005122698636957619\n",
      "train loss:0.004217242086992661\n",
      "train loss:0.02923101583467564\n",
      "train loss:0.016363969272523232\n",
      "train loss:0.005243788748106037\n",
      "train loss:0.007172631215965444\n",
      "train loss:0.0031172178608646186\n",
      "train loss:0.15410935676164741\n",
      "train loss:0.005521138320670515\n",
      "train loss:0.011746063133552148\n",
      "train loss:0.04729317740965604\n",
      "train loss:0.022589154652852616\n",
      "train loss:0.0036839145357301095\n",
      "train loss:0.011370587719739443\n",
      "train loss:0.0027199900277164253\n",
      "train loss:0.02726086335178565\n",
      "train loss:0.009828915370500638\n",
      "train loss:0.009057969476307047\n",
      "train loss:0.0210681130711342\n",
      "train loss:0.05042920557792689\n",
      "train loss:0.0026192207304604116\n",
      "train loss:0.0366509788385546\n",
      "train loss:0.003350618306776195\n",
      "train loss:0.010710184970293387\n",
      "train loss:0.04203336602772313\n",
      "train loss:0.005526376269081409\n",
      "train loss:0.018410364946259698\n",
      "train loss:0.010174223381469902\n",
      "train loss:0.007027408503989507\n",
      "train loss:0.006969604059484407\n",
      "train loss:0.007010617097545163\n",
      "train loss:0.0030168735505800544\n",
      "train loss:0.007379530442007094\n",
      "train loss:0.03639736713773449\n",
      "train loss:0.010107501441173505\n",
      "train loss:0.004577163345411882\n",
      "train loss:0.05510437719430449\n",
      "train loss:0.016293094482502494\n",
      "train loss:0.00914887242633544\n",
      "train loss:0.010059174590827336\n",
      "train loss:0.0033136157455304805\n",
      "train loss:0.003424899142987089\n",
      "train loss:0.003420264935456645\n",
      "train loss:0.031500171247131566\n",
      "train loss:0.006841301477813742\n",
      "train loss:0.002730920399753193\n",
      "train loss:0.009124238192401662\n",
      "train loss:0.02443589553174273\n",
      "train loss:0.028234547040109175\n",
      "train loss:0.005592672138898853\n",
      "train loss:0.0029694512800434486\n",
      "train loss:0.005450560982325043\n",
      "train loss:0.040031997175348374\n",
      "train loss:0.01076541811025236\n",
      "train loss:0.01220934581555122\n",
      "train loss:0.013312352891963676\n",
      "train loss:0.008503730652481578\n",
      "train loss:0.010098278879057261\n",
      "train loss:0.008989190502713278\n",
      "train loss:0.0064039840124222305\n",
      "train loss:0.0016222931843986946\n",
      "train loss:0.009173255019562338\n",
      "train loss:0.007017638683159435\n",
      "train loss:0.014781279076214026\n",
      "train loss:0.0036355234761851086\n",
      "train loss:0.02012824593290189\n",
      "train loss:0.021248672265878347\n",
      "train loss:0.003465408086642942\n",
      "train loss:0.033111502575648294\n",
      "train loss:0.0031889447969719207\n",
      "train loss:0.021620565040215037\n",
      "train loss:0.006653961807332829\n",
      "train loss:0.015023185262218961\n",
      "train loss:0.008084025820420228\n",
      "train loss:0.013725675913261412\n",
      "train loss:0.002422287890319396\n",
      "train loss:0.016042154275624255\n",
      "train loss:0.005478819689905788\n",
      "train loss:0.03787198460888112\n",
      "train loss:0.0030250219410248185\n",
      "train loss:0.011162845196060074\n",
      "train loss:0.0035553853517195145\n",
      "train loss:0.011348028817111945\n",
      "train loss:0.002460282549632041\n",
      "train loss:0.017671925552229267\n",
      "train loss:0.015941251745730398\n",
      "train loss:0.008742799678442293\n",
      "train loss:0.023658152487296413\n",
      "train loss:0.00971097484707189\n",
      "train loss:0.009333110753735689\n",
      "train loss:0.016151316357208168\n",
      "train loss:0.010193333110722697\n",
      "train loss:0.0032824503828674766\n",
      "train loss:0.002419770630462845\n",
      "train loss:0.0029423826667425873\n",
      "train loss:0.003878574376954741\n",
      "train loss:0.01763587701996833\n",
      "train loss:0.005580788055549145\n",
      "train loss:0.006791718911071994\n",
      "train loss:0.003519357553850286\n",
      "train loss:0.005139703284073878\n",
      "train loss:0.024436944339225667\n",
      "train loss:0.049153726707428805\n",
      "train loss:0.027744044470899384\n",
      "train loss:0.013944184828259178\n",
      "train loss:0.014738353762864222\n",
      "train loss:0.008941239532481653\n",
      "train loss:0.0070776282316803414\n",
      "train loss:0.011104192902711479\n",
      "train loss:0.00771072996864359\n",
      "train loss:0.0034507671934777685\n",
      "train loss:0.012828606209579924\n",
      "train loss:0.0028666186699550394\n",
      "train loss:0.009904073798037474\n",
      "train loss:0.007019234489662903\n",
      "train loss:0.0029831845967460188\n",
      "train loss:0.09201905386212751\n",
      "train loss:0.0022070872881477855\n",
      "train loss:0.007190583505842888\n",
      "train loss:0.019491941323467942\n",
      "train loss:0.0018412655279551387\n",
      "train loss:0.023589483098638352\n",
      "train loss:0.006651016738467915\n",
      "train loss:0.0066007119871416145\n",
      "train loss:0.020549726971820635\n",
      "train loss:0.008289085710283021\n",
      "train loss:0.006101208522410711\n",
      "train loss:0.003564084679903823\n",
      "train loss:0.008113550932148699\n",
      "train loss:0.004737542719475824\n",
      "train loss:0.0029067325033014665\n",
      "train loss:0.01623408393853575\n",
      "train loss:0.003800566867232052\n",
      "train loss:0.005113320783545606\n",
      "train loss:0.007876773472631254\n",
      "train loss:0.04101887354696715\n",
      "train loss:0.017222078929079013\n",
      "train loss:0.010219888643985623\n",
      "train loss:0.015257539371503481\n",
      "train loss:0.0066308691611374326\n",
      "train loss:0.0018812234168053504\n",
      "train loss:0.012579717608859713\n",
      "train loss:0.0045501029161069215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011708643293552921\n",
      "train loss:0.016292014117165438\n",
      "train loss:0.006391175378129242\n",
      "train loss:0.007083667401646925\n",
      "train loss:0.044124183299327005\n",
      "train loss:0.004831730950112067\n",
      "train loss:0.009485164727087426\n",
      "train loss:0.00816717116372019\n",
      "train loss:0.007535022564862127\n",
      "train loss:0.0348338760555533\n",
      "train loss:0.0033275644969887686\n",
      "train loss:0.034285151417500874\n",
      "train loss:0.06594026419671326\n",
      "train loss:0.0019375568509376806\n",
      "train loss:0.004638683745625711\n",
      "train loss:0.009749885167949578\n",
      "train loss:0.0029892833276866115\n",
      "train loss:0.002975150196695411\n",
      "train loss:0.005329944427735456\n",
      "train loss:0.010880394169193255\n",
      "train loss:0.008075629159003912\n",
      "train loss:0.0357639959275072\n",
      "train loss:0.00459709366873941\n",
      "train loss:0.017403173110359573\n",
      "train loss:0.00787248034381052\n",
      "train loss:0.03126372063443595\n",
      "train loss:0.026514960054942683\n",
      "train loss:0.0051821833025245505\n",
      "train loss:0.03294183942912345\n",
      "train loss:0.02618281108987308\n",
      "train loss:0.012634870087146595\n",
      "train loss:0.018237199513307635\n",
      "train loss:0.0036786048627102607\n",
      "train loss:0.021328892561358895\n",
      "train loss:0.005359513461013704\n",
      "train loss:0.029433400225654025\n",
      "train loss:0.023755552588343533\n",
      "train loss:0.02415998720699768\n",
      "train loss:0.01371126772529145\n",
      "train loss:0.012416970580736555\n",
      "train loss:0.0032135468874198814\n",
      "train loss:0.013165047184915417\n",
      "train loss:0.01261906963820914\n",
      "train loss:0.06409766062549486\n",
      "train loss:0.011898565495904534\n",
      "train loss:0.007492629603037997\n",
      "train loss:0.025257998753639054\n",
      "train loss:0.0006417585705427269\n",
      "train loss:0.016317610071194116\n",
      "train loss:0.02271040599035845\n",
      "train loss:0.007208862587284863\n",
      "train loss:0.004108817155466625\n",
      "train loss:0.006479468748534073\n",
      "train loss:0.00036850952797431416\n",
      "train loss:0.010273949092619814\n",
      "train loss:0.01957714788301323\n",
      "train loss:0.0044630815904434925\n",
      "train loss:0.005471246890672849\n",
      "train loss:0.007453541289681018\n",
      "train loss:0.01927128322376878\n",
      "train loss:0.008185756647868503\n",
      "train loss:0.0257874673388786\n",
      "train loss:0.003801328855156807\n",
      "train loss:0.004545953888784678\n",
      "train loss:0.004574245421215359\n",
      "train loss:0.008061668877779059\n",
      "train loss:0.015099533938464313\n",
      "train loss:0.02074228189314128\n",
      "train loss:0.003351294713062651\n",
      "train loss:0.015119551194012305\n",
      "train loss:0.004402029093251747\n",
      "train loss:0.005884641377011966\n",
      "train loss:0.0022053751464335115\n",
      "train loss:0.05519437167405798\n",
      "train loss:0.02207116058209553\n",
      "train loss:0.002238677121529093\n",
      "train loss:0.008937404233159571\n",
      "train loss:0.002900988029206587\n",
      "train loss:0.02865897417822296\n",
      "train loss:0.04005069273025174\n",
      "train loss:0.0019224927944018093\n",
      "train loss:0.007624380234633899\n",
      "train loss:0.004869217400379887\n",
      "train loss:0.012806384906311774\n",
      "train loss:0.003888953656979326\n",
      "train loss:0.005838462837603753\n",
      "train loss:0.01197449836481127\n",
      "train loss:0.013842552877895955\n",
      "train loss:0.03352692869798328\n",
      "train loss:0.015299362220276634\n",
      "train loss:0.019102373446540304\n",
      "train loss:0.007673387374149168\n",
      "train loss:0.0015271749415509642\n",
      "train loss:0.00994746310407107\n",
      "train loss:0.008058877451570494\n",
      "train loss:0.022391816895389948\n",
      "train loss:0.003790232441454398\n",
      "train loss:0.0018821448471741677\n",
      "train loss:0.006297605500784025\n",
      "=== epoch:9, train acc:0.992, test acc:0.988 ===\n",
      "train loss:0.009418955335885871\n",
      "train loss:0.0020648903872263562\n",
      "train loss:0.003450284371320952\n",
      "train loss:0.04532150584780125\n",
      "train loss:0.005367256118300988\n",
      "train loss:0.0070547750078874365\n",
      "train loss:0.02547018444750328\n",
      "train loss:0.00290746254681261\n",
      "train loss:0.0025623920288601674\n",
      "train loss:0.011130022242441443\n",
      "train loss:0.0053253251067125395\n",
      "train loss:0.014447812333592389\n",
      "train loss:0.0004465764741934557\n",
      "train loss:0.08054207732399368\n",
      "train loss:0.014545666578706136\n",
      "train loss:0.0014047629700793879\n",
      "train loss:0.002838328317445371\n",
      "train loss:0.012015885103611562\n",
      "train loss:0.003885068420088131\n",
      "train loss:0.008089802138966637\n",
      "train loss:0.0022178540517873335\n",
      "train loss:0.011854332110030239\n",
      "train loss:0.04072520937767503\n",
      "train loss:0.011163072805052764\n",
      "train loss:0.007056175517765621\n",
      "train loss:0.013832998904143643\n",
      "train loss:0.005455205544127001\n",
      "train loss:0.0017217777269341985\n",
      "train loss:0.014937985704301575\n",
      "train loss:0.008159410880189833\n",
      "train loss:0.016782002225745565\n",
      "train loss:0.0022913299277825205\n",
      "train loss:0.05445885076418419\n",
      "train loss:0.007721521265592391\n",
      "train loss:0.006366894665781591\n",
      "train loss:0.007821085229488782\n",
      "train loss:0.00749627219493\n",
      "train loss:0.005874953105430951\n",
      "train loss:0.009727805876524144\n",
      "train loss:0.006347413758831961\n",
      "train loss:0.0060854438715867605\n",
      "train loss:0.020777209538084804\n",
      "train loss:0.017641945770946518\n",
      "train loss:0.01453707162949885\n",
      "train loss:0.0030245449058810252\n",
      "train loss:0.0023232829828602527\n",
      "train loss:0.010767932965587168\n",
      "train loss:0.012079721973036332\n",
      "train loss:0.009060028715883014\n",
      "train loss:0.0062949095408777744\n",
      "train loss:0.012812348067194905\n",
      "train loss:0.004845377258633275\n",
      "train loss:0.015489983891517001\n",
      "train loss:0.0053881642509682895\n",
      "train loss:0.004178470603179153\n",
      "train loss:0.0032690085555733247\n",
      "train loss:0.010521393196593764\n",
      "train loss:0.003895703920081161\n",
      "train loss:0.0016094060303312632\n",
      "train loss:0.001224150205634897\n",
      "train loss:0.006467013073671717\n",
      "train loss:0.11297954199418445\n",
      "train loss:0.006883418818911647\n",
      "train loss:0.09123019124874589\n",
      "train loss:0.004006112419945519\n",
      "train loss:0.005960629561505253\n",
      "train loss:0.005655574851390628\n",
      "train loss:0.02159412938552771\n",
      "train loss:0.008480433493181791\n",
      "train loss:0.008143803641024993\n",
      "train loss:0.0029432319794066033\n",
      "train loss:0.005216159359956412\n",
      "train loss:0.007320540546261987\n",
      "train loss:0.010994977774532455\n",
      "train loss:0.008436496987665085\n",
      "train loss:0.01416566635937022\n",
      "train loss:0.001831650858067765\n",
      "train loss:0.009383598403294963\n",
      "train loss:0.03436787438218714\n",
      "train loss:0.03156529499179682\n",
      "train loss:0.047249090661610024\n",
      "train loss:0.008747439472154851\n",
      "train loss:0.016573819771306217\n",
      "train loss:0.010362196306320284\n",
      "train loss:0.0146222898248091\n",
      "train loss:0.015459357061058547\n",
      "train loss:0.006529558524179886\n",
      "train loss:0.0027656924270269005\n",
      "train loss:0.021635457571464393\n",
      "train loss:0.008391788546487158\n",
      "train loss:0.011178474727161238\n",
      "train loss:0.006080783921906942\n",
      "train loss:0.005641628016767862\n",
      "train loss:0.005606484670852558\n",
      "train loss:0.006695504448024048\n",
      "train loss:0.02254653226644858\n",
      "train loss:0.007269057933743995\n",
      "train loss:0.017480906799888667\n",
      "train loss:0.010829360427631385\n",
      "train loss:0.011983604941540544\n",
      "train loss:0.01689680687878956\n",
      "train loss:0.04588590177612671\n",
      "train loss:0.01859010604148011\n",
      "train loss:0.00465334035113014\n",
      "train loss:0.010654438008990696\n",
      "train loss:0.0071418827217499615\n",
      "train loss:0.01584258368976424\n",
      "train loss:0.013321521613078393\n",
      "train loss:0.020440386393408234\n",
      "train loss:0.004757786681013019\n",
      "train loss:0.007132083059249434\n",
      "train loss:0.0020382695830388283\n",
      "train loss:0.00336250322126943\n",
      "train loss:0.04828358074292576\n",
      "train loss:0.0039038003440534804\n",
      "train loss:0.006315178945281052\n",
      "train loss:0.048444226891385854\n",
      "train loss:0.003969079753655945\n",
      "train loss:0.006490820109441017\n",
      "train loss:0.011014939121569471\n",
      "train loss:0.01819525821065756\n",
      "train loss:0.0016229524051703148\n",
      "train loss:0.004274679628661833\n",
      "train loss:0.008992993223994373\n",
      "train loss:0.04355751094360074\n",
      "train loss:0.014859431736742566\n",
      "train loss:0.05619310479004403\n",
      "train loss:0.029538895654077798\n",
      "train loss:0.004300136308403589\n",
      "train loss:0.05415178082005403\n",
      "train loss:0.059395594395296715\n",
      "train loss:0.004622098597750789\n",
      "train loss:0.06428037456083578\n",
      "train loss:0.003918418708734446\n",
      "train loss:0.014757310765821947\n",
      "train loss:0.015172974647773885\n",
      "train loss:0.018577217540759913\n",
      "train loss:0.005861038641144276\n",
      "train loss:0.019230642109102622\n",
      "train loss:0.004389180880724544\n",
      "train loss:0.006810572388554248\n",
      "train loss:0.01052616984233806\n",
      "train loss:0.010877562468013923\n",
      "train loss:0.015430334399448999\n",
      "train loss:0.01718164150676894\n",
      "train loss:0.01583858095930093\n",
      "train loss:0.01182252660566853\n",
      "train loss:0.013364033076356306\n",
      "train loss:0.0049795400253939606\n",
      "train loss:0.006503659417395645\n",
      "train loss:0.004786436994938893\n",
      "train loss:0.005374903430162998\n",
      "train loss:0.004954473702092849\n",
      "train loss:0.04105069535649149\n",
      "train loss:0.006322203960918843\n",
      "train loss:0.004835815086566501\n",
      "train loss:0.004213571565360608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01756486470756117\n",
      "train loss:0.005006617498433616\n",
      "train loss:0.0052836946872498545\n",
      "train loss:0.008146395099905083\n",
      "train loss:0.01583120008096321\n",
      "train loss:0.004601851335032297\n",
      "train loss:0.03123911053069982\n",
      "train loss:0.022746772173843906\n",
      "train loss:0.017523753353900773\n",
      "train loss:0.013187342508923137\n",
      "train loss:0.0013109213376699509\n",
      "train loss:0.005766064637663515\n",
      "train loss:0.0043160322396008175\n",
      "train loss:0.027121253417954752\n",
      "train loss:0.01745683498232009\n",
      "train loss:0.005096604701420707\n",
      "train loss:0.016923427554438063\n",
      "train loss:0.007337487608681854\n",
      "train loss:0.021272209089204717\n",
      "train loss:0.005257091338329278\n",
      "train loss:0.00846427543148758\n",
      "train loss:0.001863208258608963\n",
      "train loss:0.009239309519049698\n",
      "train loss:0.015008298908276874\n",
      "train loss:0.012624283656316036\n",
      "train loss:0.018534085682878607\n",
      "train loss:0.006601853896750261\n",
      "train loss:0.0032926539410729778\n",
      "train loss:0.003047048877971195\n",
      "train loss:0.007421756634768279\n",
      "train loss:0.0047003795806716524\n",
      "train loss:0.029085303829715647\n",
      "train loss:0.008574976239120064\n",
      "train loss:0.011081489183854876\n",
      "train loss:0.011856576507403833\n",
      "train loss:0.02548089816373047\n",
      "train loss:0.013269024700722014\n",
      "train loss:0.011516755212298568\n",
      "train loss:0.027720447510022134\n",
      "train loss:0.003038643614858709\n",
      "train loss:0.0037066183783867005\n",
      "train loss:0.005672612329088402\n",
      "train loss:0.03266089800514341\n",
      "train loss:0.009300270789362635\n",
      "train loss:0.010449151349506119\n",
      "train loss:0.011980073320968612\n",
      "train loss:0.01086286904184922\n",
      "train loss:0.007508552972328466\n",
      "train loss:0.004670902904733019\n",
      "train loss:0.0024154698965526008\n",
      "train loss:0.015527054667293967\n",
      "train loss:0.0050763333887707575\n",
      "train loss:0.04427928361418244\n",
      "train loss:0.001346755952538688\n",
      "train loss:0.008737972110972044\n",
      "train loss:0.01164309566549431\n",
      "train loss:0.010896669207644743\n",
      "train loss:0.004546309206124877\n",
      "train loss:0.01920834458830927\n",
      "train loss:0.0011553575583782508\n",
      "train loss:0.01879168455714875\n",
      "train loss:0.01573431513340726\n",
      "train loss:0.0035228581574472235\n",
      "train loss:0.008593108356017325\n",
      "train loss:0.005053209961186116\n",
      "train loss:0.0022040797716525\n",
      "train loss:0.008159680942523282\n",
      "train loss:0.0076359913559108615\n",
      "train loss:0.007768981838664454\n",
      "train loss:0.006162959716169821\n",
      "train loss:0.020440376368817747\n",
      "train loss:0.024076756920264012\n",
      "train loss:0.008957784851123685\n",
      "train loss:0.002948545447832347\n",
      "train loss:0.0037945908718017484\n",
      "train loss:0.022915400556688947\n",
      "train loss:0.020991469620894033\n",
      "train loss:0.006528219710851362\n",
      "train loss:0.004245890559191873\n",
      "train loss:0.0021708925164400515\n",
      "train loss:0.005401763000798842\n",
      "train loss:0.008821087212770884\n",
      "train loss:0.019187696965145815\n",
      "train loss:0.005703750261284136\n",
      "train loss:0.003105637764794738\n",
      "train loss:0.008500091648671316\n",
      "train loss:0.0033601152965145385\n",
      "train loss:0.004990975107491462\n",
      "train loss:0.004166471985120612\n",
      "train loss:0.001385823382801927\n",
      "train loss:0.02514606077207592\n",
      "train loss:0.038865072232163476\n",
      "train loss:0.0010475967351912\n",
      "train loss:0.006118800745202835\n",
      "train loss:0.010545169124401142\n",
      "train loss:0.011967201257599668\n",
      "train loss:0.01695545765687074\n",
      "train loss:0.0016229747361251312\n",
      "train loss:0.0072284180768665395\n",
      "train loss:0.010389471613311748\n",
      "train loss:0.004433334051523676\n",
      "train loss:0.0011130128176186497\n",
      "train loss:0.018245962885492763\n",
      "train loss:0.0071179648268733355\n",
      "train loss:0.03258471083384323\n",
      "train loss:0.04869297813659461\n",
      "train loss:0.0018321557329876767\n",
      "train loss:0.005421257841981163\n",
      "train loss:0.0023705987488664665\n",
      "train loss:0.029028325898776765\n",
      "train loss:0.005582778911306858\n",
      "train loss:0.033188395538612726\n",
      "train loss:0.009162681998658058\n",
      "train loss:0.051571233845340174\n",
      "train loss:0.006213467577477951\n",
      "train loss:0.0128516232437115\n",
      "train loss:0.006180749214162713\n",
      "train loss:0.004740242892538466\n",
      "train loss:0.01395279490753758\n",
      "train loss:0.003473354127461531\n",
      "train loss:0.0006195010536018471\n",
      "train loss:0.0018025504193459115\n",
      "train loss:0.007989237537292455\n",
      "train loss:0.007189377083752205\n",
      "train loss:0.0016142484142512264\n",
      "train loss:0.0017680474891454351\n",
      "train loss:0.002326574980057359\n",
      "train loss:0.006283420046982171\n",
      "train loss:0.016322397699020337\n",
      "train loss:0.01170083828967438\n",
      "train loss:0.006346175574996826\n",
      "train loss:0.026157094908667324\n",
      "train loss:0.0047609486079806\n",
      "train loss:0.012167839346299893\n",
      "train loss:0.12377935957559709\n",
      "train loss:0.02199446266697131\n",
      "train loss:0.006380099375492419\n",
      "train loss:0.026380454766831995\n",
      "train loss:0.013051190937918867\n",
      "train loss:0.006937258196843324\n",
      "train loss:0.007322025497629256\n",
      "train loss:0.04666404824427925\n",
      "train loss:0.00703768103485353\n",
      "train loss:0.004447690551256603\n",
      "train loss:0.01077396383738393\n",
      "train loss:0.0013870241210111852\n",
      "train loss:0.014913830711416456\n",
      "train loss:0.0014268430587505182\n",
      "train loss:0.03684599972723434\n",
      "train loss:0.0013670939882038525\n",
      "train loss:0.0239930034853177\n",
      "train loss:0.019516461270368192\n",
      "train loss:0.010761582789123016\n",
      "train loss:0.0020892441450943854\n",
      "train loss:0.006950678790045738\n",
      "train loss:0.005313136229828197\n",
      "train loss:0.014452586405850669\n",
      "train loss:0.015502136725487057\n",
      "train loss:0.008450924552516625\n",
      "train loss:0.005609186316324676\n",
      "train loss:0.01100964614135916\n",
      "train loss:0.004527528202937029\n",
      "train loss:0.0062701082211498085\n",
      "train loss:0.013586570889552533\n",
      "train loss:0.0020453355558246473\n",
      "train loss:0.034601779211194755\n",
      "train loss:0.005126861951394701\n",
      "train loss:0.03065469589910318\n",
      "train loss:0.002560415897051541\n",
      "train loss:0.0013147928283335389\n",
      "train loss:0.0014044438677255167\n",
      "train loss:0.009740986316538058\n",
      "train loss:0.004249016739193618\n",
      "train loss:0.013211831746350784\n",
      "train loss:0.0020763044667121773\n",
      "train loss:0.009180955074025193\n",
      "train loss:0.008740978881388311\n",
      "train loss:0.008417616434946377\n",
      "train loss:0.00800007332900501\n",
      "train loss:0.011346655934095737\n",
      "train loss:0.010437762024358237\n",
      "train loss:0.0031297320904593254\n",
      "train loss:0.0238408564533521\n",
      "train loss:0.03185810609662419\n",
      "train loss:0.01971036931097278\n",
      "train loss:0.0055054867065928124\n",
      "train loss:0.004723291545073601\n",
      "train loss:0.0011105295910622773\n",
      "train loss:0.010768508614701076\n",
      "train loss:0.030196646828021912\n",
      "train loss:0.008328115140980932\n",
      "train loss:0.0029191945209712145\n",
      "train loss:0.028760007772762882\n",
      "train loss:0.0006434367998760833\n",
      "train loss:0.0030398144208953026\n",
      "train loss:0.009430931502867659\n",
      "train loss:0.0053286857433083555\n",
      "train loss:0.004257353104651707\n",
      "train loss:0.006319752422094519\n",
      "train loss:0.002473536130311906\n",
      "train loss:0.017400840470606905\n",
      "train loss:0.024634647286754505\n",
      "train loss:0.010601039000718751\n",
      "train loss:0.0036068377893735248\n",
      "train loss:0.01301453841457929\n",
      "train loss:0.0033189451164852683\n",
      "train loss:0.00805657077641566\n",
      "train loss:0.005141820595574117\n",
      "train loss:0.007892601322009982\n",
      "train loss:0.009154348336751246\n",
      "train loss:0.002170702872542755\n",
      "train loss:0.006351822362160212\n",
      "train loss:0.0020071596284863056\n",
      "train loss:0.005008667094788099\n",
      "train loss:0.01962912411240076\n",
      "train loss:0.034973546978842335\n",
      "train loss:0.007977452214871884\n",
      "train loss:0.0013249807081690832\n",
      "train loss:0.010704540068820705\n",
      "train loss:0.011604843461923545\n",
      "train loss:0.0012655716469901087\n",
      "train loss:0.012380115791839326\n",
      "train loss:0.002806855271198577\n",
      "train loss:0.008491155301082694\n",
      "train loss:0.006799616059447177\n",
      "train loss:0.0029854390180890787\n",
      "train loss:0.0008578293219796641\n",
      "train loss:0.004254739075586928\n",
      "train loss:0.0009327304339991662\n",
      "train loss:0.008057361612897872\n",
      "train loss:0.001875529928303901\n",
      "train loss:0.01392409300638695\n",
      "train loss:0.007452601116569386\n",
      "train loss:0.0044990254586913395\n",
      "train loss:0.04484531190965374\n",
      "train loss:0.0005333683400696399\n",
      "train loss:0.005854289152215402\n",
      "train loss:0.01715965338384797\n",
      "train loss:0.01320491634136533\n",
      "train loss:0.004337690990760748\n",
      "train loss:0.007756514735761007\n",
      "train loss:0.0017463747382543318\n",
      "train loss:0.003352879400817727\n",
      "train loss:0.00017461792143644726\n",
      "train loss:0.02785862979592503\n",
      "train loss:0.008963242526894247\n",
      "train loss:0.0014932727086795809\n",
      "train loss:0.008899151208618741\n",
      "train loss:0.016751431649449\n",
      "train loss:0.0005125193685814523\n",
      "train loss:0.06704339386980435\n",
      "train loss:0.11447858817568285\n",
      "train loss:0.03222548634603678\n",
      "train loss:0.0013795859660087953\n",
      "train loss:0.007917163258438038\n",
      "train loss:0.0193865292312483\n",
      "train loss:0.008478677396167884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.024688085973129926\n",
      "train loss:0.0014334771841851652\n",
      "train loss:0.00213102753044778\n",
      "train loss:0.01981741126122998\n",
      "train loss:0.005484204736814702\n",
      "train loss:0.0051898647613642865\n",
      "train loss:0.026455964659344695\n",
      "train loss:0.007758951198410147\n",
      "train loss:0.009931649964686158\n",
      "train loss:0.003974279140055686\n",
      "train loss:0.013112020655812691\n",
      "train loss:0.015662199093384666\n",
      "train loss:0.010169392394372735\n",
      "train loss:0.024362141668012795\n",
      "train loss:0.01954137302592074\n",
      "train loss:0.005555629461310464\n",
      "train loss:0.016023527384657323\n",
      "train loss:0.08747586861711579\n",
      "train loss:0.0017362998018003856\n",
      "train loss:0.05833436628904919\n",
      "train loss:0.010635296841683335\n",
      "train loss:0.013684438587929913\n",
      "train loss:0.006489059353942107\n",
      "train loss:0.008253546354928514\n",
      "train loss:0.007353746414615321\n",
      "train loss:0.004997535626579541\n",
      "train loss:0.005701837390910458\n",
      "train loss:0.012286429001112785\n",
      "train loss:0.021216281745307958\n",
      "train loss:0.009506959636893481\n",
      "train loss:0.014056694267018659\n",
      "train loss:0.003177487793671875\n",
      "train loss:0.0070429363921372815\n",
      "train loss:0.0583578320974715\n",
      "train loss:0.00578723623930164\n",
      "train loss:0.0021590303052328257\n",
      "train loss:0.008802791391708802\n",
      "train loss:0.0032001400413230498\n",
      "train loss:0.016645749240556684\n",
      "train loss:0.00516393813627191\n",
      "train loss:0.01315407336654665\n",
      "train loss:0.006591692728345576\n",
      "train loss:0.015840595912506597\n",
      "train loss:0.007259247163612882\n",
      "train loss:0.02785175215912291\n",
      "train loss:0.0015233877057128265\n",
      "train loss:0.002638457558914998\n",
      "train loss:0.003781729002885314\n",
      "train loss:0.007169735753065768\n",
      "train loss:0.0010186072230721377\n",
      "train loss:0.01948638508520524\n",
      "train loss:0.012119114638691302\n",
      "train loss:0.0033907425154274667\n",
      "train loss:0.0026324818012144506\n",
      "train loss:0.018575536525471458\n",
      "train loss:0.008834618305869095\n",
      "train loss:0.006154260211469713\n",
      "train loss:0.033509314596566545\n",
      "train loss:0.0021225383260380956\n",
      "train loss:0.09520625793177581\n",
      "train loss:0.00709716765088536\n",
      "train loss:0.02260171934057123\n",
      "train loss:0.014171018509228965\n",
      "train loss:0.006388286282911066\n",
      "train loss:0.008442189671573029\n",
      "train loss:0.01124907307555501\n",
      "train loss:0.011648097749101423\n",
      "train loss:0.013549604300327476\n",
      "train loss:0.003109418246771668\n",
      "train loss:0.0075930262655192395\n",
      "train loss:0.008871564916218343\n",
      "train loss:0.003024674965462275\n",
      "train loss:0.04232766092375228\n",
      "train loss:0.018419163759295885\n",
      "train loss:0.0021145058470480645\n",
      "train loss:0.010636881416393207\n",
      "train loss:0.005373115531923624\n",
      "train loss:0.004043193364832565\n",
      "train loss:0.023220661437328798\n",
      "train loss:0.00328800149164212\n",
      "train loss:0.003795327149255385\n",
      "train loss:0.005236240580670969\n",
      "train loss:0.003300775149086671\n",
      "train loss:0.019788527760886857\n",
      "train loss:0.010252087645479769\n",
      "train loss:0.17672162274370593\n",
      "train loss:0.0014541330434173928\n",
      "train loss:0.004904312479325267\n",
      "train loss:0.007507991524256587\n",
      "train loss:0.0146628885343923\n",
      "train loss:0.01332194004508962\n",
      "train loss:0.03876688638193951\n",
      "train loss:0.03090100664517796\n",
      "train loss:0.003932646994983899\n",
      "train loss:0.07756172049218385\n",
      "train loss:0.009834587492093491\n",
      "train loss:0.000899935446897866\n",
      "train loss:0.011836639811772985\n",
      "train loss:0.07808918814941697\n",
      "train loss:0.05531679608525707\n",
      "train loss:0.019903544327567458\n",
      "train loss:0.006798871889740748\n",
      "train loss:0.004492828776702551\n",
      "train loss:0.01755616291748726\n",
      "train loss:0.011612818578749491\n",
      "train loss:0.015900691386846036\n",
      "train loss:0.03544681045496949\n",
      "train loss:0.012562506056031587\n",
      "train loss:0.007392901280347571\n",
      "train loss:0.00885570204900311\n",
      "train loss:0.010335913646539494\n",
      "train loss:0.006050559461054823\n",
      "train loss:0.013610301043423239\n",
      "train loss:0.006560555724169011\n",
      "train loss:0.011379447213879708\n",
      "train loss:0.006519452943436869\n",
      "train loss:0.01351424133129291\n",
      "train loss:0.017859447629169457\n",
      "train loss:0.004750449026992489\n",
      "train loss:0.013693194280202775\n",
      "train loss:0.018085214501462395\n",
      "train loss:0.01752303034674573\n",
      "train loss:0.0062785518349088585\n",
      "train loss:0.018185988381979264\n",
      "train loss:0.016220236113327714\n",
      "train loss:0.015461020226080218\n",
      "train loss:0.015240982959796508\n",
      "train loss:0.015311438949179152\n",
      "train loss:0.011763247450223344\n",
      "train loss:0.003644469541948563\n",
      "train loss:0.008608992679551411\n",
      "train loss:0.01780722297272372\n",
      "train loss:0.005111502906777116\n",
      "train loss:0.013586027718274414\n",
      "train loss:0.008363276470859837\n",
      "train loss:0.004742740052592533\n",
      "train loss:0.025426795704718726\n",
      "train loss:0.0047790892170754785\n",
      "train loss:0.0026520890179181143\n",
      "train loss:0.03719510910683032\n",
      "train loss:0.004490341430882932\n",
      "train loss:0.0009499852110460441\n",
      "train loss:0.05660005591574268\n",
      "train loss:0.005882234886881994\n",
      "train loss:0.0038212187541156865\n",
      "train loss:0.017120480388065826\n",
      "train loss:0.013801414180559201\n",
      "train loss:0.008897594491340987\n",
      "train loss:0.020707722157658974\n",
      "train loss:0.010383610353869983\n",
      "train loss:0.00527268345849916\n",
      "train loss:0.01892652944221491\n",
      "train loss:0.00873460870623662\n",
      "train loss:0.007248235673608975\n",
      "train loss:0.036794359583269175\n",
      "train loss:0.016374367342719773\n",
      "train loss:0.0053568599418001885\n",
      "train loss:0.013167789599582687\n",
      "train loss:0.0016355437011639415\n",
      "train loss:0.0005124623581561349\n",
      "train loss:0.0036606380138467093\n",
      "train loss:0.0036346227691943706\n",
      "train loss:0.0027971845754907153\n",
      "train loss:0.003614994629476895\n",
      "train loss:0.006818997813851019\n",
      "train loss:0.001101076831378789\n",
      "train loss:0.03148028611720453\n",
      "train loss:0.021057397851026328\n",
      "train loss:0.01036862723610189\n",
      "train loss:0.005701767732936557\n",
      "train loss:0.007036520287823935\n",
      "train loss:0.00918912744704066\n",
      "train loss:0.03633963673073174\n",
      "train loss:0.002905975110164186\n",
      "train loss:0.005531407234716613\n",
      "train loss:0.0020225665791584837\n",
      "train loss:0.011739369063062093\n",
      "train loss:0.0054318078883245444\n",
      "train loss:0.008933957555245202\n",
      "train loss:0.01640031133207666\n",
      "train loss:0.005467606179943145\n",
      "train loss:0.005871264250224312\n",
      "train loss:0.03198435640948436\n",
      "train loss:0.00498594862264805\n",
      "train loss:0.0030211755570389294\n",
      "train loss:0.018092046426429104\n",
      "=== epoch:10, train acc:0.992, test acc:0.988 ===\n",
      "train loss:0.013499096937222425\n",
      "train loss:0.007463958697321086\n",
      "train loss:0.005927028880706684\n",
      "train loss:0.006630364444956899\n",
      "train loss:0.003128069212728321\n",
      "train loss:0.0068212765782107\n",
      "train loss:0.0063578020675993455\n",
      "train loss:0.005853398801636451\n",
      "train loss:0.008068080349211902\n",
      "train loss:0.004003739263797524\n",
      "train loss:0.032889038158496905\n",
      "train loss:0.010492805315115322\n",
      "train loss:0.005508455798391124\n",
      "train loss:0.0038037406909987932\n",
      "train loss:0.0033641380165042346\n",
      "train loss:0.00811941503970632\n",
      "train loss:0.02451986570802457\n",
      "train loss:0.006566943754310522\n",
      "train loss:0.0018240356958532556\n",
      "train loss:0.006934231096778987\n",
      "train loss:0.008283660105889316\n",
      "train loss:0.00961216561817388\n",
      "train loss:0.01853177566331943\n",
      "train loss:0.00063523546203572\n",
      "train loss:0.008919549797484001\n",
      "train loss:0.00687374581768991\n",
      "train loss:0.0006736987736834653\n",
      "train loss:0.01508125108272156\n",
      "train loss:0.0032921924081549332\n",
      "train loss:0.0008879008914004897\n",
      "train loss:0.037768014629581965\n",
      "train loss:0.003518774754548882\n",
      "train loss:0.008684698523962794\n",
      "train loss:0.0026521997381653297\n",
      "train loss:0.03523838820649892\n",
      "train loss:0.0027027191266969027\n",
      "train loss:0.005692859484666159\n",
      "train loss:0.008888423095486106\n",
      "train loss:0.013482614551927199\n",
      "train loss:0.009767552198180292\n",
      "train loss:0.01135223077270462\n",
      "train loss:0.01767723237474879\n",
      "train loss:0.019463052872285117\n",
      "train loss:0.007877659634547533\n",
      "train loss:0.0038479899527453765\n",
      "train loss:0.008348725004881102\n",
      "train loss:0.015029846197713642\n",
      "train loss:0.025072366427408687\n",
      "train loss:0.0015278780573165871\n",
      "train loss:0.0034722846994103885\n",
      "train loss:0.0028325306368092323\n",
      "train loss:0.002086325122485584\n",
      "train loss:0.010053161834066687\n",
      "train loss:0.023806031596833126\n",
      "train loss:0.00791807739764778\n",
      "train loss:0.0005354879161269278\n",
      "train loss:0.0167777879733083\n",
      "train loss:0.005830323583188483\n",
      "train loss:0.010155674335831928\n",
      "train loss:0.0011440280218910008\n",
      "train loss:0.005107802909777677\n",
      "train loss:0.012426270190682945\n",
      "train loss:0.009060883087715334\n",
      "train loss:0.004541915801755746\n",
      "train loss:0.004328495340135982\n",
      "train loss:0.010993791840103606\n",
      "train loss:0.011979770876920664\n",
      "train loss:0.0009218515261861055\n",
      "train loss:0.008364516621584434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010682202583514246\n",
      "train loss:0.007952436722598424\n",
      "train loss:0.022655633723672672\n",
      "train loss:0.008838415309522885\n",
      "train loss:0.0033010860904292495\n",
      "train loss:0.017808111188763638\n",
      "train loss:0.0064807020014362145\n",
      "train loss:0.00166144792556219\n",
      "train loss:0.011120743995351921\n",
      "train loss:0.018810643976342575\n",
      "train loss:0.00954589720587288\n",
      "train loss:0.004892474755250129\n",
      "train loss:0.01411481407140505\n",
      "train loss:0.013423894085614712\n",
      "train loss:0.004571410730947839\n",
      "train loss:0.012994847074449416\n",
      "train loss:0.0016268153300951105\n",
      "train loss:0.006832290324066888\n",
      "train loss:0.0084590889717764\n",
      "train loss:0.00993438831896831\n",
      "train loss:0.023827708123399658\n",
      "train loss:0.005078032793374591\n",
      "train loss:0.0413263902426936\n",
      "train loss:0.002201056605355974\n",
      "train loss:0.003862387610493334\n",
      "train loss:0.011502168090091268\n",
      "train loss:0.001961562145226864\n",
      "train loss:0.004575985066622806\n",
      "train loss:0.01328439927013271\n",
      "train loss:0.0032152179060466178\n",
      "train loss:0.0017371474979908966\n",
      "train loss:0.00956507209155327\n",
      "train loss:0.01444252762218063\n",
      "train loss:0.005465768150919165\n",
      "train loss:0.002471511748704791\n",
      "train loss:0.008851377933717765\n",
      "train loss:0.008373758914808481\n",
      "train loss:0.006741356168456487\n",
      "train loss:0.0025988463049216137\n",
      "train loss:0.0033123387012767595\n",
      "train loss:0.05049637684539604\n",
      "train loss:0.0025702246957086863\n",
      "train loss:0.01015706114188863\n",
      "train loss:0.00946510810464201\n",
      "train loss:0.0009718802016811028\n",
      "train loss:0.0011012402046299207\n",
      "train loss:0.014658828781778696\n",
      "train loss:0.0016485994786308122\n",
      "train loss:0.01227965257919015\n",
      "train loss:0.0019253770668151249\n",
      "train loss:0.0033389482741874505\n",
      "train loss:0.00328556184364181\n",
      "train loss:0.008474392905898836\n",
      "train loss:0.002316848960737136\n",
      "train loss:0.0012970395706031598\n",
      "train loss:0.004778450980860412\n",
      "train loss:0.01705080923637705\n",
      "train loss:0.0041516487432446325\n",
      "train loss:0.0022055169641051757\n",
      "train loss:0.0006887612873748211\n",
      "train loss:0.0010377564261087864\n",
      "train loss:0.0014549086889608508\n",
      "train loss:0.005313985835552706\n",
      "train loss:0.004276469733783222\n",
      "train loss:0.03350878493088452\n",
      "train loss:0.007687210805786111\n",
      "train loss:0.0010119032357998794\n",
      "train loss:0.009100623502141613\n",
      "train loss:0.006837715284091412\n",
      "train loss:0.007988576033185727\n",
      "train loss:0.005721429670191146\n",
      "train loss:0.025055506077052113\n",
      "train loss:0.0011815262631557045\n",
      "train loss:0.005050374915597768\n",
      "train loss:0.005063018429933084\n",
      "train loss:0.00491864291950584\n",
      "train loss:0.000920163093320039\n",
      "train loss:0.017389964639260135\n",
      "train loss:0.0006319719261039102\n",
      "train loss:0.003211570651376967\n",
      "train loss:0.007536059891181279\n",
      "train loss:0.009549758954899935\n",
      "train loss:0.002178377275787657\n",
      "train loss:0.0030817836855220448\n",
      "train loss:0.014110377219744966\n",
      "train loss:0.011308151603158248\n",
      "train loss:0.008861633326750376\n",
      "train loss:0.014774711376870881\n",
      "train loss:0.00313073060835016\n",
      "train loss:0.0054465271557215325\n",
      "train loss:0.01356332720453678\n",
      "train loss:0.00317234739127124\n",
      "train loss:0.004030835024611114\n",
      "train loss:0.013770661857014447\n",
      "train loss:0.004102102142568714\n",
      "train loss:0.0022057501912309853\n",
      "train loss:0.001571005244806267\n",
      "train loss:0.005219330164339906\n",
      "train loss:0.0006355264127339273\n",
      "train loss:0.02847821411211633\n",
      "train loss:0.004956087791497379\n",
      "train loss:0.004707373069084661\n",
      "train loss:0.06967112637813394\n",
      "train loss:0.0029435207214330568\n",
      "train loss:0.0012548459516399408\n",
      "train loss:0.011365993404861283\n",
      "train loss:0.007080847828342498\n",
      "train loss:0.00988468126288708\n",
      "train loss:0.006814694906188893\n",
      "train loss:0.0028586506556689275\n",
      "train loss:0.006779833743385414\n",
      "train loss:0.004875357688668291\n",
      "train loss:0.026451747867240492\n",
      "train loss:0.0023808518755673545\n",
      "train loss:0.007771612012663477\n",
      "train loss:0.0013588999462295437\n",
      "train loss:0.01139664345576012\n",
      "train loss:0.006646576678758756\n",
      "train loss:0.010056202650847447\n",
      "train loss:0.0075431865162481045\n",
      "train loss:0.01802581322048383\n",
      "train loss:0.02925260969170209\n",
      "train loss:0.011550077923311253\n",
      "train loss:0.003919717191735776\n",
      "train loss:0.002147463475057188\n",
      "train loss:0.0033277978827138434\n",
      "train loss:0.003961001461194061\n",
      "train loss:0.0035175713318364127\n",
      "train loss:0.0007786387551247303\n",
      "train loss:0.016877067808057967\n",
      "train loss:0.12157139603160068\n",
      "train loss:0.004828043674997628\n",
      "train loss:0.007427704308010506\n",
      "train loss:0.014861486907966912\n",
      "train loss:0.005304593006898882\n",
      "train loss:0.00437301570104254\n",
      "train loss:0.003239039072170314\n",
      "train loss:0.0006643078030175503\n",
      "train loss:0.004924341827412821\n",
      "train loss:0.0038249541099974376\n",
      "train loss:0.004201050616244578\n",
      "train loss:0.019657656751347567\n",
      "train loss:0.00462736033597621\n",
      "train loss:0.012923793359090689\n",
      "train loss:0.016442483607231592\n",
      "train loss:0.012005675368233847\n",
      "train loss:0.007223948407611495\n",
      "train loss:0.006698084090551578\n",
      "train loss:0.025873715738895325\n",
      "train loss:0.010098294306172173\n",
      "train loss:0.004143679620696506\n",
      "train loss:0.004999095976730078\n",
      "train loss:0.0018552567044621134\n",
      "train loss:0.004492297262528078\n",
      "train loss:0.0005979559017762903\n",
      "train loss:0.007207534136665626\n",
      "train loss:0.00926804366169852\n",
      "train loss:0.01390216845179083\n",
      "train loss:0.0016438146821770873\n",
      "train loss:0.0008004919823731784\n",
      "train loss:0.0012504198829130615\n",
      "train loss:0.0462887863949106\n",
      "train loss:0.006145352722314579\n",
      "train loss:0.008631770765638706\n",
      "train loss:0.006750430338907273\n",
      "train loss:0.01017476336146691\n",
      "train loss:0.002480790385327526\n",
      "train loss:0.0022599882570386613\n",
      "train loss:0.0015804501091414046\n",
      "train loss:0.0030781191567080097\n",
      "train loss:0.01657620129758236\n",
      "train loss:0.0013104883911244907\n",
      "train loss:0.020507572462101283\n",
      "train loss:0.004944264751771356\n",
      "train loss:0.003393621542877586\n",
      "train loss:0.00871560896454655\n",
      "train loss:0.0026648517814455335\n",
      "train loss:0.002235599362259326\n",
      "train loss:0.009194510976844143\n",
      "train loss:0.01028293144292574\n",
      "train loss:0.0020346892264562644\n",
      "train loss:0.0010753563313567382\n",
      "train loss:0.004232183942461801\n",
      "train loss:0.02085997498162811\n",
      "train loss:0.004942992010786063\n",
      "train loss:0.005254288441362422\n",
      "train loss:0.015119733399593742\n",
      "train loss:0.16192350170830305\n",
      "train loss:0.0029397441893419195\n",
      "train loss:0.0017156925423301658\n",
      "train loss:0.10424276747141019\n",
      "train loss:0.007489161981864711\n",
      "train loss:0.006432275261026029\n",
      "train loss:0.001485983970415077\n",
      "train loss:0.011486476224331226\n",
      "train loss:0.003711795726490558\n",
      "train loss:0.024401994106461645\n",
      "train loss:0.0019527524339964359\n",
      "train loss:0.008105085504665549\n",
      "train loss:0.0040144759397470605\n",
      "train loss:0.007991434439612533\n",
      "train loss:0.0017965418355420566\n",
      "train loss:0.0029828989389007487\n",
      "train loss:0.009438564492442583\n",
      "train loss:0.0075822270220252\n",
      "train loss:0.005921018298364677\n",
      "train loss:0.004508453088601755\n",
      "train loss:0.002466907487058693\n",
      "train loss:0.002424910496740811\n",
      "train loss:0.0012616615713634228\n",
      "train loss:0.014436085732094418\n",
      "train loss:0.02193079162292748\n",
      "train loss:0.010510285971446296\n",
      "train loss:0.004703009165893822\n",
      "train loss:0.023759537930056175\n",
      "train loss:0.006105327088285274\n",
      "train loss:0.00438817532396285\n",
      "train loss:0.0022473852561371915\n",
      "train loss:0.004342025865725674\n",
      "train loss:0.020765037416765234\n",
      "train loss:0.005666837205303507\n",
      "train loss:0.014467930617014617\n",
      "train loss:0.0018615167512870514\n",
      "train loss:0.0033114038427266303\n",
      "train loss:0.009786906577948614\n",
      "train loss:0.006973662416880229\n",
      "train loss:0.0035066612218383913\n",
      "train loss:0.0028410834161884356\n",
      "train loss:0.012104921592437312\n",
      "train loss:0.005280906743406595\n",
      "train loss:0.006364736092501554\n",
      "train loss:0.015851025532750473\n",
      "train loss:0.0024973517752414397\n",
      "train loss:0.003062178002979575\n",
      "train loss:0.009525831355901127\n",
      "train loss:0.012150291595562211\n",
      "train loss:0.01545723484875386\n",
      "train loss:0.05015069079789175\n",
      "train loss:0.001799025067142415\n",
      "train loss:0.016985437954062096\n",
      "train loss:0.13643574477313902\n",
      "train loss:0.007190500531597151\n",
      "train loss:0.03526870484743307\n",
      "train loss:0.007940682593757981\n",
      "train loss:0.005565404370358248\n",
      "train loss:0.01080912224045891\n",
      "train loss:0.0015402807920718601\n",
      "train loss:0.020337755518816086\n",
      "train loss:0.006608986576132632\n",
      "train loss:0.0045282893155776435\n",
      "train loss:0.028346794069078175\n",
      "train loss:0.0006954360744801186\n",
      "train loss:0.005834396925953701\n",
      "train loss:0.08549529322920871\n",
      "train loss:0.005082426405307125\n",
      "train loss:0.007226080496281163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006776026881342082\n",
      "train loss:0.01595283109338304\n",
      "train loss:0.002269693461815732\n",
      "train loss:0.03282712807336368\n",
      "train loss:0.008856650672719967\n",
      "train loss:0.006537914753301621\n",
      "train loss:0.004386045151593832\n",
      "train loss:0.004005219505985278\n",
      "train loss:0.010422023049601395\n",
      "train loss:0.005089945187622882\n",
      "train loss:0.009806767873939587\n",
      "train loss:0.04474075456524373\n",
      "train loss:0.00046570765373730674\n",
      "train loss:0.00877909224817281\n",
      "train loss:0.0035959438591547156\n",
      "train loss:0.007742407888096787\n",
      "train loss:0.003175617746203746\n",
      "train loss:0.009199466622642446\n",
      "train loss:0.0044418707802359346\n",
      "train loss:0.024650110778717607\n",
      "train loss:0.011780232044160182\n",
      "train loss:0.00807284386543199\n",
      "train loss:0.020078154993179664\n",
      "train loss:0.00832935490849265\n",
      "train loss:0.003355057768268497\n",
      "train loss:0.004512944746339757\n",
      "train loss:0.0013718981554200708\n",
      "train loss:0.0005725293824222653\n",
      "train loss:0.004039514635406141\n",
      "train loss:0.0010082003956699425\n",
      "train loss:0.07879412612916278\n",
      "train loss:0.09240085197086514\n",
      "train loss:0.00488035455516285\n",
      "train loss:0.0074203506705035165\n",
      "train loss:0.000810999926448557\n",
      "train loss:0.0010288673227209259\n",
      "train loss:0.006136557051534898\n",
      "train loss:0.00518556063398008\n",
      "train loss:0.0009164234152164698\n",
      "train loss:0.006090061513552882\n",
      "train loss:0.02105746797583409\n",
      "train loss:0.007036948183765913\n",
      "train loss:0.008928172562693189\n",
      "train loss:0.0018515701034818905\n",
      "train loss:0.007534832085101424\n",
      "train loss:0.002384858518136443\n",
      "train loss:0.005365706317796822\n",
      "train loss:0.0027881598896605754\n",
      "train loss:0.0036103367949792803\n",
      "train loss:0.006968057954875183\n",
      "train loss:0.006524472166354666\n",
      "train loss:0.01642640473842901\n",
      "train loss:0.004565467382343674\n",
      "train loss:0.022029476580976873\n",
      "train loss:0.000834092658313411\n",
      "train loss:0.0022829433650427486\n",
      "train loss:0.0016877710007112178\n",
      "train loss:0.004044710633056331\n",
      "train loss:0.0042129456846129775\n",
      "train loss:0.0010853577313901057\n",
      "train loss:0.007857783056202541\n",
      "train loss:0.010333133781170352\n",
      "train loss:0.0031370033977304985\n",
      "train loss:0.006536927282191739\n",
      "train loss:0.006700266715695342\n",
      "train loss:0.0006976306712645482\n",
      "train loss:0.0034553356009965437\n",
      "train loss:0.006652807906870685\n",
      "train loss:0.011076896806253731\n",
      "train loss:0.01229154720491356\n",
      "train loss:0.005883299454855575\n",
      "train loss:0.014715582479007892\n",
      "train loss:0.003750338195868697\n",
      "train loss:0.006340748728573087\n",
      "train loss:0.0015959497318382755\n",
      "train loss:0.007915877255373743\n",
      "train loss:0.002356430398024795\n",
      "train loss:0.011315697651492117\n",
      "train loss:0.004102747844672106\n",
      "train loss:0.011223923427074869\n",
      "train loss:0.005698486287353328\n",
      "train loss:0.011040567691115076\n",
      "train loss:0.007872711761723807\n",
      "train loss:0.026234691214076553\n",
      "train loss:0.004737702474330171\n",
      "train loss:0.0052799610268125085\n",
      "train loss:0.012145928300061169\n",
      "train loss:0.011640884102258203\n",
      "train loss:0.017989244136147796\n",
      "train loss:0.003406266346156524\n",
      "train loss:0.0011057741151837847\n",
      "train loss:0.005197138894666386\n",
      "train loss:0.006749251062024349\n",
      "train loss:0.009641703229096226\n",
      "train loss:0.00661713229617898\n",
      "train loss:0.006056794000053146\n",
      "train loss:0.007264759203123975\n",
      "train loss:0.005389741552860558\n",
      "train loss:0.0034523211458635295\n",
      "train loss:0.0025751505320418906\n",
      "train loss:0.040225699071874024\n",
      "train loss:0.0028032315904385164\n",
      "train loss:0.013370795346706323\n",
      "train loss:0.0021690510722095894\n",
      "train loss:0.0038572835559035307\n",
      "train loss:0.0022485617594446014\n",
      "train loss:0.0032793434734633992\n",
      "train loss:0.008341170655560372\n",
      "train loss:0.01863714247555561\n",
      "train loss:0.0031241949661349393\n",
      "train loss:0.0011199506981635356\n",
      "train loss:0.0015725785729137163\n",
      "train loss:0.0032467154487319226\n",
      "train loss:0.004021126768263011\n",
      "train loss:0.016405497356404043\n",
      "train loss:0.009766690687953836\n",
      "train loss:0.004413674959987454\n",
      "train loss:0.0012297783549536797\n",
      "train loss:0.002696393073104432\n",
      "train loss:0.0036386961555416523\n",
      "train loss:0.006750594934117767\n",
      "train loss:0.020055622418087386\n",
      "train loss:0.003433780669648626\n",
      "train loss:0.0003678358408203186\n",
      "train loss:0.007404827284139358\n",
      "train loss:0.0011333346568315919\n",
      "train loss:0.0113063965577335\n",
      "train loss:0.005257135473166263\n",
      "train loss:0.10468206652785836\n",
      "train loss:0.0018614508100412784\n",
      "train loss:0.007747979561684069\n",
      "train loss:0.001461655567458797\n",
      "train loss:0.009149869228605475\n",
      "train loss:0.00630159734395769\n",
      "train loss:0.006175906002469772\n",
      "train loss:0.007205675268059541\n",
      "train loss:0.03181866801278525\n",
      "train loss:0.024302173200261623\n",
      "train loss:0.0037377065213018497\n",
      "train loss:0.004895454127433819\n",
      "train loss:0.004185162664033016\n",
      "train loss:0.023573215635445902\n",
      "train loss:0.006102846525123817\n",
      "train loss:0.011038294886832011\n",
      "train loss:0.0029392711091723862\n",
      "train loss:0.0025382478342088287\n",
      "train loss:0.0032317106300223442\n",
      "train loss:0.0033273895153556514\n",
      "train loss:0.04014261784116457\n",
      "train loss:0.004253466167083455\n",
      "train loss:0.0020985651335536895\n",
      "train loss:0.0010735476510916014\n",
      "train loss:0.017997806129834842\n",
      "train loss:0.010534457431514046\n",
      "train loss:0.004961848756530683\n",
      "train loss:0.0053013584592074\n",
      "train loss:0.007861155564782937\n",
      "train loss:0.03778563406047659\n",
      "train loss:0.013900157810720933\n",
      "train loss:0.003517194613283754\n",
      "train loss:0.005189539623346615\n",
      "train loss:0.002078446548636266\n",
      "train loss:0.003512246748929607\n",
      "train loss:0.0037152407585387456\n",
      "train loss:0.017542040517632758\n",
      "train loss:0.007253699064259539\n",
      "train loss:0.005620503154439162\n",
      "train loss:0.007887461493386672\n",
      "train loss:0.0029002327947985672\n",
      "train loss:0.0044944096071984005\n",
      "train loss:0.0017952163372893018\n",
      "train loss:0.006344600518153089\n",
      "train loss:0.002623306753974783\n",
      "train loss:0.010229177166168932\n",
      "train loss:0.0018097485044172063\n",
      "train loss:0.010524516465569667\n",
      "train loss:0.001616336317529331\n",
      "train loss:0.00449399401775453\n",
      "train loss:0.02359362723633485\n",
      "train loss:0.0023235472586693438\n",
      "train loss:0.005162538750796175\n",
      "train loss:0.023507161589561412\n",
      "train loss:0.000510165651247922\n",
      "train loss:0.0029911283454164333\n",
      "train loss:0.0018074002890081436\n",
      "train loss:0.0037363417371469414\n",
      "train loss:0.005090086212229786\n",
      "train loss:0.004834086798969177\n",
      "train loss:0.004621643349951247\n",
      "train loss:0.0012165497598782774\n",
      "train loss:0.002820532823621368\n",
      "train loss:0.006221422600940964\n",
      "train loss:0.006232731798025216\n",
      "train loss:0.013527291481295313\n",
      "train loss:0.002247510386179128\n",
      "train loss:0.0034623022563509227\n",
      "train loss:0.009403266723875108\n",
      "train loss:0.005033322245427716\n",
      "train loss:0.0008962615057141652\n",
      "train loss:0.006277724399108093\n",
      "train loss:0.005078362200597705\n",
      "train loss:0.02045863396945292\n",
      "train loss:0.0048752593732160334\n",
      "train loss:0.003249258668519697\n",
      "train loss:0.0016045690537495457\n",
      "train loss:0.12727165344723976\n",
      "train loss:0.011684564311799945\n",
      "train loss:0.008720160976343788\n",
      "train loss:0.005804181793086679\n",
      "train loss:0.0014744746208175852\n",
      "train loss:0.0033042256998171106\n",
      "train loss:0.007114026055499502\n",
      "train loss:0.003583438805671122\n",
      "train loss:0.003510633580602875\n",
      "train loss:0.003004044003459341\n",
      "train loss:0.010157752815515883\n",
      "train loss:0.02491791937507546\n",
      "train loss:0.001652479600785349\n",
      "train loss:0.002708664063681905\n",
      "train loss:0.00448132895661479\n",
      "train loss:0.05498088298950269\n",
      "train loss:0.0008832986902907324\n",
      "train loss:0.01931807990820578\n",
      "train loss:0.019728418888865805\n",
      "train loss:0.00820946205963691\n",
      "train loss:0.003166481006091206\n",
      "train loss:0.0030726166093922465\n",
      "train loss:0.004392130344826915\n",
      "train loss:0.0012342580484309988\n",
      "train loss:0.0018896305874213975\n",
      "train loss:0.00188120542396576\n",
      "train loss:0.007224779063239329\n",
      "train loss:0.008469868877998568\n",
      "train loss:0.006037452397310505\n",
      "train loss:0.0027723094150358145\n",
      "train loss:0.0033367704611296134\n",
      "train loss:0.010947243494097092\n",
      "train loss:0.002475921862337525\n",
      "train loss:0.02368355880556502\n",
      "train loss:0.0016748445476922884\n",
      "train loss:0.014960632608466015\n",
      "train loss:0.006618666126322594\n",
      "train loss:0.0009079061695521488\n",
      "train loss:0.010259357993105768\n",
      "train loss:0.009837199676918896\n",
      "train loss:0.0014488926085126945\n",
      "train loss:0.009237872379677155\n",
      "train loss:0.00908656953737778\n",
      "train loss:0.05942636322491076\n",
      "train loss:0.030308002019911035\n",
      "train loss:0.007773240371998531\n",
      "train loss:0.02250811702357799\n",
      "train loss:0.00117046602214717\n",
      "train loss:0.014214453226999036\n",
      "train loss:0.0015550979271185135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01778492397244966\n",
      "train loss:0.007313010712798718\n",
      "train loss:0.0038773291012157694\n",
      "train loss:0.010528646283399416\n",
      "train loss:0.009789736398357684\n",
      "train loss:0.003609042212012488\n",
      "train loss:0.0027315432438684744\n",
      "train loss:0.004195960008834532\n",
      "train loss:0.011227233487233559\n",
      "train loss:0.004668714256066822\n",
      "train loss:0.019949983234275197\n",
      "train loss:0.0015550798639647877\n",
      "train loss:0.005443783205831029\n",
      "train loss:0.013992550585418668\n",
      "train loss:0.014251209735408756\n",
      "train loss:0.01749481799679987\n",
      "train loss:0.0027023321080340418\n",
      "train loss:0.006207786049010103\n",
      "train loss:0.010692632655409312\n",
      "train loss:0.007385422482980953\n",
      "=== epoch:11, train acc:0.995, test acc:0.985 ===\n",
      "train loss:0.0048126460555659115\n",
      "train loss:0.01276113854119541\n",
      "train loss:0.0034591947497029313\n",
      "train loss:0.012849253134960326\n",
      "train loss:0.004332049670636353\n",
      "train loss:0.04600622170877818\n",
      "train loss:0.009442724666644559\n",
      "train loss:0.003554363219049373\n",
      "train loss:0.0013845043424451809\n",
      "train loss:0.006746527340852948\n",
      "train loss:0.0009859379910630269\n",
      "train loss:0.0009754727117885073\n",
      "train loss:0.0069057816082198865\n",
      "train loss:0.001429797728830756\n",
      "train loss:0.012602374186355665\n",
      "train loss:0.0005858433598707769\n",
      "train loss:0.008208806410238063\n",
      "train loss:0.011459559710940918\n",
      "train loss:0.0012170599290031142\n",
      "train loss:0.007791374436585138\n",
      "train loss:0.00048386463567784345\n",
      "train loss:0.002365015671391952\n",
      "train loss:0.0031691176847568046\n",
      "train loss:0.003877234941850113\n",
      "train loss:0.009435655769706654\n",
      "train loss:0.009686611828068112\n",
      "train loss:0.010477806057499952\n",
      "train loss:0.004119320198287656\n",
      "train loss:0.0009656577325277853\n",
      "train loss:0.03183299358431155\n",
      "train loss:0.0018217010426167196\n",
      "train loss:0.002232876690948385\n",
      "train loss:0.0008230722736869312\n",
      "train loss:0.004054177148516698\n",
      "train loss:0.008171943468079318\n",
      "train loss:0.0014275913654496534\n",
      "train loss:0.010111024036360777\n",
      "train loss:0.029525011479791946\n",
      "train loss:0.029786230720681445\n",
      "train loss:0.004037376915101249\n",
      "train loss:0.004745537167219263\n",
      "train loss:0.006510642001800793\n",
      "train loss:0.01787630390357879\n",
      "train loss:0.010865644345827463\n",
      "train loss:0.006610914033080739\n",
      "train loss:0.0025598953221623467\n",
      "train loss:0.002884242336435402\n",
      "train loss:0.008703437726024986\n",
      "train loss:0.012619158891647766\n",
      "train loss:0.0034145321679248273\n",
      "train loss:0.03209894621588688\n",
      "train loss:0.002896422154811023\n",
      "train loss:0.006501130141428719\n",
      "train loss:0.012486787977059958\n",
      "train loss:0.017970203692671233\n",
      "train loss:0.001453627581831546\n",
      "train loss:0.010839149860165083\n",
      "train loss:0.0018114715726472838\n",
      "train loss:0.004050802084019077\n",
      "train loss:0.0031555169417132683\n",
      "train loss:0.005148356562156038\n",
      "train loss:0.001886205774093886\n",
      "train loss:0.02302407140668168\n",
      "train loss:0.0003264062434463002\n",
      "train loss:0.012457455266302592\n",
      "train loss:0.0004987642711006852\n",
      "train loss:0.0034676687268475185\n",
      "train loss:0.002297974478197078\n",
      "train loss:0.0018066383448738096\n",
      "train loss:0.002942710196359383\n",
      "train loss:0.003138015696960092\n",
      "train loss:0.0016373119094769488\n",
      "train loss:0.00470574324181751\n",
      "train loss:0.01857783613057147\n",
      "train loss:0.003679128950858021\n",
      "train loss:0.00300239869827099\n",
      "train loss:0.012977518573826358\n",
      "train loss:0.0026178541045728566\n",
      "train loss:0.0022175905869096647\n",
      "train loss:0.012041037472560929\n",
      "train loss:0.006130537365912474\n",
      "train loss:0.013376157784276447\n",
      "train loss:0.0028560246825054033\n",
      "train loss:0.0015622636975967013\n",
      "train loss:0.0010998928525740553\n",
      "train loss:0.009789431155667216\n",
      "train loss:0.008098437204522236\n",
      "train loss:0.012708129266638675\n",
      "train loss:0.003852201631076677\n",
      "train loss:0.0024053302907810145\n",
      "train loss:0.002042887433300366\n",
      "train loss:0.0033317101772129243\n",
      "train loss:0.0042490581840514755\n",
      "train loss:0.0015789706257708425\n",
      "train loss:0.04338703191933645\n",
      "train loss:0.002776698275818386\n",
      "train loss:0.0023141956071783872\n",
      "train loss:0.001683464116849913\n",
      "train loss:0.0005991225164666533\n",
      "train loss:0.0032827802304845576\n",
      "train loss:0.005195492622492672\n",
      "train loss:0.005321894903972533\n",
      "train loss:0.008395863109800053\n",
      "train loss:0.015834073130166007\n",
      "train loss:0.00047175747843344174\n",
      "train loss:0.005797633055730995\n",
      "train loss:0.0028993073233084094\n",
      "train loss:0.0029567542442383147\n",
      "train loss:0.0025032283031390743\n",
      "train loss:0.005682410986319666\n",
      "train loss:0.009266260259735036\n",
      "train loss:0.0011496776833175078\n",
      "train loss:0.003828162086411453\n",
      "train loss:0.0035601833181566193\n",
      "train loss:0.0038842545870077876\n",
      "train loss:0.012404155257787701\n",
      "train loss:0.0018488474338619121\n",
      "train loss:0.007575689729972726\n",
      "train loss:0.001320298704641554\n",
      "train loss:0.0016088232064695254\n",
      "train loss:0.000808101874424655\n",
      "train loss:0.0031825772086283848\n",
      "train loss:0.0012835566752211242\n",
      "train loss:0.01680053435450409\n",
      "train loss:0.005502858352399992\n",
      "train loss:0.007187728481948425\n",
      "train loss:0.034706736223699214\n",
      "train loss:0.000612530645748021\n",
      "train loss:0.002240541737789179\n",
      "train loss:0.022111171814474685\n",
      "train loss:0.0018666255109100307\n",
      "train loss:0.003859316974644741\n",
      "train loss:0.0034417267613612006\n",
      "train loss:0.022572396741720225\n",
      "train loss:0.008384088433155629\n",
      "train loss:0.002948760132188193\n",
      "train loss:0.005846269342419501\n",
      "train loss:0.005682009136515625\n",
      "train loss:0.01906047876409446\n",
      "train loss:0.010208358751425554\n",
      "train loss:0.0016662811505424857\n",
      "train loss:0.0021771903632285296\n",
      "train loss:0.004440483727648537\n",
      "train loss:0.0026620281565252276\n",
      "train loss:0.013864368617933087\n",
      "train loss:0.003025282206775708\n",
      "train loss:0.0027403764319937126\n",
      "train loss:0.0035218380402526842\n",
      "train loss:0.000882832249564112\n",
      "train loss:0.002769984354322688\n",
      "train loss:0.00434535059792343\n",
      "train loss:0.0026013662306844714\n",
      "train loss:0.0075103915503046785\n",
      "train loss:0.006881356549406278\n",
      "train loss:0.001881908913328313\n",
      "train loss:0.007398140931927195\n",
      "train loss:0.002591851634649173\n",
      "train loss:0.000901959622055353\n",
      "train loss:0.033888427117283564\n",
      "train loss:0.0008098511226148333\n",
      "train loss:0.007496981226260214\n",
      "train loss:0.0018485376156676836\n",
      "train loss:0.007507908235535341\n",
      "train loss:0.005812216962811221\n",
      "train loss:0.005507566263125934\n",
      "train loss:0.004741426215137079\n",
      "train loss:0.001998752460014989\n",
      "train loss:0.04115905333075342\n",
      "train loss:0.0031182210289704996\n",
      "train loss:0.010529901727517913\n",
      "train loss:0.003412347346860665\n",
      "train loss:0.006761236065333949\n",
      "train loss:0.0195900781757389\n",
      "train loss:0.011586438199957643\n",
      "train loss:0.0034556641607511873\n",
      "train loss:0.000647664358690294\n",
      "train loss:0.0046866873718509686\n",
      "train loss:0.006038439137469333\n",
      "train loss:0.0037191984442705166\n",
      "train loss:0.006851925445255765\n",
      "train loss:0.002793984414802795\n",
      "train loss:0.008690470155115109\n",
      "train loss:0.002391995975085667\n",
      "train loss:0.0021207449631594636\n",
      "train loss:0.015178349058170924\n",
      "train loss:0.007940295529063477\n",
      "train loss:0.0026572047408156764\n",
      "train loss:0.0018721540983221007\n",
      "train loss:0.009869457987576291\n",
      "train loss:0.004112162648269715\n",
      "train loss:0.005773528375684842\n",
      "train loss:0.005503882859110899\n",
      "train loss:0.01383538517675722\n",
      "train loss:0.009020942314314065\n",
      "train loss:0.0020391672740091888\n",
      "train loss:0.004470232796210772\n",
      "train loss:0.0015950959110920134\n",
      "train loss:0.005271314223883093\n",
      "train loss:0.0038029730575907385\n",
      "train loss:0.0031787561261547833\n",
      "train loss:0.02745158676577837\n",
      "train loss:0.003814547303408048\n",
      "train loss:0.0011130992548586554\n",
      "train loss:0.0019814291816125785\n",
      "train loss:0.002136685520267496\n",
      "train loss:0.002662769530916736\n",
      "train loss:0.003932612311121825\n",
      "train loss:0.005616752724229682\n",
      "train loss:0.005216186685240099\n",
      "train loss:0.0030485946711027597\n",
      "train loss:0.0031782919293186396\n",
      "train loss:0.0016010126133612118\n",
      "train loss:0.0035858701678743153\n",
      "train loss:0.0011825376889922593\n",
      "train loss:0.000910003182190465\n",
      "train loss:0.0019994767162426434\n",
      "train loss:0.0005881892711778851\n",
      "train loss:0.0052002872179336265\n",
      "train loss:0.0019416004615996044\n",
      "train loss:0.0004024378152165159\n",
      "train loss:0.0008630372447494372\n",
      "train loss:0.008996016762120928\n",
      "train loss:0.0010200998571031684\n",
      "train loss:0.04384752602382419\n",
      "train loss:0.04493229097352038\n",
      "train loss:0.0004538447673858581\n",
      "train loss:0.004417897377494049\n",
      "train loss:0.0012428501315125818\n",
      "train loss:0.003838960845619822\n",
      "train loss:0.00044979417060365213\n",
      "train loss:0.004452232040148969\n",
      "train loss:0.05907577245594108\n",
      "train loss:0.012172672049059247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010659186574770853\n",
      "train loss:0.002018204131067151\n",
      "train loss:0.008810226317816826\n",
      "train loss:0.011318979415701352\n",
      "train loss:0.006757274663127401\n",
      "train loss:0.0025898953400191275\n",
      "train loss:0.0023476190939191004\n",
      "train loss:0.003631830646146322\n",
      "train loss:0.02576838030795819\n",
      "train loss:0.03227959195899302\n",
      "train loss:0.004611438810479509\n",
      "train loss:0.024066470056571938\n",
      "train loss:0.014292902024814891\n",
      "train loss:0.005327208765633256\n",
      "train loss:0.007733926993539264\n",
      "train loss:0.0030271791025016574\n",
      "train loss:0.0028853984867785983\n",
      "train loss:0.0012046005766067087\n",
      "train loss:0.005742095449523548\n",
      "train loss:0.0056121064198443515\n",
      "train loss:0.018312010561375124\n",
      "train loss:0.004255560079106635\n",
      "train loss:0.014566678151322277\n",
      "train loss:0.01257532424127707\n",
      "train loss:0.04689780133818837\n",
      "train loss:0.04667620648018222\n",
      "train loss:0.004855474405903544\n",
      "train loss:0.0006391369595997229\n",
      "train loss:0.0005360446172321432\n",
      "train loss:0.005221321187768915\n",
      "train loss:0.007666129658291447\n",
      "train loss:0.0016093214525739613\n",
      "train loss:0.007474267119760142\n",
      "train loss:0.001798586103724398\n",
      "train loss:0.007374681863357983\n",
      "train loss:0.003575749127714314\n",
      "train loss:0.0009682763591744521\n",
      "train loss:0.003984653263883841\n",
      "train loss:0.001563497321701513\n",
      "train loss:0.0043548870721990705\n",
      "train loss:0.0033351761910416873\n",
      "train loss:0.0031164463761580285\n",
      "train loss:0.005992020073942523\n",
      "train loss:0.0032836651230591096\n",
      "train loss:0.006100268879677617\n",
      "train loss:0.004823489086845514\n",
      "train loss:0.01113368267584155\n",
      "train loss:0.007998846967359759\n",
      "train loss:0.0020284669365296278\n",
      "train loss:0.009471443265011016\n",
      "train loss:0.006214705615651695\n",
      "train loss:0.00939902333817226\n",
      "train loss:0.0021421530400234246\n",
      "train loss:0.0016997562714154276\n",
      "train loss:0.008682373465717628\n",
      "train loss:0.0007904332340656284\n",
      "train loss:0.003246499211843906\n",
      "train loss:0.007404644481243392\n",
      "train loss:0.003914814364115626\n",
      "train loss:0.03854195502343303\n",
      "train loss:0.006169887466395476\n",
      "train loss:0.006377038138943481\n",
      "train loss:0.00490710550679071\n",
      "train loss:0.0016236532223683183\n",
      "train loss:0.0013535198340818009\n",
      "train loss:0.0008220379055834462\n",
      "train loss:0.005612021303326209\n",
      "train loss:0.0015809314595954943\n",
      "train loss:0.001779895315503395\n",
      "train loss:0.002674420571131973\n",
      "train loss:0.0008444796836546469\n",
      "train loss:0.0049815596007430725\n",
      "train loss:0.0005728060370125117\n",
      "train loss:0.0005465785248928171\n",
      "train loss:0.004288683239389144\n",
      "train loss:0.005651398440824299\n",
      "train loss:0.003312540571182348\n",
      "train loss:0.003474178489392192\n",
      "train loss:0.00834051788608482\n",
      "train loss:0.0012824483012702245\n",
      "train loss:0.008260572962425336\n",
      "train loss:0.007000039238639791\n",
      "train loss:0.0060667239723722\n",
      "train loss:0.001160128160382588\n",
      "train loss:0.0013264414131292574\n",
      "train loss:0.0033914288616087923\n",
      "train loss:0.0017531943328554082\n",
      "train loss:0.002756514181679651\n",
      "train loss:0.004195512168559134\n",
      "train loss:0.001889421883820268\n",
      "train loss:0.0006233904203683479\n",
      "train loss:0.004742419579312764\n",
      "train loss:0.003440424247340459\n",
      "train loss:0.00311224920795977\n",
      "train loss:0.001415727503633224\n",
      "train loss:0.0012137166531042847\n",
      "train loss:0.021023581917692248\n",
      "train loss:0.0009564063005745528\n",
      "train loss:0.0021917604676783787\n",
      "train loss:0.011223880147167596\n",
      "train loss:0.001350520014352293\n",
      "train loss:0.0015572861542618823\n",
      "train loss:0.00042227729655451324\n",
      "train loss:0.0065585893654337415\n",
      "train loss:0.008288990819508926\n",
      "train loss:0.0022722417699743216\n",
      "train loss:0.005130807859672487\n",
      "train loss:0.0059954158739189125\n",
      "train loss:0.01875619404614538\n",
      "train loss:0.01360512834569414\n",
      "train loss:0.002162326061513279\n",
      "train loss:0.0051454143778373205\n",
      "train loss:0.007834774816767693\n",
      "train loss:0.0023269186607409982\n",
      "train loss:0.0028008414709293746\n",
      "train loss:0.0051140870418548015\n",
      "train loss:0.0010730197839962095\n",
      "train loss:0.01799548397089774\n",
      "train loss:0.00946591093556055\n",
      "train loss:0.0021563633578987767\n",
      "train loss:0.0005145937700502301\n",
      "train loss:0.008591196331894183\n",
      "train loss:0.0019428726470798773\n",
      "train loss:0.0010201270524719025\n",
      "train loss:0.0009895315501748081\n",
      "train loss:0.027112924002431312\n",
      "train loss:0.0035461525441283074\n",
      "train loss:0.0028257386026034714\n",
      "train loss:0.0627676987511248\n",
      "train loss:0.010938917683084734\n",
      "train loss:0.006807697715668431\n",
      "train loss:0.002766319160819091\n",
      "train loss:0.005206699103894085\n",
      "train loss:0.002510439219771163\n",
      "train loss:0.0007507402180673531\n",
      "train loss:0.0041303628762512515\n",
      "train loss:0.0018711677369093358\n",
      "train loss:0.01126337498194516\n",
      "train loss:0.004555211033418427\n",
      "train loss:0.003906858840648456\n",
      "train loss:0.016271410188180114\n",
      "train loss:0.0022731792428100574\n",
      "train loss:0.02229642658247991\n",
      "train loss:0.008224008205668152\n",
      "train loss:0.006371496125773883\n",
      "train loss:0.0034448562101461293\n",
      "train loss:0.0027933090001741245\n",
      "train loss:0.0014840251354295941\n",
      "train loss:0.009157658403414832\n",
      "train loss:0.0063859092881653635\n",
      "train loss:0.005564801146579048\n",
      "train loss:0.0010310357007892565\n",
      "train loss:0.015017940543475005\n",
      "train loss:0.0017291073104099789\n",
      "train loss:0.00213763606055291\n",
      "train loss:0.0038387100701287153\n",
      "train loss:0.011486078948906455\n",
      "train loss:0.0024425832447461226\n",
      "train loss:0.012810092541959075\n",
      "train loss:0.002684264030082266\n",
      "train loss:0.003982782070754632\n",
      "train loss:0.005307891672438283\n",
      "train loss:0.008807475511419605\n",
      "train loss:0.004616633508465111\n",
      "train loss:0.001932764880222322\n",
      "train loss:0.006824140462446884\n",
      "train loss:0.011075792060390055\n",
      "train loss:0.0011962614101711643\n",
      "train loss:0.00470615873590637\n",
      "train loss:0.0032968350845100397\n",
      "train loss:0.004704636951480957\n",
      "train loss:0.005314962074814823\n",
      "train loss:0.0036242012036224363\n",
      "train loss:0.0009929901007636464\n",
      "train loss:0.00828916629353077\n",
      "train loss:0.00242518196851064\n",
      "train loss:0.0846478458770603\n",
      "train loss:0.009428993527260541\n",
      "train loss:0.0013230402209266211\n",
      "train loss:0.0025084523088543813\n",
      "train loss:0.0037651659484702676\n",
      "train loss:0.00032594501940916537\n",
      "train loss:0.010695548593056388\n",
      "train loss:0.005765660283623365\n",
      "train loss:0.0007205580498765271\n",
      "train loss:0.004032026836848191\n",
      "train loss:0.010009917292007372\n",
      "train loss:0.0003629348808592311\n",
      "train loss:0.01327340903007155\n",
      "train loss:0.02572736369221412\n",
      "train loss:0.005035668118288194\n",
      "train loss:0.0021730078329227492\n",
      "train loss:0.0017554944653087098\n",
      "train loss:0.003510835406982889\n",
      "train loss:0.004529343264342187\n",
      "train loss:0.005366502810321881\n",
      "train loss:0.0019155966735074504\n",
      "train loss:0.001563623088005224\n",
      "train loss:0.001133183499819161\n",
      "train loss:0.005977140645793643\n",
      "train loss:0.04415414169547859\n",
      "train loss:0.005928668740565546\n",
      "train loss:0.006715678223038901\n",
      "train loss:0.002024278789266505\n",
      "train loss:0.0011338653575405557\n",
      "train loss:0.0036116867021213244\n",
      "train loss:0.0006390801353281226\n",
      "train loss:0.0023020539203303177\n",
      "train loss:0.008992745761917642\n",
      "train loss:0.002178467712879779\n",
      "train loss:0.003761093344700741\n",
      "train loss:0.001549740754186698\n",
      "train loss:0.03269155542369809\n",
      "train loss:0.005690803518306328\n",
      "train loss:0.057498420359406915\n",
      "train loss:0.0033829587226586683\n",
      "train loss:0.005592695494111661\n",
      "train loss:0.001953335619036373\n",
      "train loss:0.007205306835007511\n",
      "train loss:0.025941152455192386\n",
      "train loss:0.007939724340953965\n",
      "train loss:0.003546194842713913\n",
      "train loss:0.0006628022568902784\n",
      "train loss:0.004317160102162365\n",
      "train loss:0.0017501524635113394\n",
      "train loss:0.0035421077396108314\n",
      "train loss:0.002598936143373288\n",
      "train loss:0.03760425260119744\n",
      "train loss:0.008740710125544308\n",
      "train loss:0.0035599015172936847\n",
      "train loss:0.0018573509482568023\n",
      "train loss:0.022891749402891053\n",
      "train loss:0.005500931336605659\n",
      "train loss:0.02643499422169594\n",
      "train loss:0.006359016495082132\n",
      "train loss:0.003791935176304908\n",
      "train loss:0.001606295797339433\n",
      "train loss:0.0031451210488581045\n",
      "train loss:0.006774514392475986\n",
      "train loss:0.005074427869620189\n",
      "train loss:0.005207371403375718\n",
      "train loss:0.002439788011519935\n",
      "train loss:0.0003314628627290134\n",
      "train loss:0.0031983568192185574\n",
      "train loss:0.00948515781239313\n",
      "train loss:0.003962401244645888\n",
      "train loss:0.0015342391999131294\n",
      "train loss:0.0003853163913050129\n",
      "train loss:0.006623747127144317\n",
      "train loss:0.0029621525619092253\n",
      "train loss:0.049875866896115124\n",
      "train loss:0.01188131654515727\n",
      "train loss:0.004086527400729816\n",
      "train loss:0.0008498833834092657\n",
      "train loss:0.010349101345475226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006421892760137714\n",
      "train loss:0.0048762263796121395\n",
      "train loss:0.0010571592826365821\n",
      "train loss:0.00357870759957059\n",
      "train loss:0.004132877640406958\n",
      "train loss:0.005821598775944174\n",
      "train loss:0.0021376354002508673\n",
      "train loss:0.0044623348224562005\n",
      "train loss:0.0059835171387063145\n",
      "train loss:0.002239742903019091\n",
      "train loss:0.0019017460333642842\n",
      "train loss:0.006881770660116345\n",
      "train loss:0.004484772832089248\n",
      "train loss:0.01799139631102744\n",
      "train loss:0.0181517769221502\n",
      "train loss:0.005779891801859772\n",
      "train loss:0.004549508405922332\n",
      "train loss:0.015326654976731396\n",
      "train loss:0.0008412526248344805\n",
      "train loss:0.009472136074742848\n",
      "train loss:0.0494206599708446\n",
      "train loss:0.009724879059547857\n",
      "train loss:0.029158611081433868\n",
      "train loss:0.00810876304813672\n",
      "train loss:0.09930961130098043\n",
      "train loss:0.001153167629419441\n",
      "train loss:0.0008847126774970329\n",
      "train loss:0.0019034595403094171\n",
      "train loss:0.011990123313080678\n",
      "train loss:0.004734606391212171\n",
      "train loss:0.00597351788663653\n",
      "train loss:0.002693719284679737\n",
      "train loss:0.004644270016874251\n",
      "train loss:0.0030016442760466815\n",
      "train loss:0.00339932253163634\n",
      "train loss:0.0006613225693853212\n",
      "train loss:0.005227243670894841\n",
      "train loss:0.014455050342148359\n",
      "train loss:0.0005009282752666042\n",
      "train loss:0.0017491680224303576\n",
      "train loss:0.04798331418445838\n",
      "train loss:0.0013240685401885823\n",
      "train loss:0.0013572880676503778\n",
      "train loss:0.04495914858140014\n",
      "train loss:0.016496749554221327\n",
      "train loss:0.003757503237194296\n",
      "train loss:0.001543774003549722\n",
      "train loss:0.008517747051220827\n",
      "train loss:0.015155549787046512\n",
      "train loss:0.011251407081027405\n",
      "train loss:0.00444258457441368\n",
      "train loss:0.0171270122642449\n",
      "train loss:0.0008880883087350267\n",
      "train loss:0.0032714843107856328\n",
      "train loss:0.0005201838916795128\n",
      "train loss:0.011069818852614967\n",
      "train loss:0.0019393685797103482\n",
      "train loss:0.003782624869127651\n",
      "train loss:0.0027003731665553384\n",
      "train loss:0.007571074940819361\n",
      "train loss:0.005035067717644758\n",
      "train loss:0.004591153756600338\n",
      "train loss:0.005419376990625001\n",
      "train loss:0.007758417953257478\n",
      "train loss:0.011680304049611592\n",
      "train loss:0.004293507402492166\n",
      "train loss:0.00816020436728262\n",
      "train loss:0.0015292740471740125\n",
      "train loss:0.0026896385341823596\n",
      "train loss:0.002035664659808176\n",
      "train loss:0.006256831150471648\n",
      "train loss:0.006558002996269004\n",
      "train loss:0.010235275965574045\n",
      "train loss:0.0004387294880299861\n",
      "train loss:0.007383129602381202\n",
      "train loss:0.0018794971496723018\n",
      "train loss:0.0031121146269038275\n",
      "train loss:0.0018012090964935298\n",
      "train loss:0.0020915651915372783\n",
      "train loss:0.00513940410299916\n",
      "train loss:0.0019687793544537245\n",
      "train loss:0.00675768688469761\n",
      "train loss:0.004224509289310386\n",
      "train loss:0.008210067803681966\n",
      "train loss:0.0011964381792170607\n",
      "train loss:0.004909113414014852\n",
      "train loss:0.0020438660177522646\n",
      "train loss:0.001856587906946818\n",
      "train loss:0.0032866518563976297\n",
      "train loss:0.0039556885350096075\n",
      "train loss:0.002021207911008983\n",
      "train loss:0.0021854973782329426\n",
      "train loss:0.000771883123241833\n",
      "train loss:0.011134603148610193\n",
      "train loss:0.010857885780621577\n",
      "train loss:0.004440090209190771\n",
      "train loss:0.019068728683750195\n",
      "train loss:0.0019597937503767855\n",
      "train loss:0.07926551904115431\n",
      "train loss:0.0021606942305600796\n",
      "train loss:0.017976737830319563\n",
      "train loss:0.00795227460263777\n",
      "train loss:0.0027050237659050134\n",
      "train loss:0.004810794860590667\n",
      "train loss:0.006899385329226411\n",
      "train loss:0.009987748085142268\n",
      "train loss:0.008405284454120126\n",
      "train loss:0.00639995569531147\n",
      "train loss:0.000753992110762879\n",
      "train loss:0.0005888832744977001\n",
      "train loss:0.0029390095116734157\n",
      "train loss:0.0002782118929524171\n",
      "=== epoch:12, train acc:0.998, test acc:0.989 ===\n",
      "train loss:0.0477488535221903\n",
      "train loss:0.002330581692951842\n",
      "train loss:0.0037404912622092724\n",
      "train loss:0.0014171890629830247\n",
      "train loss:0.000830528778995747\n",
      "train loss:0.0034512701827761083\n",
      "train loss:0.00918659438495521\n",
      "train loss:0.0018405361092072227\n",
      "train loss:0.0035997718684548656\n",
      "train loss:0.0014833537118322344\n",
      "train loss:0.0015942500212737533\n",
      "train loss:0.018531617693403734\n",
      "train loss:0.00046350762489889597\n",
      "train loss:0.00012184723869067389\n",
      "train loss:0.0078109442601800175\n",
      "train loss:0.014968804334808404\n",
      "train loss:0.04823035295103769\n",
      "train loss:0.007855667851005152\n",
      "train loss:0.008274363279478293\n",
      "train loss:0.0061715522359504895\n",
      "train loss:0.027319200812611667\n",
      "train loss:0.0052780375226533635\n",
      "train loss:0.01498055447110773\n",
      "train loss:0.002728449111382372\n",
      "train loss:0.0050443154212666975\n",
      "train loss:0.0009113242664119825\n",
      "train loss:0.00823959580769838\n",
      "train loss:0.0040362639718957045\n",
      "train loss:0.0009047152732750495\n",
      "train loss:0.007723369082980229\n",
      "train loss:0.004031688528354112\n",
      "train loss:0.016336384347200455\n",
      "train loss:0.004750235231926575\n",
      "train loss:0.003145460285113923\n",
      "train loss:0.008565201356243383\n",
      "train loss:0.0013746815439555377\n",
      "train loss:0.0009518335682191074\n",
      "train loss:0.0022068466868395645\n",
      "train loss:0.005730365624561241\n",
      "train loss:0.0038812231440958052\n",
      "train loss:0.0034240063763673547\n",
      "train loss:0.000802327212194466\n",
      "train loss:0.0011862970637731918\n",
      "train loss:0.0015624030779835458\n",
      "train loss:0.0026540466610317313\n",
      "train loss:0.005470342893879187\n",
      "train loss:0.015287130679268594\n",
      "train loss:0.0014225762688927276\n",
      "train loss:0.0019988578004494786\n",
      "train loss:0.001937211338164342\n",
      "train loss:0.01823788381337058\n",
      "train loss:0.06851725479309494\n",
      "train loss:0.00766979851889806\n",
      "train loss:0.008363736507637635\n",
      "train loss:0.005582051772354106\n",
      "train loss:0.0022377838459992786\n",
      "train loss:0.0007976909811707608\n",
      "train loss:0.0032835208835741135\n",
      "train loss:0.003938351134029668\n",
      "train loss:0.005584545584907632\n",
      "train loss:0.01239247130027175\n",
      "train loss:0.00825758506905385\n",
      "train loss:0.0009898281197195736\n",
      "train loss:0.010634516008745942\n",
      "train loss:0.016828339220629353\n",
      "train loss:0.0003558216412806894\n",
      "train loss:0.0026348991624907453\n",
      "train loss:0.007667399589862575\n",
      "train loss:0.0004232886730458381\n",
      "train loss:0.0029708489342275355\n",
      "train loss:0.00475875175439368\n",
      "train loss:0.008080256709413525\n",
      "train loss:0.011720456018347848\n",
      "train loss:0.010868331479823204\n",
      "train loss:0.001125756041914625\n",
      "train loss:0.010689451781596259\n",
      "train loss:0.006454615109367671\n",
      "train loss:0.0013834154613748403\n",
      "train loss:0.002764451479758074\n",
      "train loss:0.015768348954423538\n",
      "train loss:0.0014255822811223263\n",
      "train loss:0.0022585496558201177\n",
      "train loss:0.010404063865277416\n",
      "train loss:0.0008493015147702178\n",
      "train loss:0.0008704677523815007\n",
      "train loss:0.0024107066299483494\n",
      "train loss:0.00822636783284099\n",
      "train loss:0.010144959057563548\n",
      "train loss:0.0023871185925315487\n",
      "train loss:0.004410372299927792\n",
      "train loss:0.017463328107647714\n",
      "train loss:0.0074913673371862\n",
      "train loss:0.0033402595104493338\n",
      "train loss:0.015982813539696532\n",
      "train loss:0.007594344418261673\n",
      "train loss:0.00220284298815062\n",
      "train loss:0.012079806033969478\n",
      "train loss:0.004821083165831822\n",
      "train loss:0.00846825891297173\n",
      "train loss:0.0021667158607428486\n",
      "train loss:0.00841487528362427\n",
      "train loss:0.0003235370379533686\n",
      "train loss:0.003349035903129014\n",
      "train loss:0.0007720228561150829\n",
      "train loss:0.0016229891540527849\n",
      "train loss:0.005924045625994714\n",
      "train loss:0.001300742233559618\n",
      "train loss:0.005979365485034185\n",
      "train loss:0.003886630123313117\n",
      "train loss:0.0033340376996691123\n",
      "train loss:0.01572989726689099\n",
      "train loss:0.0018319225814412954\n",
      "train loss:0.0004589109406180204\n",
      "train loss:0.001823811889223159\n",
      "train loss:0.006385087913147747\n",
      "train loss:0.003225451168180253\n",
      "train loss:0.001130796262726941\n",
      "train loss:0.006073307219981195\n",
      "train loss:0.0013858963282377074\n",
      "train loss:0.001102876085090893\n",
      "train loss:0.0026091658529489004\n",
      "train loss:0.0007486477009201533\n",
      "train loss:0.0017804585585587994\n",
      "train loss:0.002060725892267027\n",
      "train loss:0.0021891756676694026\n",
      "train loss:0.0019064902472922013\n",
      "train loss:0.0053957401957103876\n",
      "train loss:0.004516802440939471\n",
      "train loss:0.004816915053901514\n",
      "train loss:0.00545230997090974\n",
      "train loss:0.001113695818323705\n",
      "train loss:0.0028499346392341558\n",
      "train loss:0.0007111203203315363\n",
      "train loss:0.00021774956017940998\n",
      "train loss:0.0006973419811161886\n",
      "train loss:0.0018659806871092028\n",
      "train loss:0.008264950551979643\n",
      "train loss:0.0034775314711104686\n",
      "train loss:0.003006696701939159\n",
      "train loss:0.0016723737850661755\n",
      "train loss:0.0003827221422572155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00800862473594315\n",
      "train loss:0.00970440168134008\n",
      "train loss:0.0022177695970243853\n",
      "train loss:0.001036302435271295\n",
      "train loss:0.03934434657883955\n",
      "train loss:0.0003408860276111981\n",
      "train loss:0.0057054874440769935\n",
      "train loss:0.006897822264815372\n",
      "train loss:0.0026319936039842073\n",
      "train loss:0.0007031474645516989\n",
      "train loss:0.002214649904942745\n",
      "train loss:0.010241227767147318\n",
      "train loss:0.0014286148870343127\n",
      "train loss:0.001567397016737303\n",
      "train loss:0.008609990937622356\n",
      "train loss:0.0028256916451738856\n",
      "train loss:0.005671899049618702\n",
      "train loss:0.004267006074365023\n",
      "train loss:0.004127934097840178\n",
      "train loss:0.0039057530540683766\n",
      "train loss:0.0007390723114820215\n",
      "train loss:0.001896276593476633\n",
      "train loss:0.008405383098241298\n",
      "train loss:0.00026895284286291573\n",
      "train loss:0.002214655244682833\n",
      "train loss:0.004831514597433978\n",
      "train loss:0.02577608727664079\n",
      "train loss:0.004423625567097357\n",
      "train loss:0.001036679364489971\n",
      "train loss:0.000685529323879759\n",
      "train loss:0.008730648680331483\n",
      "train loss:0.0019184652472884005\n",
      "train loss:0.06097526550870419\n",
      "train loss:0.006108622229043275\n",
      "train loss:0.005698698556147666\n",
      "train loss:0.0019125219914440622\n",
      "train loss:0.0006960248401918403\n",
      "train loss:0.006526062110126981\n",
      "train loss:0.0005060425954599007\n",
      "train loss:0.0032061344526021556\n",
      "train loss:0.004021378455382527\n",
      "train loss:0.0074217418868351755\n",
      "train loss:0.010281800670182542\n",
      "train loss:0.004694293666637467\n",
      "train loss:0.0044736226088720995\n",
      "train loss:0.008104527887548884\n",
      "train loss:0.004926132974623591\n",
      "train loss:0.0012272714947219284\n",
      "train loss:0.0004774630162069087\n",
      "train loss:0.006088153454218616\n",
      "train loss:0.006121610368190693\n",
      "train loss:0.005747448599924343\n",
      "train loss:0.0002557968075785698\n",
      "train loss:0.0043852110616658425\n",
      "train loss:0.008239920319050131\n",
      "train loss:0.003166217501599699\n",
      "train loss:0.0015241431817942447\n",
      "train loss:0.0061244446946131246\n",
      "train loss:0.0016088428386191753\n",
      "train loss:0.003143101892910445\n",
      "train loss:0.0031144460288515608\n",
      "train loss:0.005865827357637009\n",
      "train loss:0.0037095163492538137\n",
      "train loss:0.016595659919245647\n",
      "train loss:0.007543852520632661\n",
      "train loss:0.0022317467110734546\n",
      "train loss:0.0034001374342999408\n",
      "train loss:0.0018617682411916773\n",
      "train loss:0.01464234122486065\n",
      "train loss:0.0021581311938864032\n",
      "train loss:0.0005752061818612162\n",
      "train loss:0.0015034351373081612\n",
      "train loss:0.002596598467053221\n",
      "train loss:0.002328039391538561\n",
      "train loss:0.013046912364857857\n",
      "train loss:0.014335117427274731\n",
      "train loss:0.0033106635484037193\n",
      "train loss:0.001889641178146619\n",
      "train loss:0.015070624106279948\n",
      "train loss:0.014116120724252713\n",
      "train loss:0.0007425674299101751\n",
      "train loss:0.08207726097428532\n",
      "train loss:0.01662042935056483\n",
      "train loss:0.002441161249468848\n",
      "train loss:0.0009072411445835055\n",
      "train loss:0.0023777141299122662\n",
      "train loss:0.0019355069427408628\n",
      "train loss:0.001784541738149568\n",
      "train loss:0.006444410598656806\n",
      "train loss:0.001684541186036745\n",
      "train loss:0.0024558541091377365\n",
      "train loss:0.014492641845875169\n",
      "train loss:0.004294674655789536\n",
      "train loss:0.013904145469183195\n",
      "train loss:0.0021204249620887096\n",
      "train loss:0.013570398168448357\n",
      "train loss:0.0021467629769891757\n",
      "train loss:0.0025530488143203057\n",
      "train loss:0.0004019497943706419\n",
      "train loss:0.005337754309918598\n",
      "train loss:0.013568264204938143\n",
      "train loss:0.0022497436837218983\n",
      "train loss:0.003076922126523625\n",
      "train loss:0.0015491334686118072\n",
      "train loss:0.0006219965347671015\n",
      "train loss:0.0010108516390890292\n",
      "train loss:0.0049750073406697945\n",
      "train loss:0.004434890685551833\n",
      "train loss:0.008612659200084402\n",
      "train loss:0.0026089581410888253\n",
      "train loss:0.003754732968481867\n",
      "train loss:0.00229121800165044\n",
      "train loss:0.0022361317293695475\n",
      "train loss:0.002703794659367501\n",
      "train loss:0.004970191017238858\n",
      "train loss:0.002195196076460329\n",
      "train loss:0.0011997933629066474\n",
      "train loss:0.0014350782139587958\n",
      "train loss:0.049299450611939945\n",
      "train loss:0.019382092219211854\n",
      "train loss:0.001735339825222847\n",
      "train loss:0.0013695018073960233\n",
      "train loss:0.024481622271901208\n",
      "train loss:0.0025875343276978114\n",
      "train loss:0.004278339973183914\n",
      "train loss:0.006341048956328795\n",
      "train loss:0.0030523810637202355\n",
      "train loss:0.030940594960318656\n",
      "train loss:0.003748288565569376\n",
      "train loss:0.0012130259677430597\n",
      "train loss:0.004462244554799005\n",
      "train loss:0.002168768090651555\n",
      "train loss:0.005712367345405058\n",
      "train loss:0.005979564076814499\n",
      "train loss:0.003284863381262338\n",
      "train loss:0.0004411541931798857\n",
      "train loss:0.00610792239389079\n",
      "train loss:0.004313941461609642\n",
      "train loss:0.0042453027886765115\n",
      "train loss:0.00518072476821321\n",
      "train loss:0.0033118291446079863\n",
      "train loss:0.0009756528898763754\n",
      "train loss:0.0005471503050424264\n",
      "train loss:0.006256961339677213\n",
      "train loss:0.005004355493930334\n",
      "train loss:0.0011401569295819763\n",
      "train loss:0.004521338026835613\n",
      "train loss:0.0022634252537244073\n",
      "train loss:0.016730769548121718\n",
      "train loss:0.00025666048374549036\n",
      "train loss:0.0005958455267425835\n",
      "train loss:0.013211568623419713\n",
      "train loss:0.011286969048701962\n",
      "train loss:0.001367778846673856\n",
      "train loss:0.006061935754851803\n",
      "train loss:0.0070942255785441995\n",
      "train loss:0.017903392527951242\n",
      "train loss:0.002174841587588634\n",
      "train loss:0.006299823497928768\n",
      "train loss:0.09522014094068602\n",
      "train loss:0.003260453156709925\n",
      "train loss:0.04966717496713449\n",
      "train loss:0.030458902261446652\n",
      "train loss:0.00236445139180514\n",
      "train loss:0.00460759602760766\n",
      "train loss:0.0013733100965184694\n",
      "train loss:0.010399152665371772\n",
      "train loss:0.002150791954045324\n",
      "train loss:0.004508573473621092\n",
      "train loss:0.022586791647045842\n",
      "train loss:0.0023564658588684085\n",
      "train loss:0.018116454844470893\n",
      "train loss:0.01727211134497487\n",
      "train loss:0.010107918234725516\n",
      "train loss:0.00878520291956828\n",
      "train loss:0.002282684506314701\n",
      "train loss:0.012725775111484143\n",
      "train loss:0.004532134129562005\n",
      "train loss:0.0009467791012377475\n",
      "train loss:0.0036061692074476123\n",
      "train loss:0.0003978268117370211\n",
      "train loss:0.003520897044553828\n",
      "train loss:0.00030002287675381126\n",
      "train loss:0.0059024968084234394\n",
      "train loss:0.0063992115237040195\n",
      "train loss:0.039925029087303915\n",
      "train loss:0.004946260455366332\n",
      "train loss:0.0036059248623830625\n",
      "train loss:0.0012402586228208725\n",
      "train loss:0.0015303181764025002\n",
      "train loss:0.0012548640346351054\n",
      "train loss:0.00207398191618951\n",
      "train loss:0.025314223592633675\n",
      "train loss:0.006587351604171288\n",
      "train loss:0.004656531101558669\n",
      "train loss:0.0007954331873826651\n",
      "train loss:0.0023472770980837495\n",
      "train loss:0.008042130499766827\n",
      "train loss:0.0008511217599307244\n",
      "train loss:0.010562956556531344\n",
      "train loss:0.0027734660344826377\n",
      "train loss:0.015129476561461762\n",
      "train loss:0.0025072135464186116\n",
      "train loss:0.0016392693912989562\n",
      "train loss:0.00043239662175247073\n",
      "train loss:0.0029990981406946655\n",
      "train loss:0.003225897182337723\n",
      "train loss:0.00012183802237770559\n",
      "train loss:0.00011918678515923473\n",
      "train loss:0.004245834617879532\n",
      "train loss:0.0026377942247720844\n",
      "train loss:0.0014484168764280314\n",
      "train loss:0.006587627735980764\n",
      "train loss:0.0007287828894089153\n",
      "train loss:0.004137203068720089\n",
      "train loss:0.009919377645362536\n",
      "train loss:0.01940457303328711\n",
      "train loss:0.005115756372973815\n",
      "train loss:0.008829477522204126\n",
      "train loss:0.002406441921965478\n",
      "train loss:0.008895435384736736\n",
      "train loss:0.00336216042562236\n",
      "train loss:0.006186960102344036\n",
      "train loss:0.0012757670170873015\n",
      "train loss:0.011382300536866395\n",
      "train loss:0.001237494920655223\n",
      "train loss:0.002121854388083039\n",
      "train loss:0.027733609300783845\n",
      "train loss:0.0007492612690134\n",
      "train loss:0.002397101770161366\n",
      "train loss:0.00042663547324443314\n",
      "train loss:0.0011466753302121985\n",
      "train loss:0.0007381968714948214\n",
      "train loss:0.0023985248049498737\n",
      "train loss:0.004794087085202612\n",
      "train loss:0.008312725165483578\n",
      "train loss:0.0009425419153054869\n",
      "train loss:0.005432677135370387\n",
      "train loss:0.002537389586098321\n",
      "train loss:0.003131970000961954\n",
      "train loss:0.004343885707672373\n",
      "train loss:0.022138972879263072\n",
      "train loss:0.002235300977828222\n",
      "train loss:0.005735444218510715\n",
      "train loss:0.01794763918955409\n",
      "train loss:0.010304012647378348\n",
      "train loss:0.003772371885483517\n",
      "train loss:0.002642429542217443\n",
      "train loss:0.007722848257166042\n",
      "train loss:0.0023715211537296997\n",
      "train loss:0.04319872756037773\n",
      "train loss:0.0010423312481767511\n",
      "train loss:0.0008294580431074054\n",
      "train loss:0.0046690487399718384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0373437556294229\n",
      "train loss:0.0018448529271679096\n",
      "train loss:0.001661722481295565\n",
      "train loss:0.010747680921263304\n",
      "train loss:0.000672628832481421\n",
      "train loss:0.006977488406469409\n",
      "train loss:0.0016622804073127405\n",
      "train loss:0.006128891826146981\n",
      "train loss:0.0028303469309577125\n",
      "train loss:0.0025825723665671265\n",
      "train loss:0.015702398025749617\n",
      "train loss:0.01762169404173712\n",
      "train loss:0.0014267021979186023\n",
      "train loss:0.00035598358453875267\n",
      "train loss:0.005657307661684137\n",
      "train loss:0.0035603464059737076\n",
      "train loss:0.004226142482376882\n",
      "train loss:0.0060895246261551805\n",
      "train loss:0.031014486533934862\n",
      "train loss:0.009666896744374825\n",
      "train loss:0.011189896793113274\n",
      "train loss:0.002809209925679299\n",
      "train loss:0.0008486523043587961\n",
      "train loss:0.002115369161276414\n",
      "train loss:0.011701809517857481\n",
      "train loss:0.0022097477279120576\n",
      "train loss:0.0192699005423789\n",
      "train loss:0.0013239926203718947\n",
      "train loss:0.01753917963984769\n",
      "train loss:0.0017638126885789725\n",
      "train loss:0.020614200173812536\n",
      "train loss:0.006715195284845452\n",
      "train loss:0.004547958645164002\n",
      "train loss:0.001001805026853034\n",
      "train loss:0.0005728777070810681\n",
      "train loss:0.003549261453641262\n",
      "train loss:0.0031629753342769166\n",
      "train loss:0.0004159841634518011\n",
      "train loss:0.0014091417181131551\n",
      "train loss:0.001777927515305071\n",
      "train loss:0.0028033550838369487\n",
      "train loss:0.0051870096479597096\n",
      "train loss:0.016278022649511427\n",
      "train loss:0.0014235851926250307\n",
      "train loss:0.004731312894167475\n",
      "train loss:0.001878601705524549\n",
      "train loss:0.0004811931897264849\n",
      "train loss:0.01135664696902764\n",
      "train loss:0.002093878905692175\n",
      "train loss:0.0042376256710304205\n",
      "train loss:0.010832589091839569\n",
      "train loss:0.005629845327401607\n",
      "train loss:0.003819173854279333\n",
      "train loss:0.004291016698258837\n",
      "train loss:0.019633516281920192\n",
      "train loss:0.013214416133457125\n",
      "train loss:0.002317443217324802\n",
      "train loss:0.0018855768060084734\n",
      "train loss:0.0005715824302288663\n",
      "train loss:0.0006544407771404991\n",
      "train loss:0.0044775670762379535\n",
      "train loss:0.0074835974426311225\n",
      "train loss:0.0016056433892933646\n",
      "train loss:0.0075112257348397245\n",
      "train loss:0.0006071254792934602\n",
      "train loss:0.0017517929262994818\n",
      "train loss:0.0010689293769117166\n",
      "train loss:0.0023673858899553126\n",
      "train loss:0.0031731404900893385\n",
      "train loss:0.00021494241604853287\n",
      "train loss:0.01235132517936507\n",
      "train loss:0.004817260414456091\n",
      "train loss:0.008357277662972683\n",
      "train loss:0.0009268389324637831\n",
      "train loss:0.0062445642361332486\n",
      "train loss:0.005636381083526038\n",
      "train loss:0.00421319478135965\n",
      "train loss:0.0018605325080159405\n",
      "train loss:0.0024441669461483326\n",
      "train loss:0.0033365647698770933\n",
      "train loss:0.0029112539526503123\n",
      "train loss:0.004257164981019469\n",
      "train loss:0.0013773487879256258\n",
      "train loss:0.01899428006568974\n",
      "train loss:0.0019931248407466465\n",
      "train loss:0.001412919789769851\n",
      "train loss:0.005647330939826002\n",
      "train loss:0.003165009602800797\n",
      "train loss:0.0022912023074437345\n",
      "train loss:0.002471539741356143\n",
      "train loss:0.0005324309107337618\n",
      "train loss:0.004727366262039711\n",
      "train loss:0.0013908158021585008\n",
      "train loss:0.01056000871772848\n",
      "train loss:0.015219365350610496\n",
      "train loss:0.020214356139088285\n",
      "train loss:0.0035285369993641818\n",
      "train loss:0.007249919132917918\n",
      "train loss:0.022881723596295388\n",
      "train loss:0.0028209979797972577\n",
      "train loss:0.0013356604962666014\n",
      "train loss:0.0034092097388344067\n",
      "train loss:0.006893377746814989\n",
      "train loss:0.006716767016976021\n",
      "train loss:0.019038410966503955\n",
      "train loss:0.0042738831094731805\n",
      "train loss:0.0007929521222634532\n",
      "train loss:0.0019048402667688222\n",
      "train loss:0.004131736226251188\n",
      "train loss:0.0047984298014879315\n",
      "train loss:0.006903257971122918\n",
      "train loss:0.0021527991458353273\n",
      "train loss:0.005658025270756374\n",
      "train loss:0.0014518459226269714\n",
      "train loss:0.008412176107763314\n",
      "train loss:0.004747570367998319\n",
      "train loss:0.01049765167561872\n",
      "train loss:0.012420259066492934\n",
      "train loss:0.0016848646975778491\n",
      "train loss:0.006457423936109141\n",
      "train loss:0.0037965258207721775\n",
      "train loss:0.0002206277982529069\n",
      "train loss:0.0008078569174035631\n",
      "train loss:0.001056527819408284\n",
      "train loss:0.0011158245154243482\n",
      "train loss:0.00044546933179572456\n",
      "train loss:0.009352385862825467\n",
      "train loss:0.0006710514404664418\n",
      "train loss:0.00413878589909474\n",
      "train loss:0.004867333101885682\n",
      "train loss:0.0070031091095369\n",
      "train loss:0.013172698744480802\n",
      "train loss:0.0018832779624093226\n",
      "train loss:0.00870386714865875\n",
      "train loss:0.001480150514620219\n",
      "train loss:0.0026473267618043737\n",
      "train loss:0.009848913957500588\n",
      "train loss:0.0003321402288940362\n",
      "train loss:0.0008417167724495216\n",
      "train loss:0.0009725742317908662\n",
      "train loss:0.003885954072286672\n",
      "train loss:0.005666293633511921\n",
      "train loss:0.020159944272489187\n",
      "train loss:0.001233088915705727\n",
      "train loss:0.007433395914728198\n",
      "train loss:0.01095290145228881\n",
      "train loss:0.004938619995301057\n",
      "train loss:0.002770860353605829\n",
      "train loss:0.002443830158041842\n",
      "train loss:0.0009302910759836463\n",
      "train loss:0.035566107537496464\n",
      "train loss:0.0058647500909623455\n",
      "train loss:0.0011759542528932089\n",
      "train loss:0.004151840137778335\n",
      "train loss:0.005021224145948715\n",
      "train loss:0.007043715436181753\n",
      "train loss:0.0042716301127399435\n",
      "train loss:0.002377768370312344\n",
      "train loss:0.0013932646264015747\n",
      "train loss:0.003018017833695263\n",
      "train loss:0.00491213225447762\n",
      "train loss:0.0018293939723719819\n",
      "train loss:0.0010436490444919477\n",
      "train loss:0.0008774948845703082\n",
      "train loss:0.004761212909880932\n",
      "train loss:0.007706690905323321\n",
      "train loss:0.0015823974693990625\n",
      "train loss:0.003550772425131981\n",
      "train loss:0.0028090353915210336\n",
      "train loss:0.0010958922593444173\n",
      "train loss:0.0047311173857878565\n",
      "train loss:0.0033539877196273717\n",
      "train loss:0.0034245861911402016\n",
      "train loss:0.0038687649976552746\n",
      "train loss:0.0021409323082440717\n",
      "train loss:0.0010831287110133214\n",
      "train loss:0.0051686404081041646\n",
      "train loss:0.0019537300564941473\n",
      "train loss:0.0017261824705286615\n",
      "train loss:0.01113523296500472\n",
      "train loss:0.004407466677569236\n",
      "train loss:0.005901060858391292\n",
      "train loss:0.001028596455823101\n",
      "train loss:0.003840306786106642\n",
      "train loss:0.002589822629870197\n",
      "train loss:0.005959950298208455\n",
      "train loss:0.0032428502066514948\n",
      "train loss:0.00022019256564100246\n",
      "train loss:0.0008261496869820822\n",
      "train loss:0.007221059710035487\n",
      "train loss:0.001670587884889594\n",
      "train loss:0.000603419686403424\n",
      "train loss:0.03243916328047565\n",
      "train loss:0.0024953917595102334\n",
      "train loss:0.010325877641777247\n",
      "train loss:0.0014799119794259826\n",
      "train loss:0.02284971444631588\n",
      "train loss:0.002521996856038852\n",
      "train loss:0.001660350901458055\n",
      "train loss:0.004764743266060155\n",
      "train loss:0.012054438701993297\n",
      "train loss:0.002054443211857055\n",
      "train loss:0.004922789176339206\n",
      "train loss:0.0015060517949930566\n",
      "train loss:0.003681818784253953\n",
      "=== epoch:13, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.0024214853371987517\n",
      "train loss:0.00045637280285942513\n",
      "train loss:0.00021736906062557918\n",
      "train loss:0.0035076411141322767\n",
      "train loss:0.0018121969667366953\n",
      "train loss:0.0007601555438236761\n",
      "train loss:0.0038396326216585757\n",
      "train loss:0.009369492427896038\n",
      "train loss:0.0013822645020545015\n",
      "train loss:0.020965324437187235\n",
      "train loss:0.019291285981848955\n",
      "train loss:0.003360021119772375\n",
      "train loss:0.0006186491149038351\n",
      "train loss:0.0067938762874310684\n",
      "train loss:0.010267688870935036\n",
      "train loss:0.0006219436118407535\n",
      "train loss:0.0063961361331152855\n",
      "train loss:0.0012744068558759902\n",
      "train loss:0.00042397552695634964\n",
      "train loss:0.011189921098854914\n",
      "train loss:0.002274660786633344\n",
      "train loss:0.0043456375826682785\n",
      "train loss:0.0005065523714654303\n",
      "train loss:0.0017329775192288935\n",
      "train loss:0.0021474170232763127\n",
      "train loss:0.005238849183684518\n",
      "train loss:0.001933006167338203\n",
      "train loss:0.0013946855549256687\n",
      "train loss:0.0028462824008223505\n",
      "train loss:0.001475403002985913\n",
      "train loss:0.0038501246098677482\n",
      "train loss:0.005077348062984631\n",
      "train loss:0.007731968030389839\n",
      "train loss:0.0014172862642791964\n",
      "train loss:0.0032279062486387706\n",
      "train loss:0.0035021577196996394\n",
      "train loss:0.0005177118098321146\n",
      "train loss:0.0017271272212027013\n",
      "train loss:0.004585378356573628\n",
      "train loss:0.009437860342442785\n",
      "train loss:0.005817230716598175\n",
      "train loss:0.0014181258395572504\n",
      "train loss:0.004931156403580363\n",
      "train loss:0.0036988009899315143\n",
      "train loss:0.015378819802756405\n",
      "train loss:0.0007348018692715275\n",
      "train loss:0.009070951429648996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010448863003261002\n",
      "train loss:0.0009369882205899485\n",
      "train loss:0.002494204876750322\n",
      "train loss:0.010674702930032138\n",
      "train loss:0.005981706674259823\n",
      "train loss:0.0009717088811914763\n",
      "train loss:0.0005209760907103143\n",
      "train loss:0.0012682232004162922\n",
      "train loss:0.005352174841363903\n",
      "train loss:0.0026216182821356742\n",
      "train loss:0.0008117862023139888\n",
      "train loss:0.0004440423202802317\n",
      "train loss:0.007759731188789577\n",
      "train loss:0.051643444918896206\n",
      "train loss:0.0019748439469558336\n",
      "train loss:0.0178714323873351\n",
      "train loss:0.004467840412733526\n",
      "train loss:0.00045508178787623336\n",
      "train loss:0.0014839261647540678\n",
      "train loss:0.022140922570373672\n",
      "train loss:0.0009409020920057478\n",
      "train loss:0.0027809887383406016\n",
      "train loss:0.005841447449591387\n",
      "train loss:0.02134548374012495\n",
      "train loss:0.006811315018247389\n",
      "train loss:0.007386464968865902\n",
      "train loss:0.0004838700568706513\n",
      "train loss:0.0028622481242602865\n",
      "train loss:0.00022423150139854717\n",
      "train loss:0.0035329420915918407\n",
      "train loss:0.0011925246846354492\n",
      "train loss:0.026030169148099747\n",
      "train loss:0.001693410353706734\n",
      "train loss:0.015491734748239965\n",
      "train loss:0.002205769462466994\n",
      "train loss:0.005718660970435971\n",
      "train loss:0.002365855815671026\n",
      "train loss:0.0009180656897546361\n",
      "train loss:0.0036381981890955435\n",
      "train loss:0.004228310643550466\n",
      "train loss:0.018457203379919563\n",
      "train loss:0.0019406215357407714\n",
      "train loss:0.0008801041966459084\n",
      "train loss:0.0003549811251964055\n",
      "train loss:0.0025561085133159627\n",
      "train loss:0.00306308064063695\n",
      "train loss:0.0029941798773549426\n",
      "train loss:0.001130392667685355\n",
      "train loss:0.001283733617822107\n",
      "train loss:0.04137108957829251\n",
      "train loss:0.0026747823882246695\n",
      "train loss:0.0036879895909289646\n",
      "train loss:0.004960090894205083\n",
      "train loss:0.0048145911877958145\n",
      "train loss:0.001178079668730936\n",
      "train loss:0.003726364815788869\n",
      "train loss:0.003791853014033891\n",
      "train loss:0.0005036661734140152\n",
      "train loss:0.00412880512661001\n",
      "train loss:0.01122832257594957\n",
      "train loss:0.0016161486545929504\n",
      "train loss:0.0010308818945084558\n",
      "train loss:0.03947070589289813\n",
      "train loss:0.002046648657955977\n",
      "train loss:0.0006861914430141854\n",
      "train loss:0.002466686355756584\n",
      "train loss:0.008353332363643344\n",
      "train loss:0.003221933820413243\n",
      "train loss:0.030810012702899767\n",
      "train loss:0.002007441164695595\n",
      "train loss:0.0003023247160475404\n",
      "train loss:0.0030004508888671123\n",
      "train loss:0.006200720671700872\n",
      "train loss:0.003819112738594542\n",
      "train loss:0.0010117423195044612\n",
      "train loss:0.0040967774518339516\n",
      "train loss:0.0007539053976096384\n",
      "train loss:0.0001451747381734256\n",
      "train loss:0.0009646152859647142\n",
      "train loss:0.005841034038666239\n",
      "train loss:0.03980402663537796\n",
      "train loss:0.005347588511994846\n",
      "train loss:0.004201702714580816\n",
      "train loss:0.004131755220232282\n",
      "train loss:0.0063936386420290455\n",
      "train loss:0.001006350741552212\n",
      "train loss:0.00039119543936573005\n",
      "train loss:0.0009004842913566194\n",
      "train loss:0.000600082631901586\n",
      "train loss:0.0047734950083242016\n",
      "train loss:0.005449847860806518\n",
      "train loss:0.0014953388567622847\n",
      "train loss:0.003124121716258774\n",
      "train loss:0.0009173396529869679\n",
      "train loss:0.0034404899384730646\n",
      "train loss:0.003184161833127344\n",
      "train loss:0.0009660920363110164\n",
      "train loss:0.0028499512049534738\n",
      "train loss:0.001670838454718277\n",
      "train loss:0.009004277064414042\n",
      "train loss:0.0012384645687870683\n",
      "train loss:0.004001780425344126\n",
      "train loss:0.0006476948885106823\n",
      "train loss:0.001970190769432047\n",
      "train loss:0.0021391588661505397\n",
      "train loss:0.0011866213182883851\n",
      "train loss:0.033966357598757324\n",
      "train loss:0.0062444513036738845\n",
      "train loss:0.0008605645741443528\n",
      "train loss:0.0024360051378655785\n",
      "train loss:0.0014738738473881955\n",
      "train loss:0.013680402005814543\n",
      "train loss:0.004660463279790451\n",
      "train loss:0.0034809475076012088\n",
      "train loss:0.0005622655142332772\n",
      "train loss:0.036157587995165975\n",
      "train loss:0.013690260284433025\n",
      "train loss:0.0018841028941331641\n",
      "train loss:0.0019251931579557901\n",
      "train loss:0.005999713279340153\n",
      "train loss:0.00462464673691798\n",
      "train loss:0.0017641407372404063\n",
      "train loss:0.003295480094156012\n",
      "train loss:0.0021553471052175514\n",
      "train loss:0.002267555635810416\n",
      "train loss:0.0028097128143172623\n",
      "train loss:0.006906199672918072\n",
      "train loss:0.0025340301794126207\n",
      "train loss:0.04053639020912998\n",
      "train loss:0.002154608290119587\n",
      "train loss:0.004516517260151365\n",
      "train loss:0.0013011451357219028\n",
      "train loss:0.001704586372097988\n",
      "train loss:0.004220491566749808\n",
      "train loss:0.002908775763535093\n",
      "train loss:0.0038397140222161696\n",
      "train loss:0.002964995649317088\n",
      "train loss:0.0029621036038785997\n",
      "train loss:0.0003808799445740882\n",
      "train loss:0.000997227131743042\n",
      "train loss:0.01542064906405886\n",
      "train loss:0.003094184120235976\n",
      "train loss:0.017693074660890443\n",
      "train loss:0.0037420094629303704\n",
      "train loss:0.09395921454306645\n",
      "train loss:0.005996962405232854\n",
      "train loss:0.0002984781711696039\n",
      "train loss:0.009339749602727862\n",
      "train loss:0.0040126107299465604\n",
      "train loss:0.001818446685066365\n",
      "train loss:0.00494710191992269\n",
      "train loss:0.003483293277313691\n",
      "train loss:0.011383361373213038\n",
      "train loss:0.004784418458159263\n",
      "train loss:0.0060980738478057595\n",
      "train loss:0.0026171116782907934\n",
      "train loss:0.0009906384198729232\n",
      "train loss:0.005294547809643719\n",
      "train loss:0.002457534507290306\n",
      "train loss:0.0016000265223725\n",
      "train loss:0.0011961342492050441\n",
      "train loss:0.024815159583912606\n",
      "train loss:0.0034966650335381756\n",
      "train loss:0.0027297123077090796\n",
      "train loss:0.0030610561417220507\n",
      "train loss:0.0013002776458658119\n",
      "train loss:0.007635332708741628\n",
      "train loss:0.0034238712360863555\n",
      "train loss:0.00599222038841909\n",
      "train loss:0.001938921353422968\n",
      "train loss:0.004874144769065016\n",
      "train loss:0.002512853031068704\n",
      "train loss:0.00132733010290787\n",
      "train loss:0.0006550284714885722\n",
      "train loss:0.00221250369538743\n",
      "train loss:0.0013113442731541906\n",
      "train loss:0.005147973749650413\n",
      "train loss:0.0010869824256079142\n",
      "train loss:0.001119238812310164\n",
      "train loss:0.004474844456279107\n",
      "train loss:0.004664102861153404\n",
      "train loss:0.001106032537946482\n",
      "train loss:0.005557995191805892\n",
      "train loss:0.004682278666005891\n",
      "train loss:0.006859383108125897\n",
      "train loss:0.006385575574351114\n",
      "train loss:0.003559773148596462\n",
      "train loss:0.0020106446694454112\n",
      "train loss:0.0065322208065357636\n",
      "train loss:0.001574097635065003\n",
      "train loss:0.002129040126165058\n",
      "train loss:0.00499452852006898\n",
      "train loss:0.016237524249212355\n",
      "train loss:0.0008060245758411851\n",
      "train loss:0.005561767974410875\n",
      "train loss:0.0017147938080443958\n",
      "train loss:0.004548007895395068\n",
      "train loss:0.004998530462428772\n",
      "train loss:0.0020365417653139895\n",
      "train loss:0.004474460104263198\n",
      "train loss:0.003347454157658883\n",
      "train loss:0.04269536734700664\n",
      "train loss:0.0034675780293962665\n",
      "train loss:0.00384378999757941\n",
      "train loss:0.005982363503496647\n",
      "train loss:0.010936894278106804\n",
      "train loss:0.0013147601241460568\n",
      "train loss:0.00043764112044219073\n",
      "train loss:0.00110347976934387\n",
      "train loss:0.0007659665810719477\n",
      "train loss:0.0007894804585536124\n",
      "train loss:0.003853659894158578\n",
      "train loss:0.0013665483931533356\n",
      "train loss:0.004422434055472696\n",
      "train loss:0.00023612543174484146\n",
      "train loss:0.002969820145869711\n",
      "train loss:0.0008983533213504487\n",
      "train loss:0.00024113992399206068\n",
      "train loss:0.0014114748508540459\n",
      "train loss:0.0004149143954256564\n",
      "train loss:0.0014315186115541423\n",
      "train loss:0.0014741934791778933\n",
      "train loss:0.0003083203894663124\n",
      "train loss:0.0006833182108440016\n",
      "train loss:0.0010326993441279071\n",
      "train loss:0.012089267748682181\n",
      "train loss:0.001659208143307781\n",
      "train loss:0.009673587948674093\n",
      "train loss:0.002089490537635192\n",
      "train loss:0.003182065671360765\n",
      "train loss:0.002410946046248794\n",
      "train loss:0.0028740260725200876\n",
      "train loss:0.005086358130079238\n",
      "train loss:0.007910511425584764\n",
      "train loss:0.005432602470190083\n",
      "train loss:0.0005898105789877903\n",
      "train loss:0.004183896101763001\n",
      "train loss:0.0016759165591073075\n",
      "train loss:0.002565095311731188\n",
      "train loss:0.001469459665815006\n",
      "train loss:0.0061631966483155255\n",
      "train loss:0.0003273318865766223\n",
      "train loss:0.0008983609468448664\n",
      "train loss:0.031867344898626165\n",
      "train loss:0.011500301771969248\n",
      "train loss:0.0013042755340305296\n",
      "train loss:0.0003666189973858621\n",
      "train loss:0.0015279805505962322\n",
      "train loss:0.0002457987771055275\n",
      "train loss:0.000757739702747723\n",
      "train loss:0.005031917099933525\n",
      "train loss:0.0008001572155673133\n",
      "train loss:0.015561440472676213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003690318626166964\n",
      "train loss:0.002107702535347456\n",
      "train loss:0.003988556392584493\n",
      "train loss:0.002384648790436094\n",
      "train loss:0.0019202584929268927\n",
      "train loss:0.007208085257383344\n",
      "train loss:0.0006074351114966904\n",
      "train loss:0.00044803488654098574\n",
      "train loss:0.0027899056253733634\n",
      "train loss:0.009366956441404619\n",
      "train loss:0.0019891245720087816\n",
      "train loss:0.0016602566460512864\n",
      "train loss:0.0010820936620576404\n",
      "train loss:0.0021295779136826245\n",
      "train loss:0.0002778216906371868\n",
      "train loss:0.002088253375747172\n",
      "train loss:0.0029119251397955242\n",
      "train loss:0.00522735501372425\n",
      "train loss:0.0036136482733483575\n",
      "train loss:0.0018527371610627414\n",
      "train loss:0.004077332104240774\n",
      "train loss:0.0029744623875125383\n",
      "train loss:0.0010384133791559408\n",
      "train loss:0.0031324398024067278\n",
      "train loss:0.0077921754971760045\n",
      "train loss:0.011104196500876266\n",
      "train loss:0.003262833365666159\n",
      "train loss:0.002214605255944212\n",
      "train loss:0.0010337638886308137\n",
      "train loss:0.0004488564925270971\n",
      "train loss:0.0017290058971490086\n",
      "train loss:0.005653610151735616\n",
      "train loss:0.0008916811546281441\n",
      "train loss:0.006034681294047076\n",
      "train loss:0.016355465959077026\n",
      "train loss:0.03487117640109677\n",
      "train loss:0.005855927161046263\n",
      "train loss:0.0014956973124897674\n",
      "train loss:0.0026434747302108595\n",
      "train loss:0.008443140327432354\n",
      "train loss:0.010122322365295356\n",
      "train loss:0.004448275734568277\n",
      "train loss:0.00033168598296808607\n",
      "train loss:0.01028634738837417\n",
      "train loss:0.007582150453302989\n",
      "train loss:0.003146313664993917\n",
      "train loss:0.0010584855700143416\n",
      "train loss:0.057776174603093755\n",
      "train loss:0.000991811388941507\n",
      "train loss:0.007296321867375904\n",
      "train loss:0.0009566613147882912\n",
      "train loss:0.004065043567596574\n",
      "train loss:0.005805349821705437\n",
      "train loss:0.001759585897703627\n",
      "train loss:0.004484386867400104\n",
      "train loss:0.0013026418637602439\n",
      "train loss:0.002026059028257079\n",
      "train loss:0.010719616249557777\n",
      "train loss:0.0033228875125976337\n",
      "train loss:0.006108640440345602\n",
      "train loss:0.008997735285625214\n",
      "train loss:0.003956817424661829\n",
      "train loss:0.005068592830467009\n",
      "train loss:0.005512350218432193\n",
      "train loss:0.0036114716235081303\n",
      "train loss:0.0010195654492854906\n",
      "train loss:0.029329494683393523\n",
      "train loss:0.00022375424241755665\n",
      "train loss:0.0017869460088887675\n",
      "train loss:0.0022902723949268827\n",
      "train loss:0.0034128787202632165\n",
      "train loss:0.001448355407205388\n",
      "train loss:0.006457354418729317\n",
      "train loss:8.505973346060983e-05\n",
      "train loss:0.0014534079605645583\n",
      "train loss:0.0017674126420158403\n",
      "train loss:0.003807658452111592\n",
      "train loss:0.0014579404686995126\n",
      "train loss:0.0032344513494149936\n",
      "train loss:0.008600052592007763\n",
      "train loss:0.033031313137599556\n",
      "train loss:0.0002544582385281064\n",
      "train loss:0.0006986033766919375\n",
      "train loss:0.002808663544478584\n",
      "train loss:0.0024534766090251407\n",
      "train loss:0.004855898673305366\n",
      "train loss:0.0029126224449614034\n",
      "train loss:0.0007488880913500299\n",
      "train loss:0.0031856830221777743\n",
      "train loss:0.0005184068651482188\n",
      "train loss:0.0003043671684228817\n",
      "train loss:0.0024710244473076896\n",
      "train loss:0.005051213627125371\n",
      "train loss:0.0005846709453183535\n",
      "train loss:0.0014007235112426096\n",
      "train loss:0.0007278638853903026\n",
      "train loss:0.0038643529387552738\n",
      "train loss:0.0023492658525660366\n",
      "train loss:0.009263334732073103\n",
      "train loss:0.002851404615687534\n",
      "train loss:0.0007683464353786956\n",
      "train loss:0.02566347405182653\n",
      "train loss:0.007340595806868834\n",
      "train loss:0.0005690549041519593\n",
      "train loss:0.00347083237963204\n",
      "train loss:0.00019611207735429262\n",
      "train loss:0.007865808450234577\n",
      "train loss:0.005328344539273031\n",
      "train loss:0.00025635791787335645\n",
      "train loss:0.005778435491514253\n",
      "train loss:0.035843282852412464\n",
      "train loss:0.0022135959509838993\n",
      "train loss:0.002839905926390139\n",
      "train loss:0.0009599422937008949\n",
      "train loss:0.0019063610687562354\n",
      "train loss:0.0005151095779000145\n",
      "train loss:0.0007598130565155375\n",
      "train loss:0.0011190109416420921\n",
      "train loss:0.0017160567471341882\n",
      "train loss:0.00700227148320002\n",
      "train loss:0.0012406219499163942\n",
      "train loss:0.0037470862098922773\n",
      "train loss:0.000494146359427355\n",
      "train loss:0.00041766519658738516\n",
      "train loss:0.003061777127900053\n",
      "train loss:0.0002742447493011604\n",
      "train loss:0.005113093735032329\n",
      "train loss:0.001585153044831711\n",
      "train loss:0.0003326168009887891\n",
      "train loss:0.0003801926564186225\n",
      "train loss:0.013718285547345593\n",
      "train loss:0.0004620789577870622\n",
      "train loss:0.004705520685182297\n",
      "train loss:0.008434650079252719\n",
      "train loss:0.009041503044881806\n",
      "train loss:0.007357681059475365\n",
      "train loss:0.0023484590804553813\n",
      "train loss:0.0012416018095647962\n",
      "train loss:0.0016435807745690404\n",
      "train loss:0.0025745003406976246\n",
      "train loss:0.002368078932619066\n",
      "train loss:0.001651422849964275\n",
      "train loss:0.005054608834552079\n",
      "train loss:0.014857765790506986\n",
      "train loss:0.00953961187441457\n",
      "train loss:0.007936245102344714\n",
      "train loss:0.0015334779324703096\n",
      "train loss:0.005841664224036539\n",
      "train loss:0.007056822841084682\n",
      "train loss:0.0018390277365248008\n",
      "train loss:0.00041722024457591626\n",
      "train loss:0.0023003575147948993\n",
      "train loss:0.007301088483733437\n",
      "train loss:0.0010683697035638708\n",
      "train loss:0.0036021080663335143\n",
      "train loss:0.002581519827191206\n",
      "train loss:0.016250098291844848\n",
      "train loss:0.0017086127991541094\n",
      "train loss:0.0012286314743969718\n",
      "train loss:0.003620171910414916\n",
      "train loss:0.00883380807915845\n",
      "train loss:0.002356661198230814\n",
      "train loss:0.0015577541236367442\n",
      "train loss:0.012214496977600691\n",
      "train loss:0.0024794878269453896\n",
      "train loss:0.0008019106178315716\n",
      "train loss:0.0011256546646815366\n",
      "train loss:0.0008892202786060879\n",
      "train loss:0.0009257355755141109\n",
      "train loss:0.001373657966844527\n",
      "train loss:0.000588409567045844\n",
      "train loss:0.0008920254656463675\n",
      "train loss:0.0035352221822224205\n",
      "train loss:0.005370722904516151\n",
      "train loss:0.003450614461950519\n",
      "train loss:0.0022127776918488638\n",
      "train loss:0.0014790518905708583\n",
      "train loss:0.0034852013384634563\n",
      "train loss:0.005256733754592312\n",
      "train loss:0.05290958081402514\n",
      "train loss:0.00156654817495928\n",
      "train loss:0.0016377534212709802\n",
      "train loss:0.0010147118077654077\n",
      "train loss:0.0008582528768760494\n",
      "train loss:0.007110378135218162\n",
      "train loss:0.0035045903850206457\n",
      "train loss:0.011539249168500685\n",
      "train loss:0.0029673507840414985\n",
      "train loss:0.00230095116399228\n",
      "train loss:0.0015239590850827807\n",
      "train loss:0.0004209741880699129\n",
      "train loss:0.0033609429379809147\n",
      "train loss:0.0003198559304798638\n",
      "train loss:0.004225439799609081\n",
      "train loss:0.0007876642245138414\n",
      "train loss:0.0010667336641359047\n",
      "train loss:0.00026649432555340334\n",
      "train loss:0.005392008791210031\n",
      "train loss:0.0015837414715755118\n",
      "train loss:0.003943515778950899\n",
      "train loss:0.00396248628540378\n",
      "train loss:0.0028569118704282344\n",
      "train loss:0.0010855734181398988\n",
      "train loss:0.01567607417155039\n",
      "train loss:0.0046756127464685875\n",
      "train loss:0.0015632080313069704\n",
      "train loss:0.00551042276735462\n",
      "train loss:0.005282809807349575\n",
      "train loss:0.011053801869192253\n",
      "train loss:0.00013793317546814042\n",
      "train loss:0.0022638652976513765\n",
      "train loss:0.0026413116499115004\n",
      "train loss:0.002179944040032847\n",
      "train loss:0.0008617342916617754\n",
      "train loss:0.0037865308112196637\n",
      "train loss:0.03375024779389348\n",
      "train loss:0.0030061541263881088\n",
      "train loss:0.00222148865053013\n",
      "train loss:0.001118287473759759\n",
      "train loss:0.0010100514728214529\n",
      "train loss:0.002645510696190115\n",
      "train loss:0.0023491302723187613\n",
      "train loss:0.004002707681316859\n",
      "train loss:0.002799711984801891\n",
      "train loss:0.0008269090579284421\n",
      "train loss:0.0014349793582973012\n",
      "train loss:0.003971727262655521\n",
      "train loss:0.0025988466969493803\n",
      "train loss:0.008500882890995874\n",
      "train loss:0.03439212674472854\n",
      "train loss:0.006808878055205467\n",
      "train loss:0.0013033196844669146\n",
      "train loss:0.0009005645750229805\n",
      "train loss:0.0037093116110309926\n",
      "train loss:0.0015155537108291941\n",
      "train loss:0.0015885319151088097\n",
      "train loss:0.00228934772263664\n",
      "train loss:0.006907804963036426\n",
      "train loss:0.0007158733136346804\n",
      "train loss:0.001261395167433402\n",
      "train loss:0.001057244397718042\n",
      "train loss:0.0028301755170684214\n",
      "train loss:0.003944454816057841\n",
      "train loss:0.0011681905659310533\n",
      "train loss:0.0026020734619331075\n",
      "train loss:0.015966516918353758\n",
      "train loss:0.007422084233461841\n",
      "train loss:0.004505250738599095\n",
      "train loss:0.0017581459332388838\n",
      "train loss:0.0004603953954437295\n",
      "train loss:0.0008929919777101153\n",
      "train loss:0.000997068860713554\n",
      "train loss:0.0031119911843791874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0029374171060234182\n",
      "train loss:0.025854807841901542\n",
      "train loss:0.00017426897468330568\n",
      "train loss:0.005722844675608515\n",
      "train loss:0.017202228042411737\n",
      "train loss:0.00014130404945420037\n",
      "train loss:0.003979950726841108\n",
      "train loss:0.0022182539090628162\n",
      "train loss:0.0031271141911074535\n",
      "train loss:0.0008691177423911537\n",
      "train loss:0.0004976197897181494\n",
      "train loss:0.001391665597623492\n",
      "train loss:0.0020363706649081594\n",
      "train loss:0.018173551424299585\n",
      "train loss:0.0015155794133702557\n",
      "train loss:0.0017194751494320518\n",
      "train loss:0.0014337598688586156\n",
      "train loss:0.001209972710850502\n",
      "train loss:0.0009686386625181749\n",
      "train loss:0.0006290587835278723\n",
      "train loss:0.00726526829731217\n",
      "train loss:0.00546960856278178\n",
      "train loss:0.002008986541953324\n",
      "train loss:0.0221031439194899\n",
      "train loss:0.0018889887264985697\n",
      "train loss:0.005062241431142094\n",
      "train loss:0.001156721801515276\n",
      "train loss:0.0005517487992540118\n",
      "train loss:0.0059171746063782504\n",
      "train loss:0.0018061457629244874\n",
      "train loss:0.0016036275452174745\n",
      "train loss:0.0037100320737488857\n",
      "train loss:0.009479530688539378\n",
      "train loss:0.0031488621128213435\n",
      "train loss:0.0014354730218173125\n",
      "train loss:0.0064754390572403465\n",
      "train loss:0.0004921276636847511\n",
      "train loss:0.0024374315322217917\n",
      "train loss:0.005163772553545606\n",
      "train loss:0.07282429930385954\n",
      "train loss:0.0005467595247798683\n",
      "train loss:0.0010998089406763425\n",
      "train loss:0.000268791215469073\n",
      "train loss:0.0009758706857157185\n",
      "train loss:0.004062239534189181\n",
      "train loss:0.0017582611862873882\n",
      "train loss:0.005403532209915256\n",
      "=== epoch:14, train acc:0.997, test acc:0.986 ===\n",
      "train loss:0.002744139412627627\n",
      "train loss:0.0005392285263839573\n",
      "train loss:0.0019764184776133805\n",
      "train loss:0.002110896146971963\n",
      "train loss:0.0054190499296129565\n",
      "train loss:0.023787024929736188\n",
      "train loss:0.0006894251439976645\n",
      "train loss:0.01480174974191882\n",
      "train loss:0.004290813333176999\n",
      "train loss:0.0018023402796859091\n",
      "train loss:0.0007020712972064178\n",
      "train loss:0.009609322163244135\n",
      "train loss:0.0062463865301459745\n",
      "train loss:0.003202804569304338\n",
      "train loss:0.006507588752642187\n",
      "train loss:9.873511817204933e-05\n",
      "train loss:0.00493738004701661\n",
      "train loss:0.0014321497619249573\n",
      "train loss:0.0013992329319390511\n",
      "train loss:0.001769669718310181\n",
      "train loss:0.0011689403181038439\n",
      "train loss:0.0037173521031629974\n",
      "train loss:0.00026433935651524093\n",
      "train loss:0.020029143977091834\n",
      "train loss:0.0013294838591711173\n",
      "train loss:0.0073671450810359786\n",
      "train loss:0.0005063333289886416\n",
      "train loss:0.012189134613479013\n",
      "train loss:0.000951140239965386\n",
      "train loss:0.00010055162498767448\n",
      "train loss:0.011431496603157816\n",
      "train loss:0.006249273306613206\n",
      "train loss:0.004892983611066777\n",
      "train loss:0.013008003883677788\n",
      "train loss:0.0019127927148632632\n",
      "train loss:0.0013772226136920095\n",
      "train loss:0.0006025903234467936\n",
      "train loss:0.0012228409726278316\n",
      "train loss:0.0009092022470216911\n",
      "train loss:0.09786767071474638\n",
      "train loss:0.002396404117273145\n",
      "train loss:0.011832437460564383\n",
      "train loss:0.00964021908243261\n",
      "train loss:0.0063580585760156984\n",
      "train loss:0.009598197517351314\n",
      "train loss:0.002106079053461769\n",
      "train loss:0.007457147209158748\n",
      "train loss:0.0017588561266555852\n",
      "train loss:0.0021341510619588265\n",
      "train loss:0.004094509144350117\n",
      "train loss:0.0045211152984726225\n",
      "train loss:0.021594481775991468\n",
      "train loss:0.003401125614202844\n",
      "train loss:0.003042445082435749\n",
      "train loss:0.011626042243948349\n",
      "train loss:0.0002438431743057335\n",
      "train loss:0.003055303464816764\n",
      "train loss:0.0030711351605794894\n",
      "train loss:0.0015570881555407273\n",
      "train loss:0.0031397296799509345\n",
      "train loss:0.004701271010738753\n",
      "train loss:0.0032840763583868683\n",
      "train loss:0.00814185353557023\n",
      "train loss:0.02073410322220734\n",
      "train loss:0.009273156410572681\n",
      "train loss:0.0025547131473266653\n",
      "train loss:0.0029032860914332643\n",
      "train loss:0.0030314911052234834\n",
      "train loss:0.032859285678870115\n",
      "train loss:0.0002054717169725417\n",
      "train loss:0.005361061456950039\n",
      "train loss:0.004018102160919097\n",
      "train loss:0.002394764955040592\n",
      "train loss:0.0033789632551881952\n",
      "train loss:0.004499096986723986\n",
      "train loss:0.037902842886573015\n",
      "train loss:0.00026747091487959137\n",
      "train loss:0.00358924991668235\n",
      "train loss:0.004118085048092352\n",
      "train loss:0.001734221313509987\n",
      "train loss:0.005409639869228113\n",
      "train loss:0.0004443711241175404\n",
      "train loss:0.004524645579980776\n",
      "train loss:0.0009691570378281246\n",
      "train loss:0.005862980807160228\n",
      "train loss:0.005757823120739541\n",
      "train loss:0.0011462544843808481\n",
      "train loss:0.026167616964360416\n",
      "train loss:0.004055421208082086\n",
      "train loss:0.001893728031031938\n",
      "train loss:0.0036805996540503682\n",
      "train loss:0.0048301883551826125\n",
      "train loss:0.0016636876704163364\n",
      "train loss:0.002852849969770386\n",
      "train loss:0.0013204345793854475\n",
      "train loss:0.004329594203945493\n",
      "train loss:0.00032930483493895846\n",
      "train loss:0.0030837968615082412\n",
      "train loss:0.0060096067597374715\n",
      "train loss:0.00235142771269203\n",
      "train loss:0.005170516134997417\n",
      "train loss:0.012852774063611431\n",
      "train loss:0.0010496755381616087\n",
      "train loss:0.0032348670959042314\n",
      "train loss:0.006206726461568569\n",
      "train loss:0.0006931282679981911\n",
      "train loss:0.02888380954575775\n",
      "train loss:0.0011707264672140643\n",
      "train loss:0.0005377993529327432\n",
      "train loss:0.0007310344387828503\n",
      "train loss:0.0032707861255944393\n",
      "train loss:0.003744264909277326\n",
      "train loss:0.007816027226405946\n",
      "train loss:0.0007232311093657394\n",
      "train loss:0.0027239687265685343\n",
      "train loss:0.003569303945694515\n",
      "train loss:0.0006394450428373727\n",
      "train loss:0.0019451971802764657\n",
      "train loss:0.002531365246392533\n",
      "train loss:0.001059768028015061\n",
      "train loss:0.004113653920586739\n",
      "train loss:0.0014156999151795635\n",
      "train loss:0.001044974358495034\n",
      "train loss:0.0004076587151258915\n",
      "train loss:0.0007318927577417589\n",
      "train loss:0.006250551288820713\n",
      "train loss:0.0015931519168367364\n",
      "train loss:0.0017714613741185916\n",
      "train loss:0.01477569862049661\n",
      "train loss:0.0012868699371151883\n",
      "train loss:0.0008864592860911797\n",
      "train loss:0.004826632380298853\n",
      "train loss:0.0046332133756255365\n",
      "train loss:0.0014365157563115496\n",
      "train loss:0.0028730029960360405\n",
      "train loss:0.004791456194471303\n",
      "train loss:0.0015861348981442884\n",
      "train loss:0.0014960191521918575\n",
      "train loss:0.001761073941019867\n",
      "train loss:0.0003251877573720336\n",
      "train loss:0.006508022750104326\n",
      "train loss:0.00404323777800153\n",
      "train loss:0.0006239721582137664\n",
      "train loss:0.0009612628627112135\n",
      "train loss:0.0017796658578458256\n",
      "train loss:0.0006539079653665263\n",
      "train loss:0.002354592698358526\n",
      "train loss:0.00264841785688997\n",
      "train loss:0.0002635089813254995\n",
      "train loss:0.0018512201795761064\n",
      "train loss:0.009278871303094986\n",
      "train loss:0.00024487764489626205\n",
      "train loss:0.0022418948026158435\n",
      "train loss:0.02678700560022945\n",
      "train loss:0.0002717505412133592\n",
      "train loss:0.0008621499599880986\n",
      "train loss:0.0015151528235829046\n",
      "train loss:0.0021434446386617563\n",
      "train loss:0.0014499862617898074\n",
      "train loss:0.0008575098929971757\n",
      "train loss:0.003962657518268655\n",
      "train loss:0.006733445878046854\n",
      "train loss:0.001364260860628676\n",
      "train loss:0.016676962237860672\n",
      "train loss:0.002279391529697485\n",
      "train loss:0.00482769781000043\n",
      "train loss:0.006755402502391837\n",
      "train loss:0.00036067077697970025\n",
      "train loss:0.0003633692882937294\n",
      "train loss:0.002526505413383365\n",
      "train loss:0.0013604282753008042\n",
      "train loss:0.006587547682447573\n",
      "train loss:0.0022217004862448834\n",
      "train loss:0.0021554198922018684\n",
      "train loss:0.002261929563152307\n",
      "train loss:0.002128427351917662\n",
      "train loss:0.0027963139088869934\n",
      "train loss:0.004171364199444798\n",
      "train loss:0.0010766439151447434\n",
      "train loss:0.01055156577099404\n",
      "train loss:0.0007525143858464591\n",
      "train loss:0.003777934762468681\n",
      "train loss:0.009617435170542183\n",
      "train loss:0.0010693393322996046\n",
      "train loss:0.0007459853159124425\n",
      "train loss:0.001911011037259311\n",
      "train loss:0.006386189546567758\n",
      "train loss:0.003055495762566557\n",
      "train loss:0.01128974171454876\n",
      "train loss:0.00022900236630056566\n",
      "train loss:0.0005348715709375734\n",
      "train loss:0.0022161643982209563\n",
      "train loss:0.002197218557207699\n",
      "train loss:0.005468690188960658\n",
      "train loss:0.0012679864591348873\n",
      "train loss:0.0027508200249170374\n",
      "train loss:0.001453979391583981\n",
      "train loss:0.006482212190076164\n",
      "train loss:0.0018116601974999314\n",
      "train loss:0.004256610332635871\n",
      "train loss:0.012993860223313936\n",
      "train loss:0.0029323995143080346\n",
      "train loss:0.0013349723431419025\n",
      "train loss:0.001980838418209521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010135380490554275\n",
      "train loss:0.005003706488269042\n",
      "train loss:0.0010359490386209695\n",
      "train loss:0.0022587955133607364\n",
      "train loss:0.003965177417013901\n",
      "train loss:0.0014529139356640097\n",
      "train loss:0.006621725204312157\n",
      "train loss:0.00033128139852996397\n",
      "train loss:0.0007259193599961827\n",
      "train loss:0.0004753228346836755\n",
      "train loss:0.0010780117186057522\n",
      "train loss:0.0021033416892173745\n",
      "train loss:0.0030046634679523464\n",
      "train loss:0.006161289975127085\n",
      "train loss:0.0002699587669021692\n",
      "train loss:0.0011493587533925721\n",
      "train loss:0.0054644956188522175\n",
      "train loss:8.867139210511826e-05\n",
      "train loss:0.005531404249039588\n",
      "train loss:0.005747321113374029\n",
      "train loss:0.0007704052800598376\n",
      "train loss:0.014747536195934961\n",
      "train loss:0.0020773175929512306\n",
      "train loss:0.003610192660721218\n",
      "train loss:0.001818190069561106\n",
      "train loss:0.0028290903409703403\n",
      "train loss:0.0006015915151120905\n",
      "train loss:0.004050069535557456\n",
      "train loss:0.000968613169309476\n",
      "train loss:0.0024714688701587394\n",
      "train loss:0.006254870642349149\n",
      "train loss:0.0022883989407131923\n",
      "train loss:0.010490294529001203\n",
      "train loss:0.000614222605196223\n",
      "train loss:0.00301397054685732\n",
      "train loss:0.007823505780489445\n",
      "train loss:0.004153298743507343\n",
      "train loss:0.00012233895488760792\n",
      "train loss:0.014066364421581903\n",
      "train loss:0.006642231227266108\n",
      "train loss:0.0005111873788478314\n",
      "train loss:0.0021262599021080785\n",
      "train loss:0.006526949367595081\n",
      "train loss:0.0017538513485068502\n",
      "train loss:0.00025978906280836774\n",
      "train loss:0.0038912006795154973\n",
      "train loss:0.0033091832432558628\n",
      "train loss:0.0026610397515238107\n",
      "train loss:0.0023071892424398658\n",
      "train loss:0.0014232815702701562\n",
      "train loss:0.005857263752537197\n",
      "train loss:0.004227739030140713\n",
      "train loss:0.0015526581850112584\n",
      "train loss:0.00027753415534278124\n",
      "train loss:0.004047677759830117\n",
      "train loss:0.0006907069449631366\n",
      "train loss:0.0054828145632749604\n",
      "train loss:0.0010725552127530832\n",
      "train loss:0.0010161324783732727\n",
      "train loss:0.001733183484952153\n",
      "train loss:0.0012110074212298087\n",
      "train loss:0.0023669891099975743\n",
      "train loss:0.006920302422470239\n",
      "train loss:0.0046070146417212295\n",
      "train loss:0.0006961149904667127\n",
      "train loss:0.0003686194611004505\n",
      "train loss:0.0012475523697941414\n",
      "train loss:0.000314395588312627\n",
      "train loss:0.0007428665066998275\n",
      "train loss:0.0008597624543258786\n",
      "train loss:0.0014370904681935293\n",
      "train loss:0.00047463105143022725\n",
      "train loss:0.0025037960362635408\n",
      "train loss:0.0007412826419906933\n",
      "train loss:0.00019895611879150517\n",
      "train loss:0.0032971003217443164\n",
      "train loss:8.861307059821735e-05\n",
      "train loss:0.0006398628131612297\n",
      "train loss:0.002280263004464893\n",
      "train loss:0.0003483812219217368\n",
      "train loss:0.00026084502207111615\n",
      "train loss:0.002441499874257001\n",
      "train loss:0.002163775655556067\n",
      "train loss:0.0012219349432644503\n",
      "train loss:0.0006721208421485777\n",
      "train loss:9.886914577376768e-05\n",
      "train loss:0.0004808543213114111\n",
      "train loss:0.0002626873188512248\n",
      "train loss:0.0032414008825129557\n",
      "train loss:0.0028880637694388067\n",
      "train loss:0.000790402423600059\n",
      "train loss:0.0002993746522613456\n",
      "train loss:0.00033309741059613367\n",
      "train loss:0.002444189517820557\n",
      "train loss:0.001231897886825937\n",
      "train loss:0.0012742374334612562\n",
      "train loss:0.00045056274163453986\n",
      "train loss:0.002912140319247622\n",
      "train loss:0.0027275420862125145\n",
      "train loss:0.001742705643382286\n",
      "train loss:0.00037185420736386183\n",
      "train loss:0.00021853502952941167\n",
      "train loss:0.0022276181367532665\n",
      "train loss:0.0019727482401716095\n",
      "train loss:0.0007409976370231533\n",
      "train loss:0.0006611556606663792\n",
      "train loss:0.0007465501622393252\n",
      "train loss:0.000166157618392099\n",
      "train loss:0.00017868326828428114\n",
      "train loss:0.003647539709096545\n",
      "train loss:0.003510880858198409\n",
      "train loss:0.0015246916772625701\n",
      "train loss:0.001171341842828573\n",
      "train loss:0.002860130565659308\n",
      "train loss:0.0008325342963269934\n",
      "train loss:0.00044296793310859257\n",
      "train loss:0.0016564847224227136\n",
      "train loss:0.0036894385263525416\n",
      "train loss:0.0021911250875345355\n",
      "train loss:0.00023796875035256293\n",
      "train loss:0.0011161223813893845\n",
      "train loss:0.0011360587713616513\n",
      "train loss:0.0024601612225485705\n",
      "train loss:0.012575554080204079\n",
      "train loss:0.00029391333698821265\n",
      "train loss:0.004266367562272205\n",
      "train loss:7.722549352330994e-05\n",
      "train loss:0.0019228712921332868\n",
      "train loss:0.0032254582790323155\n",
      "train loss:0.0007617415449918555\n",
      "train loss:0.0003147461491567987\n",
      "train loss:0.0017411659915914468\n",
      "train loss:0.0021964349793909396\n",
      "train loss:0.0003544022978775533\n",
      "train loss:0.0018624533327582288\n",
      "train loss:0.0010192633333259331\n",
      "train loss:5.93329764905852e-05\n",
      "train loss:0.0008776727984281798\n",
      "train loss:0.0039001739650513074\n",
      "train loss:0.01824312406053634\n",
      "train loss:0.0017474965181239516\n",
      "train loss:0.00029997585139986154\n",
      "train loss:0.0011381637806352962\n",
      "train loss:0.0013736246553958597\n",
      "train loss:0.001399619136729752\n",
      "train loss:0.015858345698085644\n",
      "train loss:0.00047479905566768957\n",
      "train loss:0.0006586299568826984\n",
      "train loss:0.0003813444059013755\n",
      "train loss:0.004422741662391888\n",
      "train loss:0.000590838409152692\n",
      "train loss:0.002290162472209864\n",
      "train loss:0.0006247845891031726\n",
      "train loss:0.00012108708765201417\n",
      "train loss:0.0007843269720332112\n",
      "train loss:0.0014485021602896348\n",
      "train loss:0.0023923248261736234\n",
      "train loss:0.0009356402405159564\n",
      "train loss:0.02236708278487722\n",
      "train loss:0.0005771616721542851\n",
      "train loss:0.00014283251286969798\n",
      "train loss:0.001860291425342023\n",
      "train loss:0.0002804449473261012\n",
      "train loss:0.0005826082399629221\n",
      "train loss:0.002304030540335556\n",
      "train loss:0.0006316654026995462\n",
      "train loss:0.0012671556332724961\n",
      "train loss:0.005533786799278775\n",
      "train loss:0.0038702637209634717\n",
      "train loss:0.0007158705070730824\n",
      "train loss:0.0023918652110301937\n",
      "train loss:5.6127338963858785e-05\n",
      "train loss:0.02175332772377471\n",
      "train loss:0.0013037997399802962\n",
      "train loss:0.0025392752707720134\n",
      "train loss:0.0009224497863072555\n",
      "train loss:0.0012796457080768925\n",
      "train loss:0.0023243889350396383\n",
      "train loss:0.0015806771139162002\n",
      "train loss:8.680900831780557e-05\n",
      "train loss:0.005548563380690108\n",
      "train loss:0.013330818004628668\n",
      "train loss:0.005712027433421284\n",
      "train loss:0.0038856917013743763\n",
      "train loss:0.0004465235217816532\n",
      "train loss:0.0016556970140331276\n",
      "train loss:0.004413302149566059\n",
      "train loss:0.0012328953648368304\n",
      "train loss:0.029857654612639024\n",
      "train loss:0.0012303802571817847\n",
      "train loss:0.004522259992148086\n",
      "train loss:0.003403684082628277\n",
      "train loss:0.0001469525516984817\n",
      "train loss:0.0015726449307064741\n",
      "train loss:0.005094246237019988\n",
      "train loss:0.0014596198583389352\n",
      "train loss:0.0007954637793469016\n",
      "train loss:0.001175548259680092\n",
      "train loss:0.0024302259058641773\n",
      "train loss:0.0045798583197089095\n",
      "train loss:0.0018982681395887698\n",
      "train loss:0.0038367223035089514\n",
      "train loss:0.000930760491305654\n",
      "train loss:0.0031760721388300432\n",
      "train loss:0.006344713386404945\n",
      "train loss:0.002175682994160363\n",
      "train loss:0.00013794204481907174\n",
      "train loss:0.0005746172948079254\n",
      "train loss:0.010546771277954742\n",
      "train loss:0.0004642451232037443\n",
      "train loss:0.0015295993376821136\n",
      "train loss:0.0019432298283859188\n",
      "train loss:0.001976233201091464\n",
      "train loss:0.0010257461166489482\n",
      "train loss:0.0006068618309324797\n",
      "train loss:0.0017213687196871706\n",
      "train loss:0.005125183908352257\n",
      "train loss:0.002588663461852585\n",
      "train loss:0.0011886578634550701\n",
      "train loss:0.0009199292718719667\n",
      "train loss:0.003122884229521896\n",
      "train loss:0.00020059590118525692\n",
      "train loss:0.0011168888623544497\n",
      "train loss:0.005529634089230606\n",
      "train loss:0.0032830514541018134\n",
      "train loss:0.0022039649112055816\n",
      "train loss:0.003041022369511805\n",
      "train loss:0.0060705496478484266\n",
      "train loss:0.003072343501140325\n",
      "train loss:0.0007682323026692954\n",
      "train loss:0.0005667148359300968\n",
      "train loss:0.000636575714565786\n",
      "train loss:0.002121854088374371\n",
      "train loss:0.0018055243714995184\n",
      "train loss:0.0036458145246553463\n",
      "train loss:0.0009345354516836707\n",
      "train loss:0.00465292051806406\n",
      "train loss:0.004248570821977887\n",
      "train loss:0.0015753322314608984\n",
      "train loss:0.0014569932965023474\n",
      "train loss:0.0025169590604774143\n",
      "train loss:0.0014370926722334823\n",
      "train loss:0.00910061521182028\n",
      "train loss:0.0008462524691968705\n",
      "train loss:0.007120119866704287\n",
      "train loss:0.006816943449586277\n",
      "train loss:0.00037434858124042416\n",
      "train loss:0.0007764780084021779\n",
      "train loss:0.000824420619743645\n",
      "train loss:0.001461047350151602\n",
      "train loss:0.0007439265145235166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005607504841742641\n",
      "train loss:0.0016843422494154648\n",
      "train loss:0.0014434621736291167\n",
      "train loss:0.0033902979426738786\n",
      "train loss:0.00038047209531552107\n",
      "train loss:0.001656556727743164\n",
      "train loss:0.0001845027861407553\n",
      "train loss:0.006304883118850531\n",
      "train loss:0.0011489854146740923\n",
      "train loss:0.020458836078363483\n",
      "train loss:0.001289300357793684\n",
      "train loss:0.013168743601706539\n",
      "train loss:0.003161785548198454\n",
      "train loss:0.0009710334397479954\n",
      "train loss:0.00015017289444055923\n",
      "train loss:0.0006846633808951077\n",
      "train loss:0.0003392253710142944\n",
      "train loss:0.007708143203611185\n",
      "train loss:0.004547650348245699\n",
      "train loss:0.000588436713389974\n",
      "train loss:0.0016962917726522204\n",
      "train loss:0.000930102115413536\n",
      "train loss:0.001673958971561945\n",
      "train loss:0.0019930959074493685\n",
      "train loss:0.0006205803922013235\n",
      "train loss:0.00027769142184079347\n",
      "train loss:0.0012862251475245633\n",
      "train loss:0.0022163388753113473\n",
      "train loss:0.00042257934842403124\n",
      "train loss:0.00040115827991191855\n",
      "train loss:0.00018562911116481003\n",
      "train loss:0.0003959166376125235\n",
      "train loss:0.0008376059112386332\n",
      "train loss:0.0009128372074710091\n",
      "train loss:0.004286278055060357\n",
      "train loss:0.0014835965245271767\n",
      "train loss:0.0008188953982166412\n",
      "train loss:0.00013923064046193203\n",
      "train loss:0.0025742633699444243\n",
      "train loss:0.0007111590467749191\n",
      "train loss:0.003553202204975929\n",
      "train loss:0.0033123985678680367\n",
      "train loss:0.00171921501784917\n",
      "train loss:0.005584753947185293\n",
      "train loss:0.0006644861960883211\n",
      "train loss:0.0006799225583849996\n",
      "train loss:0.0016581527674770684\n",
      "train loss:0.007541463117890395\n",
      "train loss:0.0018522644520088927\n",
      "train loss:0.0013021457665495628\n",
      "train loss:0.00040008162373997053\n",
      "train loss:0.0003562774299786787\n",
      "train loss:0.003325462266449543\n",
      "train loss:0.03785562406030291\n",
      "train loss:0.009273232635373817\n",
      "train loss:0.00528605914227682\n",
      "train loss:0.002718398285671915\n",
      "train loss:0.006089751553627857\n",
      "train loss:0.001152651340155643\n",
      "train loss:0.0019252023037354014\n",
      "train loss:0.003730655842623177\n",
      "train loss:0.002507439212835253\n",
      "train loss:0.004085312947018268\n",
      "train loss:0.0014403421327827673\n",
      "train loss:0.0029838977671275703\n",
      "train loss:0.010116439009987908\n",
      "train loss:0.0027207072459678517\n",
      "train loss:0.0012252629337223327\n",
      "train loss:0.005268161143622159\n",
      "train loss:0.0013457903243960878\n",
      "train loss:0.006258206536212798\n",
      "train loss:0.0015393873873260177\n",
      "train loss:0.00030267771962091516\n",
      "train loss:0.001021676728771232\n",
      "train loss:0.0038250143097886273\n",
      "train loss:0.002418406026456493\n",
      "train loss:0.002058620173221578\n",
      "train loss:0.006148259197646305\n",
      "train loss:0.00030360051169182303\n",
      "train loss:0.019652025405850943\n",
      "train loss:0.00027568203516732513\n",
      "train loss:0.0011829766577003545\n",
      "train loss:0.010546602591460851\n",
      "train loss:0.0011903890030750394\n",
      "train loss:0.002186578738473026\n",
      "train loss:0.0017867038692499662\n",
      "train loss:0.0028711853060375105\n",
      "train loss:0.0047279265709293024\n",
      "train loss:0.002662544707619578\n",
      "train loss:0.0002283420916982205\n",
      "train loss:0.00014774197325580855\n",
      "train loss:0.0008595278535279713\n",
      "train loss:0.001296254950897123\n",
      "train loss:0.004221745580082372\n",
      "train loss:0.0016412558997336104\n",
      "train loss:0.004529019843403894\n",
      "train loss:0.0030104434639445267\n",
      "train loss:0.003423898554299779\n",
      "train loss:0.004172392158167364\n",
      "train loss:0.027526287220796766\n",
      "train loss:0.0006299617306818783\n",
      "train loss:0.002039448184959256\n",
      "train loss:0.007377264535140583\n",
      "train loss:0.000507938530134249\n",
      "train loss:0.0010073935876500125\n",
      "train loss:0.0045718888750112575\n",
      "train loss:0.0033993823840563343\n",
      "train loss:0.00016427782838420105\n",
      "train loss:0.0007447696357397722\n",
      "train loss:0.00012891871720321202\n",
      "train loss:0.0040890837219309285\n",
      "train loss:7.918499405729319e-05\n",
      "train loss:0.006719442142764861\n",
      "train loss:0.0035470193110891286\n",
      "train loss:0.00529182189508245\n",
      "train loss:0.00030079420307091773\n",
      "train loss:0.00034318233472336137\n",
      "train loss:0.0013950345855315005\n",
      "train loss:0.004970367462712239\n",
      "train loss:0.019320184532743624\n",
      "train loss:0.0029129343355317333\n",
      "train loss:0.002146845069576867\n",
      "train loss:0.001070604595313137\n",
      "train loss:0.0029392564134363437\n",
      "train loss:0.001150419140074003\n",
      "train loss:0.00016325711309921168\n",
      "train loss:0.0009022250352257701\n",
      "train loss:0.006456589298421005\n",
      "train loss:0.01796993381561176\n",
      "train loss:0.001562185697560168\n",
      "train loss:0.004120479659462888\n",
      "train loss:0.0018791689881611242\n",
      "train loss:0.002197068870720803\n",
      "train loss:0.048206447304240355\n",
      "train loss:0.006220943413994048\n",
      "train loss:0.0015840712268919257\n",
      "train loss:0.00669987003731558\n",
      "train loss:0.0031515042120356827\n",
      "train loss:0.001758265997681587\n",
      "train loss:0.006292582252946094\n",
      "train loss:0.00841743062738645\n",
      "train loss:0.003912779084419935\n",
      "train loss:0.0005050368657056174\n",
      "train loss:0.0016363764326457891\n",
      "train loss:0.0012191662439540202\n",
      "=== epoch:15, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0011496718786368162\n",
      "train loss:0.0016056560358788097\n",
      "train loss:0.0011705339559958516\n",
      "train loss:0.004631481823660846\n",
      "train loss:0.0072954961501584805\n",
      "train loss:0.0038414201260058463\n",
      "train loss:0.00041055804000706184\n",
      "train loss:0.0038941934083554803\n",
      "train loss:0.0010190985556615113\n",
      "train loss:0.0010672080610825458\n",
      "train loss:0.001306376489313888\n",
      "train loss:0.0008692088586699739\n",
      "train loss:0.004964220791176139\n",
      "train loss:0.0024130421349103826\n",
      "train loss:0.0017806224200136076\n",
      "train loss:0.006351850338309635\n",
      "train loss:0.0022093270840954408\n",
      "train loss:0.001035215969057752\n",
      "train loss:0.01785346452112081\n",
      "train loss:0.00010356862711628832\n",
      "train loss:0.0002567521572891915\n",
      "train loss:0.004428353564903408\n",
      "train loss:0.0037096056952617314\n",
      "train loss:0.0009701551632314163\n",
      "train loss:0.02240657443125739\n",
      "train loss:0.0006777937702350358\n",
      "train loss:0.0004303165882097721\n",
      "train loss:0.00045358124500029636\n",
      "train loss:0.004385958986623504\n",
      "train loss:0.0026940881574208154\n",
      "train loss:0.0036737220396333265\n",
      "train loss:0.000873582361150498\n",
      "train loss:0.0037996702794047517\n",
      "train loss:0.0008470663572428693\n",
      "train loss:0.0007065787918195587\n",
      "train loss:0.0005284258452919297\n",
      "train loss:0.000894412311817245\n",
      "train loss:0.002995529340872949\n",
      "train loss:0.0025693524252415646\n",
      "train loss:0.0004398505881692728\n",
      "train loss:0.04519157147774298\n",
      "train loss:0.00248527726462218\n",
      "train loss:0.003029847701110127\n",
      "train loss:0.0035927792744474296\n",
      "train loss:0.02885909230064662\n",
      "train loss:0.00044904057259585587\n",
      "train loss:0.0020733100603297764\n",
      "train loss:0.001518132115554705\n",
      "train loss:0.004064287696816659\n",
      "train loss:0.0011643615947664475\n",
      "train loss:0.0014475301769978218\n",
      "train loss:0.0018695810924508824\n",
      "train loss:0.005904088694744677\n",
      "train loss:0.0021407514746174124\n",
      "train loss:0.0053721906749138485\n",
      "train loss:0.010874310563523124\n",
      "train loss:0.0014373255984564976\n",
      "train loss:0.00447914850768619\n",
      "train loss:0.0004764158647992474\n",
      "train loss:0.002815415270474454\n",
      "train loss:0.004488344590849653\n",
      "train loss:0.0024493444731385275\n",
      "train loss:0.0013165429125399685\n",
      "train loss:0.004103065486897329\n",
      "train loss:0.019174279393324542\n",
      "train loss:0.00012101930343371887\n",
      "train loss:0.004846496039101953\n",
      "train loss:0.0017176766134020724\n",
      "train loss:0.051029157870569025\n",
      "train loss:0.0007324793330670655\n",
      "train loss:0.0006487913337532158\n",
      "train loss:0.0018485409249566803\n",
      "train loss:0.00042532809855182603\n",
      "train loss:0.0011429720093414605\n",
      "train loss:0.004807876280188891\n",
      "train loss:0.00015273959499052187\n",
      "train loss:0.003219036867181199\n",
      "train loss:0.003970072124814432\n",
      "train loss:0.014684259836197899\n",
      "train loss:0.0010773330462887296\n",
      "train loss:0.010841386840742645\n",
      "train loss:0.0012911042392135272\n",
      "train loss:0.0034213338694431585\n",
      "train loss:0.0025138859540838688\n",
      "train loss:0.00790089460700548\n",
      "train loss:0.002365273271497612\n",
      "train loss:0.0010581744663938786\n",
      "train loss:0.002517772905836023\n",
      "train loss:0.0027981975329363514\n",
      "train loss:0.002472197181990048\n",
      "train loss:0.02013694704443978\n",
      "train loss:0.001759328815084635\n",
      "train loss:0.009757022404051737\n",
      "train loss:0.005598279189720905\n",
      "train loss:0.0003818214485382258\n",
      "train loss:0.003012083399484002\n",
      "train loss:0.007856380955529067\n",
      "train loss:0.005136661608504769\n",
      "train loss:0.008250101556102512\n",
      "train loss:0.0006321600559405615\n",
      "train loss:0.00357679308841409\n",
      "train loss:0.010155888775306742\n",
      "train loss:0.002253802905363528\n",
      "train loss:0.05375460097458963\n",
      "train loss:0.002896887621474316\n",
      "train loss:0.004606869745051107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0031537509686673034\n",
      "train loss:0.017653798203996388\n",
      "train loss:0.0018371318991591023\n",
      "train loss:0.005163424270364355\n",
      "train loss:0.0008741093526051527\n",
      "train loss:0.007590943859357046\n",
      "train loss:0.005112490149266635\n",
      "train loss:0.0076141388786963035\n",
      "train loss:0.00036007204849816357\n",
      "train loss:0.002572692981046807\n",
      "train loss:0.0014048483378737648\n",
      "train loss:0.004481057533677181\n",
      "train loss:0.0003115268177410381\n",
      "train loss:0.001140007590271625\n",
      "train loss:0.004385558434200468\n",
      "train loss:0.00016221353447784268\n",
      "train loss:0.00024314042959946517\n",
      "train loss:0.0013097327014327757\n",
      "train loss:0.0012523373173722882\n",
      "train loss:0.002263792795332202\n",
      "train loss:0.0004441660334225428\n",
      "train loss:0.003888673022706322\n",
      "train loss:0.0024590603291263767\n",
      "train loss:0.05122782669397627\n",
      "train loss:0.002251338649332571\n",
      "train loss:0.0011883159674351128\n",
      "train loss:0.007082991438610162\n",
      "train loss:0.0006620720152016931\n",
      "train loss:0.0018320059386859057\n",
      "train loss:0.006178366859490459\n",
      "train loss:0.004044752610305846\n",
      "train loss:0.01755729285170848\n",
      "train loss:0.0003665204480096853\n",
      "train loss:0.0029104072805572275\n",
      "train loss:0.002535523249215946\n",
      "train loss:0.001335212098008234\n",
      "train loss:0.004575421169522351\n",
      "train loss:0.005534776204207526\n",
      "train loss:0.00014035480001568633\n",
      "train loss:0.00033057969254317294\n",
      "train loss:0.0028354124805719957\n",
      "train loss:0.0018757301826698863\n",
      "train loss:0.007758595027811113\n",
      "train loss:0.007626227499710805\n",
      "train loss:0.0021596508392662354\n",
      "train loss:0.004067178156631445\n",
      "train loss:0.0011510567348871619\n",
      "train loss:0.008576799412537518\n",
      "train loss:0.002265658796667154\n",
      "train loss:0.030970380922602434\n",
      "train loss:0.0035919005335927874\n",
      "train loss:0.002219986424285887\n",
      "train loss:0.0022495511362146067\n",
      "train loss:0.0013390377164781508\n",
      "train loss:0.0010863128411409521\n",
      "train loss:0.0069495328193929255\n",
      "train loss:0.0008738137120729897\n",
      "train loss:0.014187271718926406\n",
      "train loss:0.0004823579145180905\n",
      "train loss:0.004747270535314605\n",
      "train loss:0.003983446831672197\n",
      "train loss:0.0013759277858272723\n",
      "train loss:0.0018781945115097774\n",
      "train loss:0.0031428527283435346\n",
      "train loss:0.0070104834378884205\n",
      "train loss:0.00755759311623614\n",
      "train loss:0.0013124213962712825\n",
      "train loss:0.006446541811258018\n",
      "train loss:0.00102258355937183\n",
      "train loss:0.00281371962762313\n",
      "train loss:0.012213469347042151\n",
      "train loss:0.0018635940784905406\n",
      "train loss:0.0022322838213307853\n",
      "train loss:0.0010784328700065044\n",
      "train loss:0.004969759034872577\n",
      "train loss:0.001288248325815453\n",
      "train loss:0.0031280714143969877\n",
      "train loss:0.0024734690464767585\n",
      "train loss:0.005318966292000445\n",
      "train loss:0.0011638569749485809\n",
      "train loss:0.002114200155665617\n",
      "train loss:0.01272629673803504\n",
      "train loss:0.006798983207222481\n",
      "train loss:0.002876964763406635\n",
      "train loss:0.004107168210077932\n",
      "train loss:0.03151565561211073\n",
      "train loss:0.0004753622766784097\n",
      "train loss:0.004785644351238851\n",
      "train loss:0.04337686781391867\n",
      "train loss:0.013267635323481084\n",
      "train loss:0.00037575482808625734\n",
      "train loss:0.012260105401086695\n",
      "train loss:0.0007302297473264819\n",
      "train loss:0.005492934816264383\n",
      "train loss:0.00532749865648908\n",
      "train loss:0.0011625818092225034\n",
      "train loss:0.0024684347730851244\n",
      "train loss:0.0015496490979067844\n",
      "train loss:0.002898323299563502\n",
      "train loss:0.009356368989270782\n",
      "train loss:0.0014040005293162947\n",
      "train loss:0.0032646849717160135\n",
      "train loss:0.0010768837026099583\n",
      "train loss:0.004393906901743191\n",
      "train loss:0.0029079201851125304\n",
      "train loss:0.0007093321578268206\n",
      "train loss:0.005986576335506516\n",
      "train loss:0.0031677350630954586\n",
      "train loss:0.008027281432795554\n",
      "train loss:0.010788665784022638\n",
      "train loss:0.005320695386756235\n",
      "train loss:0.013746500175723608\n",
      "train loss:0.0015019355875659332\n",
      "train loss:0.00500060372306456\n",
      "train loss:0.0005908485960266835\n",
      "train loss:0.0015105970582487583\n",
      "train loss:0.005378413147931076\n",
      "train loss:0.00019514909609096267\n",
      "train loss:0.0033902074656827386\n",
      "train loss:0.009138525921261558\n",
      "train loss:0.007309756215587051\n",
      "train loss:0.00020675617101845281\n",
      "train loss:0.001624579669619004\n",
      "train loss:0.011904693621771269\n",
      "train loss:0.0037532187452345113\n",
      "train loss:0.0007837503170240064\n",
      "train loss:0.0010530476662496818\n",
      "train loss:0.0030731997865566553\n",
      "train loss:0.004226113455091695\n",
      "train loss:0.001491063019226509\n",
      "train loss:0.002614287597420959\n",
      "train loss:0.004166440877380796\n",
      "train loss:0.001190483070706016\n",
      "train loss:0.0007483874652789623\n",
      "train loss:0.0012657246581993964\n",
      "train loss:0.006424357174735171\n",
      "train loss:0.00044443876514642296\n",
      "train loss:0.0054876587071861615\n",
      "train loss:0.006561577080862616\n",
      "train loss:0.002867540698528202\n",
      "train loss:0.008404808245479721\n",
      "train loss:0.008413206140162202\n",
      "train loss:0.0007299482927084594\n",
      "train loss:0.0003295117119099909\n",
      "train loss:0.0005120873665880729\n",
      "train loss:0.0016657509900931166\n",
      "train loss:0.0035905770862514363\n",
      "train loss:0.007274907879319099\n",
      "train loss:0.00349431604454013\n",
      "train loss:0.0011692440943364285\n",
      "train loss:0.0014233140090830292\n",
      "train loss:0.0024563188740001672\n",
      "train loss:0.0012253679219164798\n",
      "train loss:0.002891167590001294\n",
      "train loss:0.0016557116158839055\n",
      "train loss:0.008864443450094503\n",
      "train loss:0.0028102976837320643\n",
      "train loss:0.0005571594996932149\n",
      "train loss:0.0022734598040105723\n",
      "train loss:0.019626128699744904\n",
      "train loss:0.03544373286636277\n",
      "train loss:0.0010602696289908375\n",
      "train loss:0.000874071496481481\n",
      "train loss:0.0014392318111029357\n",
      "train loss:0.00022034709317224086\n",
      "train loss:0.002549373125865798\n",
      "train loss:0.006825876433345184\n",
      "train loss:0.0019670740469391245\n",
      "train loss:0.0024569597268712514\n",
      "train loss:0.0014356253830560147\n",
      "train loss:0.0006411767243938055\n",
      "train loss:0.006221859950922861\n",
      "train loss:0.004565045018728232\n",
      "train loss:0.0010543365838363728\n",
      "train loss:0.00039575023222370413\n",
      "train loss:0.0023920061882441285\n",
      "train loss:0.006867686660570603\n",
      "train loss:0.0012926104940127509\n",
      "train loss:0.011451159092946316\n",
      "train loss:0.0012688641143996065\n",
      "train loss:0.0023494237222950122\n",
      "train loss:0.0009139423350444463\n",
      "train loss:0.007110188180385085\n",
      "train loss:0.001563717310818024\n",
      "train loss:0.0016099077177928632\n",
      "train loss:0.004162489228546916\n",
      "train loss:0.0026103789379731523\n",
      "train loss:0.001192829297762296\n",
      "train loss:0.0008898035093394077\n",
      "train loss:0.004840486457004374\n",
      "train loss:0.0004966728209763085\n",
      "train loss:0.004834594354883135\n",
      "train loss:0.003962102733740154\n",
      "train loss:0.0068076289639554585\n",
      "train loss:0.0006363713944429862\n",
      "train loss:0.08932332567985521\n",
      "train loss:0.004374854097135577\n",
      "train loss:0.003101892262449421\n",
      "train loss:0.003147381916211522\n",
      "train loss:0.0023803867728165403\n",
      "train loss:0.004131343069026731\n",
      "train loss:0.001969575455078119\n",
      "train loss:0.002092465868507187\n",
      "train loss:0.0028250258881788145\n",
      "train loss:0.00015833267429321218\n",
      "train loss:0.000983628116561505\n",
      "train loss:0.01511947888403941\n",
      "train loss:0.002740020602841052\n",
      "train loss:0.00276885401060846\n",
      "train loss:0.0006142938735793912\n",
      "train loss:0.005048442668340358\n",
      "train loss:0.004793127021699062\n",
      "train loss:0.01015426278426428\n",
      "train loss:0.000662679162759909\n",
      "train loss:0.0015677077363637373\n",
      "train loss:0.002926060053951425\n",
      "train loss:0.003680037367458229\n",
      "train loss:0.0018090206090842856\n",
      "train loss:0.0035049466352886187\n",
      "train loss:0.0029154484090172677\n",
      "train loss:0.002429098730667778\n",
      "train loss:0.018087886956805937\n",
      "train loss:0.007045440149851078\n",
      "train loss:0.0016685720241299096\n",
      "train loss:0.001012626775349005\n",
      "train loss:0.028759343960309085\n",
      "train loss:0.0013073624889036167\n",
      "train loss:0.0016413957635064477\n",
      "train loss:0.007891833022785476\n",
      "train loss:0.006739796093179183\n",
      "train loss:0.0020381584575840405\n",
      "train loss:0.003261807712737933\n",
      "train loss:0.0016602513370793908\n",
      "train loss:0.006172094542474441\n",
      "train loss:0.0013012596426804912\n",
      "train loss:0.02534869875443465\n",
      "train loss:0.030283965967243878\n",
      "train loss:0.00085421228594693\n",
      "train loss:0.0004208395447182647\n",
      "train loss:0.0027005697707412446\n",
      "train loss:0.004877060222226588\n",
      "train loss:0.0005114606790214085\n",
      "train loss:0.000996430698412365\n",
      "train loss:0.0020080011201471944\n",
      "train loss:0.0005041150163835776\n",
      "train loss:0.005610613239854522\n",
      "train loss:0.0011701324716976182\n",
      "train loss:0.016629704124275092\n",
      "train loss:0.006428729249844735\n",
      "train loss:0.003764643949919623\n",
      "train loss:0.002003396527842193\n",
      "train loss:0.0005010121113566583\n",
      "train loss:0.001575414127636769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00033822250132321173\n",
      "train loss:0.004866515780211666\n",
      "train loss:0.005135935054194121\n",
      "train loss:0.00390971558251366\n",
      "train loss:0.0035739285830725166\n",
      "train loss:0.0004451635576409482\n",
      "train loss:0.005096675943706568\n",
      "train loss:0.0008767295827644756\n",
      "train loss:0.0004567059940287886\n",
      "train loss:0.00039677843514647834\n",
      "train loss:0.002813278372005334\n",
      "train loss:0.0007023985288061882\n",
      "train loss:0.01038442469478954\n",
      "train loss:0.015200104859994892\n",
      "train loss:0.0006957228725627003\n",
      "train loss:0.00739830763662661\n",
      "train loss:0.003935419486856919\n",
      "train loss:0.0021115129511139323\n",
      "train loss:0.0031396793128142296\n",
      "train loss:0.0008145643929819163\n",
      "train loss:0.0007800959474235269\n",
      "train loss:0.0035647545744855384\n",
      "train loss:0.006250401451608667\n",
      "train loss:0.0010483713157929755\n",
      "train loss:0.001951818194388058\n",
      "train loss:0.0016952452637748869\n",
      "train loss:0.0009193018359902194\n",
      "train loss:0.0011492846883217616\n",
      "train loss:0.007776957618061147\n",
      "train loss:0.0004594318928699806\n",
      "train loss:0.011734678074320803\n",
      "train loss:0.009065445013517817\n",
      "train loss:0.008093103475677953\n",
      "train loss:0.011650811991209853\n",
      "train loss:0.0003722904510786711\n",
      "train loss:0.0040842302202031685\n",
      "train loss:0.009354842390243853\n",
      "train loss:0.0020128882664500088\n",
      "train loss:0.0005832657841181849\n",
      "train loss:0.035974817526076924\n",
      "train loss:0.001784473360315692\n",
      "train loss:0.006989956910082655\n",
      "train loss:0.0007941572801610559\n",
      "train loss:0.004275642005337482\n",
      "train loss:0.006894808714394397\n",
      "train loss:0.0023388757965511204\n",
      "train loss:0.0002795090890720858\n",
      "train loss:0.004635602246604708\n",
      "train loss:0.0031068683656543515\n",
      "train loss:0.004637548971565845\n",
      "train loss:0.002035421970247396\n",
      "train loss:0.0032689517520541837\n",
      "train loss:0.003724445712086305\n",
      "train loss:0.00034175803890103376\n",
      "train loss:0.004171230541399231\n",
      "train loss:0.0004711534414746554\n",
      "train loss:0.007693439707784441\n",
      "train loss:0.0031501876379763675\n",
      "train loss:0.0005339367325292309\n",
      "train loss:0.0013474412663270366\n",
      "train loss:0.0011450934999943842\n",
      "train loss:0.02006002027003539\n",
      "train loss:0.0008611709043281977\n",
      "train loss:0.003255262587724316\n",
      "train loss:0.0009956518689967833\n",
      "train loss:0.02165502869003642\n",
      "train loss:0.0033809356408979942\n",
      "train loss:0.002053248021639801\n",
      "train loss:0.004691497096034405\n",
      "train loss:0.002474328280738512\n",
      "train loss:0.001708937588181944\n",
      "train loss:0.00077085743256379\n",
      "train loss:0.0017084315228390432\n",
      "train loss:0.007284550217790478\n",
      "train loss:0.0007657901820237894\n",
      "train loss:0.0036889812048987443\n",
      "train loss:0.0019257133089747782\n",
      "train loss:0.009289850421631624\n",
      "train loss:0.0004305101669688943\n",
      "train loss:0.004891248451164339\n",
      "train loss:0.0008754893370147505\n",
      "train loss:0.0014820059712843045\n",
      "train loss:0.004787881511304432\n",
      "train loss:0.004758620491042232\n",
      "train loss:0.0024067943364068744\n",
      "train loss:0.004033470529331672\n",
      "train loss:0.009030037828050006\n",
      "train loss:0.002364800649849837\n",
      "train loss:0.000306341105688839\n",
      "train loss:0.0021402528944355647\n",
      "train loss:0.0024633367029861003\n",
      "train loss:0.003917748224999794\n",
      "train loss:0.0033357565533938156\n",
      "train loss:0.002869483092030467\n",
      "train loss:0.0031628890438492856\n",
      "train loss:0.017868119447504625\n",
      "train loss:0.00019238940756242446\n",
      "train loss:0.01611425459378882\n",
      "train loss:0.003962030953435395\n",
      "train loss:0.0014199188938139274\n",
      "train loss:0.0007736143699242199\n",
      "train loss:0.0013762189844070134\n",
      "train loss:6.394737663397717e-05\n",
      "train loss:0.0005280834196507876\n",
      "train loss:0.0003331984992578356\n",
      "train loss:0.0033057332166453717\n",
      "train loss:0.0018579671981417349\n",
      "train loss:0.0017442046724023847\n",
      "train loss:0.0015277297897315963\n",
      "train loss:0.0018916031247465364\n",
      "train loss:0.0027085238056653855\n",
      "train loss:0.0017171350343679098\n",
      "train loss:0.004964834406108718\n",
      "train loss:0.000613836025008877\n",
      "train loss:0.005548644547720757\n",
      "train loss:0.00015374713469704988\n",
      "train loss:0.004111147373094178\n",
      "train loss:0.030590945249751846\n",
      "train loss:0.009542028950556369\n",
      "train loss:0.011419474189031487\n",
      "train loss:0.000530634321719855\n",
      "train loss:0.014859857922495803\n",
      "train loss:0.001072056717407855\n",
      "train loss:0.011872361726806668\n",
      "train loss:0.001222940459218796\n",
      "train loss:0.0001425744016803776\n",
      "train loss:0.0023905689993971736\n",
      "train loss:0.033128252663760606\n",
      "train loss:0.005183015315599452\n",
      "train loss:0.03818715023952581\n",
      "train loss:0.0007279762821725238\n",
      "train loss:0.002216262055653532\n",
      "train loss:0.0003174701787477347\n",
      "train loss:0.006369240566973073\n",
      "train loss:0.004066393813792292\n",
      "train loss:0.002788988813696323\n",
      "train loss:0.00083614231393252\n",
      "train loss:0.0030072337861058334\n",
      "train loss:0.005774599327215905\n",
      "train loss:0.005613145645960744\n",
      "train loss:0.001797666537746588\n",
      "train loss:0.01899599944288254\n",
      "train loss:0.0025991903139381306\n",
      "train loss:0.004612134162168987\n",
      "train loss:0.0006420401692931523\n",
      "train loss:0.006765107679316338\n",
      "train loss:0.001507547252171198\n",
      "train loss:0.0019571790208355757\n",
      "train loss:0.00020104730850104284\n",
      "train loss:0.001499070768948802\n",
      "train loss:0.0002570146464528972\n",
      "train loss:0.0023836409923066377\n",
      "train loss:0.03213890831957228\n",
      "train loss:0.0037141168549119307\n",
      "train loss:0.0006714881130862203\n",
      "train loss:0.00709305417462422\n",
      "train loss:0.0002527876293748749\n",
      "train loss:0.00022569629782848573\n",
      "train loss:0.0015489112252093085\n",
      "train loss:0.000504772349484511\n",
      "train loss:0.008798041605657166\n",
      "train loss:0.001386746777423597\n",
      "train loss:0.00010652930741172986\n",
      "train loss:0.0019296546672553283\n",
      "train loss:0.0017347116553371525\n",
      "train loss:0.0009695416970346273\n",
      "train loss:0.0003440009384853987\n",
      "train loss:0.004742404206124973\n",
      "train loss:0.004804952469126894\n",
      "train loss:0.0015037585249654093\n",
      "train loss:0.0034910701920856254\n",
      "train loss:0.008599799353629062\n",
      "train loss:0.006057175522967334\n",
      "train loss:0.0007841186183692719\n",
      "train loss:0.0035684577620333025\n",
      "train loss:0.0026455732569011857\n",
      "train loss:0.018464864789966076\n",
      "train loss:0.003967559801408496\n",
      "train loss:0.0005725153457479424\n",
      "train loss:0.0007006131201195101\n",
      "train loss:0.01247862329057287\n",
      "train loss:0.003666424618389075\n",
      "train loss:0.004117127318303132\n",
      "train loss:0.0022956413214658246\n",
      "train loss:0.0026475334917504868\n",
      "train loss:0.00027450137661948947\n",
      "train loss:0.0005571109709665447\n",
      "train loss:0.00971256720660022\n",
      "train loss:0.008005456733259357\n",
      "train loss:0.0014592153164477183\n",
      "train loss:0.002010669099867265\n",
      "train loss:0.006383924281468607\n",
      "train loss:0.0011148860010210741\n",
      "train loss:0.0046278954581156955\n",
      "train loss:0.0030033370084338127\n",
      "train loss:0.0005478280276543621\n",
      "train loss:0.0054118696088825005\n",
      "train loss:9.44661963430498e-05\n",
      "train loss:0.00277698640931148\n",
      "train loss:0.011682968701423579\n",
      "train loss:0.005282622450695774\n",
      "train loss:0.0022623653500015084\n",
      "train loss:0.014604447039045492\n",
      "train loss:0.0058773167598397255\n",
      "train loss:0.004989433494000182\n",
      "train loss:0.00045450187682491585\n",
      "train loss:0.0013311138341435922\n",
      "train loss:0.0013799727502025643\n",
      "train loss:0.0012702315240212157\n",
      "train loss:0.0011577306570668992\n",
      "train loss:0.0009357887514151414\n",
      "train loss:0.0018254203880149924\n",
      "train loss:0.0063284569646437795\n",
      "train loss:0.001032178289549658\n",
      "train loss:0.0024839992335886885\n",
      "train loss:0.00018923587290249473\n",
      "train loss:0.0027211548386850415\n",
      "train loss:0.004247760278171186\n",
      "train loss:0.0026198336458504662\n",
      "train loss:0.002774322966351222\n",
      "train loss:0.002805650246566001\n",
      "train loss:0.0006647221869579684\n",
      "train loss:0.00017937625609987156\n",
      "train loss:0.0026830023522665613\n",
      "train loss:0.001931468224993116\n",
      "train loss:0.01607339512577885\n",
      "train loss:0.0016845077656974566\n",
      "train loss:0.00020601103940624528\n",
      "train loss:0.003904934809265263\n",
      "train loss:0.006260464602323056\n",
      "train loss:0.0010778948342281837\n",
      "train loss:0.0032213649451817467\n",
      "train loss:0.01124457244850019\n",
      "train loss:0.0008678990026306137\n",
      "train loss:0.002131330890020494\n",
      "train loss:0.004281829832432882\n",
      "train loss:0.003530080071713812\n",
      "train loss:0.00020174710152996963\n",
      "train loss:0.00034415503414188546\n",
      "train loss:0.0012443172695849182\n",
      "train loss:0.0015371076318214565\n",
      "=== epoch:16, train acc:1.0, test acc:0.988 ===\n",
      "train loss:0.00014338441867208006\n",
      "train loss:0.0005789132112035394\n",
      "train loss:0.004522201990921125\n",
      "train loss:0.00019811177799949022\n",
      "train loss:0.004694367834884658\n",
      "train loss:0.00018150358933683485\n",
      "train loss:0.00038857618966868073\n",
      "train loss:0.0031524727127422475\n",
      "train loss:0.0006650517042803336\n",
      "train loss:0.0023443265092359966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001332056552309139\n",
      "train loss:0.0014649132226624791\n",
      "train loss:0.00023719643814119724\n",
      "train loss:0.0003093288457416905\n",
      "train loss:0.0007627706536693888\n",
      "train loss:0.00017114410378459423\n",
      "train loss:0.03490368081861386\n",
      "train loss:0.0015931926670177388\n",
      "train loss:0.0011358747085711655\n",
      "train loss:0.00105427082817884\n",
      "train loss:0.0013582455079698894\n",
      "train loss:0.008928749913942914\n",
      "train loss:0.0023181713009021885\n",
      "train loss:0.001525786621679131\n",
      "train loss:0.005868613878088715\n",
      "train loss:0.0056930563837287625\n",
      "train loss:0.010053662173066144\n",
      "train loss:0.003298855135020603\n",
      "train loss:0.0012342629304689275\n",
      "train loss:0.004858791659466609\n",
      "train loss:0.001292331823176829\n",
      "train loss:0.0039377048739462385\n",
      "train loss:0.0004077555929618643\n",
      "train loss:0.004541783152370365\n",
      "train loss:0.0008779530845899262\n",
      "train loss:0.004484179970682457\n",
      "train loss:0.0042384322185422645\n",
      "train loss:0.0006532275118151445\n",
      "train loss:0.006930771308494263\n",
      "train loss:0.0002507892743115551\n",
      "train loss:0.0028385891488240415\n",
      "train loss:0.008726806240274769\n",
      "train loss:0.0014423546961961017\n",
      "train loss:0.0017573082050907837\n",
      "train loss:0.00020690780946958892\n",
      "train loss:0.0005377612872380689\n",
      "train loss:0.0015177463871945773\n",
      "train loss:0.0015315409861421203\n",
      "train loss:0.0029845976732542144\n",
      "train loss:0.0011248892900920945\n",
      "train loss:0.003735807646950901\n",
      "train loss:0.0031868086287623683\n",
      "train loss:0.0033670835060255182\n",
      "train loss:0.0017220121289437621\n",
      "train loss:0.0005402486266670096\n",
      "train loss:0.004867373689686873\n",
      "train loss:0.0027278908834109028\n",
      "train loss:0.0003708340673728448\n",
      "train loss:0.004665745750432762\n",
      "train loss:0.00034391961189472644\n",
      "train loss:0.00033029779219846174\n",
      "train loss:0.0031451113566214758\n",
      "train loss:0.002636447320959791\n",
      "train loss:0.001926847534722183\n",
      "train loss:0.0026725980665920157\n",
      "train loss:0.0004618350084607495\n",
      "train loss:0.0017772680825349281\n",
      "train loss:0.0006328245878048322\n",
      "train loss:0.004059852466396226\n",
      "train loss:0.005062714305295158\n",
      "train loss:0.00133308720297991\n",
      "train loss:0.005795389008346644\n",
      "train loss:0.0006033653696959427\n",
      "train loss:0.002999856514412415\n",
      "train loss:0.004885276171251139\n",
      "train loss:0.004815697950764707\n",
      "train loss:0.0031921133492952137\n",
      "train loss:0.002136056815416832\n",
      "train loss:0.0037168991577763415\n",
      "train loss:0.0009762531422833105\n",
      "train loss:0.00033286412035787074\n",
      "train loss:0.0023334863590609984\n",
      "train loss:0.0034805115971652143\n",
      "train loss:0.00042404090154203307\n",
      "train loss:0.005954116728658509\n",
      "train loss:0.002246753492561393\n",
      "train loss:0.00016419813728001917\n",
      "train loss:0.0010711841162455073\n",
      "train loss:0.0007714278708918399\n",
      "train loss:0.0034759453861114994\n",
      "train loss:0.0004917470297488993\n",
      "train loss:9.955399054429093e-05\n",
      "train loss:0.0028307237306506162\n",
      "train loss:0.0003828070355348368\n",
      "train loss:0.0015040420690425136\n",
      "train loss:0.00264510351851026\n",
      "train loss:0.0005198359152242297\n",
      "train loss:0.0006085107248998946\n",
      "train loss:0.0023525030613638113\n",
      "train loss:0.027388062907884016\n",
      "train loss:0.001964724104922673\n",
      "train loss:0.004863990814951822\n",
      "train loss:0.0010980813235156673\n",
      "train loss:0.0039047577267799153\n",
      "train loss:0.000260919664031342\n",
      "train loss:0.0015679833087927392\n",
      "train loss:0.0008830406815467209\n",
      "train loss:0.0015227841807158244\n",
      "train loss:0.0030365829129393135\n",
      "train loss:0.004399251896266369\n",
      "train loss:0.002642773404182538\n",
      "train loss:0.0021054150825899013\n",
      "train loss:0.014959219217120867\n",
      "train loss:0.0064634706906087835\n",
      "train loss:0.005883070007895995\n",
      "train loss:0.0008282407161066154\n",
      "train loss:0.0029565008157976243\n",
      "train loss:0.0012216552288003048\n",
      "train loss:0.010315344769358721\n",
      "train loss:0.005713507063327502\n",
      "train loss:0.0003150107723086247\n",
      "train loss:0.0004902734774199615\n",
      "train loss:0.0022572682789304154\n",
      "train loss:0.001162922702137523\n",
      "train loss:0.0028508320950454656\n",
      "train loss:0.020721392569327944\n",
      "train loss:0.0008571221860329911\n",
      "train loss:0.0016622939504089664\n",
      "train loss:0.00015234860298499897\n",
      "train loss:0.003790976300658256\n",
      "train loss:0.00564571711297687\n",
      "train loss:0.0015495085664256809\n",
      "train loss:0.0016001200384704033\n",
      "train loss:0.0006983933644573602\n",
      "train loss:0.0011731495987473855\n",
      "train loss:0.0018810045889177517\n",
      "train loss:0.00865909688131792\n",
      "train loss:0.0016130200742964069\n",
      "train loss:0.021850544127703028\n",
      "train loss:0.00203390218167236\n",
      "train loss:0.00212351229510041\n",
      "train loss:0.00240698845156211\n",
      "train loss:0.001380568134347039\n",
      "train loss:0.0003866820246537105\n",
      "train loss:0.001918258377857659\n",
      "train loss:0.0029385145251375035\n",
      "train loss:0.0004699806030924326\n",
      "train loss:0.00188541748439265\n",
      "train loss:0.0017912997932871071\n",
      "train loss:0.0020433056495050834\n",
      "train loss:0.0003576662822079384\n",
      "train loss:0.004398289146723117\n",
      "train loss:0.0009011577582488573\n",
      "train loss:0.002549047078093278\n",
      "train loss:0.002817639413781369\n",
      "train loss:0.00039604572847846243\n",
      "train loss:0.0029285528862227563\n",
      "train loss:0.0013134546381042118\n",
      "train loss:0.0020484546427952865\n",
      "train loss:0.001326107904333953\n",
      "train loss:0.0034174761230802\n",
      "train loss:0.0008678635151335831\n",
      "train loss:0.0009677103686860774\n",
      "train loss:0.000860688930787367\n",
      "train loss:0.005533851858001665\n",
      "train loss:0.011152098745709126\n",
      "train loss:0.00046790579980374744\n",
      "train loss:0.006995391692558877\n",
      "train loss:0.0012070635470839857\n",
      "train loss:0.00043417652714201004\n",
      "train loss:0.004143436084406976\n",
      "train loss:0.00016642402390283108\n",
      "train loss:0.0005706891342856619\n",
      "train loss:0.0016837626792148403\n",
      "train loss:0.011795464831464743\n",
      "train loss:0.0008298798250135402\n",
      "train loss:0.0008768199459032787\n",
      "train loss:0.0018826317991149453\n",
      "train loss:0.001106954024191584\n",
      "train loss:0.0007358984452004561\n",
      "train loss:0.002382967114743591\n",
      "train loss:0.006265685111555697\n",
      "train loss:0.0019175423726899086\n",
      "train loss:0.00206940686019918\n",
      "train loss:0.0022386200476049857\n",
      "train loss:0.00319721690145371\n",
      "train loss:0.0009449748610183871\n",
      "train loss:0.0012548819011893473\n",
      "train loss:4.6366056892673396e-05\n",
      "train loss:0.0007778531071211088\n",
      "train loss:0.0031431361341985914\n",
      "train loss:0.00015651147185421235\n",
      "train loss:0.003743558215433163\n",
      "train loss:0.00042912977166280103\n",
      "train loss:0.000838320749402072\n",
      "train loss:0.004968723709480233\n",
      "train loss:0.00030335357060848794\n",
      "train loss:0.008762751226858552\n",
      "train loss:0.0016957083979079362\n",
      "train loss:0.0014056357670619696\n",
      "train loss:0.0005372901916444142\n",
      "train loss:0.0002697848922911785\n",
      "train loss:0.0014774363024560972\n",
      "train loss:0.010125977809665919\n",
      "train loss:0.0028253685799162786\n",
      "train loss:0.013243893899553017\n",
      "train loss:0.0003811133944206835\n",
      "train loss:0.0017721846811983777\n",
      "train loss:0.0019459275652828328\n",
      "train loss:0.004540147696326318\n",
      "train loss:0.0012208036943277335\n",
      "train loss:0.002198123300067383\n",
      "train loss:0.0014745938207266008\n",
      "train loss:0.0017777376992133486\n",
      "train loss:0.001324230844300152\n",
      "train loss:0.0010186083329521234\n",
      "train loss:0.0003676937535879663\n",
      "train loss:0.00023426056697287717\n",
      "train loss:0.0195518421930619\n",
      "train loss:0.0003164923450211273\n",
      "train loss:0.001639864941745531\n",
      "train loss:0.0040435820508363625\n",
      "train loss:0.0007115267250426193\n",
      "train loss:0.0092579912542127\n",
      "train loss:0.0004821670955298065\n",
      "train loss:0.019942706911460176\n",
      "train loss:0.0001958638205843728\n",
      "train loss:0.004492696699442105\n",
      "train loss:0.001050792489486347\n",
      "train loss:0.0007661092577323021\n",
      "train loss:0.005805560346645387\n",
      "train loss:0.000565887076878073\n",
      "train loss:0.0008372369845563764\n",
      "train loss:0.003897363453464356\n",
      "train loss:0.00015649239456501097\n",
      "train loss:0.03231319226986813\n",
      "train loss:0.0007947519564677773\n",
      "train loss:0.003229871242238863\n",
      "train loss:0.0026443562583703807\n",
      "train loss:0.0009809323180740954\n",
      "train loss:0.0012548596895724416\n",
      "train loss:0.00595028114119178\n",
      "train loss:0.0035082083789667955\n",
      "train loss:0.0005964655447600661\n",
      "train loss:0.003298875297341343\n",
      "train loss:0.010027865514952869\n",
      "train loss:0.0013737937462609045\n",
      "train loss:0.0005312820792842745\n",
      "train loss:0.0041506608769167576\n",
      "train loss:0.0017919314392742108\n",
      "train loss:0.02472171727829586\n",
      "train loss:0.0009719337159261646\n",
      "train loss:0.000287283340465285\n",
      "train loss:0.0011215830545566905\n",
      "train loss:0.0002306118713729269\n",
      "train loss:0.00026245049980516943\n",
      "train loss:0.002948275985013684\n",
      "train loss:0.0005225135357721024\n",
      "train loss:0.044248307515930146\n",
      "train loss:0.0031530893075286254\n",
      "train loss:0.0020718232901452143\n",
      "train loss:0.0034551195682688634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00225694726646836\n",
      "train loss:0.0034902146970924035\n",
      "train loss:0.000689479578835171\n",
      "train loss:0.0012026837720045295\n",
      "train loss:0.0033818423701133613\n",
      "train loss:0.005265070193038834\n",
      "train loss:0.00024625052811790693\n",
      "train loss:0.0019216822774936835\n",
      "train loss:0.001061364924573476\n",
      "train loss:0.0026135900770771128\n",
      "train loss:0.0055855420175541385\n",
      "train loss:0.0013046894144405578\n",
      "train loss:0.0029879836006524397\n",
      "train loss:0.00259986115057447\n",
      "train loss:0.0029470086672171523\n",
      "train loss:0.0019247231634279363\n",
      "train loss:0.004437962374100459\n",
      "train loss:0.005185354652816658\n",
      "train loss:0.002317973145013997\n",
      "train loss:0.003245417616578708\n",
      "train loss:0.004085087669479779\n",
      "train loss:0.0004034758365095099\n",
      "train loss:0.0003768263823244352\n",
      "train loss:0.002474519715790663\n",
      "train loss:0.0004680717697986866\n",
      "train loss:0.00062386484489948\n",
      "train loss:0.0001375683835624713\n",
      "train loss:0.0009527861369780135\n",
      "train loss:0.012731214189334072\n",
      "train loss:0.0021974156818581315\n",
      "train loss:3.7183400798967074e-05\n",
      "train loss:0.0008965418832898367\n",
      "train loss:0.0007525732637160476\n",
      "train loss:0.0005658653465586958\n",
      "train loss:0.0036275459627269093\n",
      "train loss:0.004253454629088428\n",
      "train loss:0.0022222855873309465\n",
      "train loss:0.0008999667776566087\n",
      "train loss:0.0008343545042276759\n",
      "train loss:0.001827680512413681\n",
      "train loss:0.00033477590034054\n",
      "train loss:0.00014711063088266975\n",
      "train loss:0.0003436374001284982\n",
      "train loss:0.0006197348772923714\n",
      "train loss:0.003425008848141387\n",
      "train loss:0.0030974942314324233\n",
      "train loss:0.0003086445786521631\n",
      "train loss:0.0034554070484711153\n",
      "train loss:0.0007377065544779138\n",
      "train loss:0.0012692694900806154\n",
      "train loss:0.0013814833273296603\n",
      "train loss:0.0004499961072865769\n",
      "train loss:0.0026249857404651816\n",
      "train loss:0.0014290939568686386\n",
      "train loss:0.00047540414651133607\n",
      "train loss:0.0022479536957493635\n",
      "train loss:0.003227684767573725\n",
      "train loss:0.0030597967322730417\n",
      "train loss:0.019231272913106244\n",
      "train loss:0.0010714030873573022\n",
      "train loss:0.0022783551457615254\n",
      "train loss:0.00028843882419892847\n",
      "train loss:0.0010357114788843694\n",
      "train loss:0.00017075177688318007\n",
      "train loss:0.00026456389427750605\n",
      "train loss:0.0010353555960104183\n",
      "train loss:0.0008317919628054086\n",
      "train loss:0.005916962388690529\n",
      "train loss:0.00047190739277754663\n",
      "train loss:0.0015392934318316806\n",
      "train loss:0.000208127574027319\n",
      "train loss:0.0005097951712933438\n",
      "train loss:0.017747360488169918\n",
      "train loss:8.82059100802258e-05\n",
      "train loss:0.002248459793707929\n",
      "train loss:0.00183686047506412\n",
      "train loss:0.0006614343972185617\n",
      "train loss:0.0008711475514638412\n",
      "train loss:0.0023412476764222505\n",
      "train loss:0.0009702279431688646\n",
      "train loss:0.00037197717309434323\n",
      "train loss:0.0008494642701401693\n",
      "train loss:0.018093105748513513\n",
      "train loss:0.005178823723694753\n",
      "train loss:0.0013298181837792108\n",
      "train loss:0.0021128485810458456\n",
      "train loss:0.003988377467427962\n",
      "train loss:0.0009734486847762111\n",
      "train loss:0.00606697821637905\n",
      "train loss:0.0007713529137352516\n",
      "train loss:0.004710050063090389\n",
      "train loss:0.0002812517897165619\n",
      "train loss:0.00034471301374000514\n",
      "train loss:0.00018989026637206537\n",
      "train loss:0.0003763647563098089\n",
      "train loss:0.0007789389034324314\n",
      "train loss:0.000976572221311462\n",
      "train loss:0.0003854905431405072\n",
      "train loss:0.0005965643422583309\n",
      "train loss:0.0005814918616845387\n",
      "train loss:6.836360336571523e-05\n",
      "train loss:0.0027528702742441622\n",
      "train loss:0.0008244274174083095\n",
      "train loss:0.007163061893442458\n",
      "train loss:0.0005360280447103188\n",
      "train loss:0.001301932813313887\n",
      "train loss:0.002696161297819478\n",
      "train loss:0.004533985707530398\n",
      "train loss:0.003633518129695194\n",
      "train loss:0.0002981010047344402\n",
      "train loss:0.0024689698167514066\n",
      "train loss:0.0024952831955385273\n",
      "train loss:0.0004917449406665643\n",
      "train loss:0.00015452703033834382\n",
      "train loss:0.0003949735980058458\n",
      "train loss:0.0003657078316747172\n",
      "train loss:0.0005530477857498424\n",
      "train loss:0.0036776290393315245\n",
      "train loss:0.005773235503991817\n",
      "train loss:0.0020194333089575025\n",
      "train loss:0.002530500492438388\n",
      "train loss:0.0005926910266752294\n",
      "train loss:0.001393629425651553\n",
      "train loss:0.0015274503081928882\n",
      "train loss:0.0002899923540215285\n",
      "train loss:0.0038980003942905043\n",
      "train loss:0.002243900963528014\n",
      "train loss:0.0026788631016904057\n",
      "train loss:0.000460443581164166\n",
      "train loss:0.00039724332892101735\n",
      "train loss:0.008605347496516398\n",
      "train loss:0.004273243972807529\n",
      "train loss:0.0029224761581868415\n",
      "train loss:0.016750598980076324\n",
      "train loss:0.0014680286362144031\n",
      "train loss:0.00027054995977228896\n",
      "train loss:0.0006358752218217059\n",
      "train loss:0.0026870855716171534\n",
      "train loss:0.0019759409354600296\n",
      "train loss:0.0005842495439817242\n",
      "train loss:0.00032134079100638646\n",
      "train loss:0.0015303247643516796\n",
      "train loss:0.0020576889139914474\n",
      "train loss:0.0026153200651029313\n",
      "train loss:0.008279808014725809\n",
      "train loss:0.002834590224078724\n",
      "train loss:0.027346167493954954\n",
      "train loss:0.0005598549490378092\n",
      "train loss:0.009010069448827715\n",
      "train loss:0.00423359501763525\n",
      "train loss:0.0022373826072150595\n",
      "train loss:0.0003302377885758717\n",
      "train loss:0.010321856867465421\n",
      "train loss:0.000924262634920344\n",
      "train loss:0.006089886061411686\n",
      "train loss:0.0012744178888171875\n",
      "train loss:0.0002029276797725098\n",
      "train loss:0.001741291861642424\n",
      "train loss:0.000424709159292625\n",
      "train loss:0.00021500586296806313\n",
      "train loss:0.005533315209236919\n",
      "train loss:0.00028634458251414224\n",
      "train loss:0.0009036945850871453\n",
      "train loss:0.0013286663985275773\n",
      "train loss:0.0009308573128875404\n",
      "train loss:0.0018921317493787039\n",
      "train loss:0.0010719319949808168\n",
      "train loss:0.0013177278357006008\n",
      "train loss:0.0004574242495450691\n",
      "train loss:0.002371401915545049\n",
      "train loss:0.0019804319753872744\n",
      "train loss:0.0032313987417947206\n",
      "train loss:0.0009251865050975973\n",
      "train loss:0.0017774800605752895\n",
      "train loss:0.004696278904472107\n",
      "train loss:0.0011398182244467757\n",
      "train loss:0.011620376934971805\n",
      "train loss:0.0012494923504476978\n",
      "train loss:0.00048459673541670313\n",
      "train loss:0.006184179262054823\n",
      "train loss:0.00756694433481066\n",
      "train loss:0.00011031536496489723\n",
      "train loss:0.003085980911395036\n",
      "train loss:0.0025068012044191764\n",
      "train loss:0.004192736451880183\n",
      "train loss:0.006140235428627819\n",
      "train loss:0.0023082091518365913\n",
      "train loss:0.0007971996876563172\n",
      "train loss:0.005536069662271219\n",
      "train loss:0.0008728476314275798\n",
      "train loss:0.0019994541761002836\n",
      "train loss:0.0028015631709774054\n",
      "train loss:0.02159024138299854\n",
      "train loss:0.002555179470940608\n",
      "train loss:0.0008468628728438153\n",
      "train loss:0.003460804682215548\n",
      "train loss:0.0007281058432680775\n",
      "train loss:0.005852769963331652\n",
      "train loss:0.010313081264511326\n",
      "train loss:0.0036103528731381406\n",
      "train loss:0.0002443548175842496\n",
      "train loss:0.00031423366579566586\n",
      "train loss:0.008738486457272357\n",
      "train loss:0.0005029546378808549\n",
      "train loss:0.0009276784714068343\n",
      "train loss:0.004875262191237726\n",
      "train loss:0.0007887987019234937\n",
      "train loss:0.00044709081463483147\n",
      "train loss:0.0021723224352540164\n",
      "train loss:0.00452066248580284\n",
      "train loss:0.0002729636200545317\n",
      "train loss:0.01623036446722955\n",
      "train loss:0.0005496219428816562\n",
      "train loss:0.0017939890012895988\n",
      "train loss:0.00480915107467173\n",
      "train loss:0.0003261114459089243\n",
      "train loss:0.0006697789898302464\n",
      "train loss:0.0013928697323194092\n",
      "train loss:0.0009405620857789874\n",
      "train loss:0.001908862666853673\n",
      "train loss:0.0008772044401923515\n",
      "train loss:0.002483272014151027\n",
      "train loss:0.004023089639512667\n",
      "train loss:0.00023706552418079722\n",
      "train loss:0.0020936506698121804\n",
      "train loss:0.02282529804396056\n",
      "train loss:0.003071363863205169\n",
      "train loss:0.00211841209288739\n",
      "train loss:0.000341886709077241\n",
      "train loss:0.002300144527571237\n",
      "train loss:0.005082829656470091\n",
      "train loss:0.0007653082736775711\n",
      "train loss:0.014260382295734737\n",
      "train loss:0.005221642708803142\n",
      "train loss:0.001706018752326657\n",
      "train loss:0.0023902868130836596\n",
      "train loss:0.002462589314507566\n",
      "train loss:0.0006311029074118923\n",
      "train loss:0.0007542734192351641\n",
      "train loss:0.0002824966255910666\n",
      "train loss:0.0007317413211307972\n",
      "train loss:0.00917962302521281\n",
      "train loss:0.0004044144769702688\n",
      "train loss:0.010991777291068388\n",
      "train loss:0.002552115828779057\n",
      "train loss:0.0007864318483072574\n",
      "train loss:0.001129783130208909\n",
      "train loss:0.0007980557122287715\n",
      "train loss:0.0007492922779161546\n",
      "train loss:0.0032575849251208467\n",
      "train loss:0.019478701556644808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011192902630219079\n",
      "train loss:0.0002981707296808134\n",
      "train loss:0.03153749268085135\n",
      "train loss:0.00035612056249881415\n",
      "train loss:0.001315935854838285\n",
      "train loss:0.0033678912978031437\n",
      "train loss:0.000675055856736888\n",
      "train loss:0.013916360866341357\n",
      "train loss:0.0014419369354181962\n",
      "train loss:0.004604810864639656\n",
      "train loss:0.006188174082937699\n",
      "train loss:0.007290144324691329\n",
      "train loss:0.003482494830259975\n",
      "train loss:0.001374009741717957\n",
      "train loss:0.004069058926697293\n",
      "train loss:0.0029933865537326906\n",
      "train loss:0.00027233648060269125\n",
      "train loss:0.0244230846696554\n",
      "train loss:0.004393393411499775\n",
      "train loss:0.00045847143441219514\n",
      "train loss:0.002720285123993292\n",
      "train loss:0.0015125858494552833\n",
      "train loss:0.0008828193131216179\n",
      "train loss:0.0004946254951248639\n",
      "train loss:0.00024613621700919966\n",
      "train loss:0.0021657450531048657\n",
      "train loss:0.0005466318358381346\n",
      "train loss:0.006599646039613537\n",
      "train loss:0.008899785829171605\n",
      "train loss:0.003757090711161376\n",
      "train loss:0.0011811747020143582\n",
      "train loss:0.010887668662858768\n",
      "train loss:0.004433493680007391\n",
      "train loss:0.0021798790929439533\n",
      "train loss:0.001958308959893106\n",
      "train loss:0.0006746504518019267\n",
      "train loss:0.00041728334556018513\n",
      "train loss:0.0013314767826664972\n",
      "train loss:0.0004960982102472886\n",
      "train loss:0.0004531920480355263\n",
      "train loss:0.013584572581832106\n",
      "train loss:0.0012551126106306457\n",
      "train loss:0.0022544262017800813\n",
      "train loss:0.0006281821802528965\n",
      "train loss:0.0016040340025036425\n",
      "train loss:0.0014537292577144168\n",
      "train loss:0.002655221127173371\n",
      "train loss:0.004364914687709758\n",
      "train loss:0.002743306196911988\n",
      "train loss:0.0006869508200239732\n",
      "train loss:0.00020436553262217428\n",
      "train loss:0.0028114881262292896\n",
      "train loss:0.0067410233803672495\n",
      "train loss:0.0005396835788157478\n",
      "train loss:0.000994747297243066\n",
      "train loss:0.0014480384909325641\n",
      "train loss:0.00280301677934873\n",
      "train loss:0.01612307077183579\n",
      "train loss:0.0032288671752658243\n",
      "train loss:0.005059151125001226\n",
      "train loss:0.001218508962620843\n",
      "train loss:0.0004895002681521557\n",
      "train loss:0.0022315102166525543\n",
      "train loss:0.004360534959481816\n",
      "train loss:0.003906642281624098\n",
      "train loss:0.0012867150662008667\n",
      "train loss:0.006451017404814565\n",
      "train loss:0.004374415338364569\n",
      "train loss:0.00017455144550002088\n",
      "train loss:0.007080686058174004\n",
      "train loss:0.00128148805548893\n",
      "train loss:0.003493675728641313\n",
      "train loss:0.10164182939299456\n",
      "train loss:0.003507262854565385\n",
      "train loss:0.0004074987380704592\n",
      "train loss:0.013919225870010925\n",
      "train loss:0.0018666742609182141\n",
      "train loss:0.00017204367907781563\n",
      "train loss:0.011922032084447637\n",
      "train loss:0.0014381498122679284\n",
      "train loss:0.0006524977785825141\n",
      "train loss:0.002636610783241352\n",
      "train loss:0.0006652235942552036\n",
      "train loss:0.006588917877245283\n",
      "train loss:0.0019225189090368957\n",
      "train loss:0.0008822717811001865\n",
      "train loss:0.0037435682628263905\n",
      "=== epoch:17, train acc:0.999, test acc:0.985 ===\n",
      "train loss:0.0005223571911178606\n",
      "train loss:0.0007501184769424077\n",
      "train loss:0.00224803547100474\n",
      "train loss:0.0009655755317704482\n",
      "train loss:0.002624029728140236\n",
      "train loss:0.0014450240293297947\n",
      "train loss:0.0004606160244958596\n",
      "train loss:0.004490031451196718\n",
      "train loss:0.000823578463643777\n",
      "train loss:0.0021207433381601683\n",
      "train loss:6.725353134455248e-05\n",
      "train loss:0.00019611227652286574\n",
      "train loss:0.0002266020450389915\n",
      "train loss:0.0020739392322431226\n",
      "train loss:0.0029182567769401413\n",
      "train loss:0.002723037620526995\n",
      "train loss:0.000606039671615393\n",
      "train loss:0.0003588013154106903\n",
      "train loss:7.12615526464253e-05\n",
      "train loss:0.0007652861002185857\n",
      "train loss:0.0004165701966013708\n",
      "train loss:0.00018842982454393058\n",
      "train loss:0.0002850497845545667\n",
      "train loss:0.0471529721421082\n",
      "train loss:0.008537043225297625\n",
      "train loss:0.001371655776585322\n",
      "train loss:0.0003401365184556738\n",
      "train loss:0.000314080578608049\n",
      "train loss:0.0012827918771226316\n",
      "train loss:0.008344012868323092\n",
      "train loss:0.00028582210902923933\n",
      "train loss:0.0008317796025216462\n",
      "train loss:0.00028000817342139795\n",
      "train loss:0.0016570706761431517\n",
      "train loss:0.0005943111681058371\n",
      "train loss:0.0044930313714205295\n",
      "train loss:0.0007254224435289678\n",
      "train loss:0.004348452476534183\n",
      "train loss:0.0008151652956864147\n",
      "train loss:0.00039221503015373954\n",
      "train loss:0.009521987690483676\n",
      "train loss:0.0017769125679432036\n",
      "train loss:0.0014900519157290237\n",
      "train loss:0.007037448092042309\n",
      "train loss:0.00021006865005492598\n",
      "train loss:0.00012646201831748396\n",
      "train loss:0.0002208178797416252\n",
      "train loss:0.0006749660637505039\n",
      "train loss:0.012327096661488037\n",
      "train loss:9.435379313250123e-05\n",
      "train loss:0.001591034689496658\n",
      "train loss:0.006041222173099492\n",
      "train loss:3.0017331024554824e-05\n",
      "train loss:0.0007800850378279671\n",
      "train loss:0.0013411442564538881\n",
      "train loss:0.0004870186506376162\n",
      "train loss:0.0010334093496725436\n",
      "train loss:0.0019457629695545174\n",
      "train loss:0.00027124820974571003\n",
      "train loss:0.0015025258679326275\n",
      "train loss:0.0033694704931569288\n",
      "train loss:0.000986375292745371\n",
      "train loss:0.002717080967488354\n",
      "train loss:0.01153227782461312\n",
      "train loss:0.00011517106591770497\n",
      "train loss:0.0031177702705387934\n",
      "train loss:0.0002494662701135093\n",
      "train loss:0.0011033108218968688\n",
      "train loss:0.0013464340646409877\n",
      "train loss:0.011301959706638805\n",
      "train loss:0.0009437021180962343\n",
      "train loss:0.005399730159163891\n",
      "train loss:0.0022424841868958125\n",
      "train loss:0.0011472361356271526\n",
      "train loss:0.005906522460498977\n",
      "train loss:0.0019320935046904235\n",
      "train loss:0.002687555174666085\n",
      "train loss:0.0006712795607892878\n",
      "train loss:0.0005858792278955348\n",
      "train loss:0.00034398748305316764\n",
      "train loss:0.0037045240602563024\n",
      "train loss:0.001505349072770021\n",
      "train loss:0.0003154785467678286\n",
      "train loss:0.0011668428611839392\n",
      "train loss:0.023536805251653314\n",
      "train loss:0.0013803232673613047\n",
      "train loss:0.0007976070894828075\n",
      "train loss:0.00017603763116944948\n",
      "train loss:0.0057140813432635775\n",
      "train loss:0.00035436290402649016\n",
      "train loss:0.001247688148598748\n",
      "train loss:0.0006917251181484276\n",
      "train loss:0.00783728932271657\n",
      "train loss:0.002424749558865585\n",
      "train loss:0.001626726688315462\n",
      "train loss:0.0008576355130518105\n",
      "train loss:0.00023282609515766297\n",
      "train loss:0.0003050171901112966\n",
      "train loss:0.009136454621063139\n",
      "train loss:0.0027549489265202894\n",
      "train loss:0.001111867370777827\n",
      "train loss:0.006589052852270719\n",
      "train loss:0.0005742061641342426\n",
      "train loss:0.00186641278650614\n",
      "train loss:0.0003839828631932804\n",
      "train loss:0.0030132560525882803\n",
      "train loss:0.00031980207244009266\n",
      "train loss:0.0024160394274563893\n",
      "train loss:0.0014413384123809474\n",
      "train loss:0.0008196068095394685\n",
      "train loss:0.0006257807740037275\n",
      "train loss:0.00026668608285435714\n",
      "train loss:0.0009049017470307138\n",
      "train loss:0.004002741925300425\n",
      "train loss:0.0024383814950210674\n",
      "train loss:0.0005325000058443496\n",
      "train loss:0.0085163405877275\n",
      "train loss:0.0009312195927096299\n",
      "train loss:0.00833091482309154\n",
      "train loss:0.0004653558571230762\n",
      "train loss:0.00048254623433874213\n",
      "train loss:0.0023433388832138544\n",
      "train loss:0.00021223939612487894\n",
      "train loss:0.005288101565434472\n",
      "train loss:0.004943876096772648\n",
      "train loss:0.0011740128968750457\n",
      "train loss:0.0008855536577074139\n",
      "train loss:0.00125634815209307\n",
      "train loss:0.0009405319354235428\n",
      "train loss:0.0015375341654052087\n",
      "train loss:0.0005241776208795019\n",
      "train loss:0.0034598492087007443\n",
      "train loss:0.0011217614848990317\n",
      "train loss:0.000603419515972911\n",
      "train loss:0.0037007200880908083\n",
      "train loss:0.014029201174695121\n",
      "train loss:0.001391049390678209\n",
      "train loss:0.00020447681893394836\n",
      "train loss:0.0014023073602486872\n",
      "train loss:0.00020240616603829398\n",
      "train loss:0.002504871188777464\n",
      "train loss:0.0033186692658987516\n",
      "train loss:0.0010243259990237947\n",
      "train loss:0.0002467628875043204\n",
      "train loss:0.0008949387945937374\n",
      "train loss:0.00013684487093488593\n",
      "train loss:0.0005167839107380703\n",
      "train loss:0.000691429685409552\n",
      "train loss:0.0013795984710197663\n",
      "train loss:0.0012183510965479297\n",
      "train loss:0.006318774569279015\n",
      "train loss:0.002098247336932372\n",
      "train loss:0.01870424901871097\n",
      "train loss:9.586716438929778e-05\n",
      "train loss:0.0007800171848138263\n",
      "train loss:0.003967828803684797\n",
      "train loss:0.00012282737003929434\n",
      "train loss:0.00022257384526736822\n",
      "train loss:0.0025875156063148983\n",
      "train loss:0.0005942500470540795\n",
      "train loss:0.0014768254800381947\n",
      "train loss:0.0010151868634456567\n",
      "train loss:0.00039275734791540957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010101013696364185\n",
      "train loss:0.0004925669861528987\n",
      "train loss:0.003549338655256888\n",
      "train loss:0.0002128730333501305\n",
      "train loss:0.003937461741614645\n",
      "train loss:0.0011360410712009813\n",
      "train loss:0.002252997328907901\n",
      "train loss:0.0013215723002662255\n",
      "train loss:0.0007064956866212994\n",
      "train loss:0.000568618128469478\n",
      "train loss:0.0008512759570090392\n",
      "train loss:0.004067354388118975\n",
      "train loss:0.003772304044855102\n",
      "train loss:0.0005321144923870027\n",
      "train loss:0.005706037049049153\n",
      "train loss:0.0005054700877897879\n",
      "train loss:0.0013202545418985168\n",
      "train loss:0.0026463559874614234\n",
      "train loss:0.008248310027217313\n",
      "train loss:0.014692812175883332\n",
      "train loss:0.0037934293379060335\n",
      "train loss:0.001242519546076462\n",
      "train loss:0.0015694004743390566\n",
      "train loss:0.0008247368823185149\n",
      "train loss:0.000991544664956923\n",
      "train loss:0.0003561703125741354\n",
      "train loss:0.0012743600514299595\n",
      "train loss:0.0007754276099193034\n",
      "train loss:0.0031901574220041984\n",
      "train loss:0.00030846248261170983\n",
      "train loss:0.0007464323750804905\n",
      "train loss:0.0012674629646263092\n",
      "train loss:0.0011566360201166706\n",
      "train loss:0.00937472011758333\n",
      "train loss:0.0019034367155020585\n",
      "train loss:0.008113958256819861\n",
      "train loss:0.0004977015374096403\n",
      "train loss:0.017535226813369817\n",
      "train loss:0.0012711137358608013\n",
      "train loss:0.0006670040702122348\n",
      "train loss:0.0009353100144095024\n",
      "train loss:0.000325353794610748\n",
      "train loss:0.0017166967579122106\n",
      "train loss:0.0005306268613139568\n",
      "train loss:0.001175360524700894\n",
      "train loss:0.0006505703178115788\n",
      "train loss:0.0014083355999171595\n",
      "train loss:0.01983692964021646\n",
      "train loss:0.006962428993369927\n",
      "train loss:0.0005757558558898796\n",
      "train loss:0.0007633602020143455\n",
      "train loss:0.0029298491038711695\n",
      "train loss:0.0020207610300621136\n",
      "train loss:0.003836282438642539\n",
      "train loss:0.003252467861233435\n",
      "train loss:0.0005170626978863795\n",
      "train loss:0.0008540376484786335\n",
      "train loss:0.0004353798947675451\n",
      "train loss:0.0016889057557716851\n",
      "train loss:0.0007123731561513505\n",
      "train loss:0.0007794691774255792\n",
      "train loss:0.02574213458536593\n",
      "train loss:0.001360161558639795\n",
      "train loss:0.0006617245865608678\n",
      "train loss:0.009262252587951672\n",
      "train loss:0.0005300040247624478\n",
      "train loss:0.00033426222042389826\n",
      "train loss:0.0035956178753806444\n",
      "train loss:0.0016060093809872691\n",
      "train loss:0.0019008679324164096\n",
      "train loss:0.0008203426390810096\n",
      "train loss:0.0023138348051289378\n",
      "train loss:0.0027300919330543\n",
      "train loss:0.0014668138601030237\n",
      "train loss:0.002633245878738927\n",
      "train loss:0.0015338315174469957\n",
      "train loss:0.000669352718504567\n",
      "train loss:8.550759240789237e-05\n",
      "train loss:0.0012570600431442173\n",
      "train loss:0.002057680083673503\n",
      "train loss:0.0029362778011882136\n",
      "train loss:0.0004705004204056126\n",
      "train loss:0.0008677592601332828\n",
      "train loss:0.002268544814841425\n",
      "train loss:0.0016017395143829273\n",
      "train loss:0.00021171384259182152\n",
      "train loss:0.0016893587239320646\n",
      "train loss:0.0016684242976197196\n",
      "train loss:0.0019481884871345447\n",
      "train loss:0.002686622747540925\n",
      "train loss:0.000195235100350303\n",
      "train loss:0.024770194012639673\n",
      "train loss:0.0050368946802272765\n",
      "train loss:0.0027792450540959847\n",
      "train loss:0.02381615957076764\n",
      "train loss:0.0019653517907744166\n",
      "train loss:0.001156120345683624\n",
      "train loss:0.011116979493305297\n",
      "train loss:0.003525714943091256\n",
      "train loss:0.001375796296804669\n",
      "train loss:0.0051924034747136616\n",
      "train loss:0.0011561577682904667\n",
      "train loss:0.0010457547071772008\n",
      "train loss:0.002823675259933103\n",
      "train loss:0.006363808553574886\n",
      "train loss:0.0013485137723737637\n",
      "train loss:0.00016940556391710187\n",
      "train loss:0.0024255408883372097\n",
      "train loss:0.000241417594912922\n",
      "train loss:0.00033452537993326184\n",
      "train loss:0.0036389361138002983\n",
      "train loss:0.00011122422733222278\n",
      "train loss:0.0011726079185357086\n",
      "train loss:0.03910031942977601\n",
      "train loss:0.002194279484771076\n",
      "train loss:0.003958196793923214\n",
      "train loss:0.0012454506284047741\n",
      "train loss:0.003392190898182151\n",
      "train loss:0.00039846756264393275\n",
      "train loss:0.0005278481934677088\n",
      "train loss:0.0004297323530589758\n",
      "train loss:0.0022995238029236355\n",
      "train loss:0.005574650730788027\n",
      "train loss:0.003548633407583214\n",
      "train loss:0.0014706675797546472\n",
      "train loss:0.0038044188025315156\n",
      "train loss:0.00265799240190044\n",
      "train loss:0.00033937722141904534\n",
      "train loss:0.0020127013785020496\n",
      "train loss:0.0007868172056608773\n",
      "train loss:0.0012573124953667652\n",
      "train loss:0.0007148340389876336\n",
      "train loss:0.0013387869892667393\n",
      "train loss:0.008686397339923956\n",
      "train loss:0.0015959378891951589\n",
      "train loss:0.0002930191611045508\n",
      "train loss:0.0017885129432500667\n",
      "train loss:0.0008956287360135853\n",
      "train loss:0.0024990740658882146\n",
      "train loss:0.0008221223301697865\n",
      "train loss:0.0029205278264563977\n",
      "train loss:0.007544977119000916\n",
      "train loss:0.001921962651780141\n",
      "train loss:0.0030522295474216497\n",
      "train loss:0.00021400015369280644\n",
      "train loss:0.0059401103125209355\n",
      "train loss:8.284195552397632e-05\n",
      "train loss:0.05254963696730321\n",
      "train loss:0.003878258666011588\n",
      "train loss:0.015759714238392085\n",
      "train loss:0.003136893380762731\n",
      "train loss:0.003526617153275905\n",
      "train loss:0.0004950618605909777\n",
      "train loss:0.00023485784350382296\n",
      "train loss:0.0031257127157142722\n",
      "train loss:0.01455513023440691\n",
      "train loss:0.0027460555482300714\n",
      "train loss:0.029622019212542258\n",
      "train loss:0.0002300187578850308\n",
      "train loss:0.008736151306510788\n",
      "train loss:0.0003235079089273686\n",
      "train loss:0.0006335294307305379\n",
      "train loss:0.0036599987435261463\n",
      "train loss:0.0026181887308263595\n",
      "train loss:0.00012518245751239756\n",
      "train loss:0.0004011312413548402\n",
      "train loss:0.005813736147716394\n",
      "train loss:0.004702788248913706\n",
      "train loss:0.0002140893038486945\n",
      "train loss:0.0019091867524724073\n",
      "train loss:0.002877561031923645\n",
      "train loss:0.003381199260751927\n",
      "train loss:0.0024091119340559726\n",
      "train loss:0.0011802353720132216\n",
      "train loss:0.0006517707967880887\n",
      "train loss:0.0003447998396407952\n",
      "train loss:0.0019873422468135176\n",
      "train loss:0.00025473934580321416\n",
      "train loss:0.0018990232225589748\n",
      "train loss:0.00012097092346798843\n",
      "train loss:0.004730011333061664\n",
      "train loss:0.0034390712239581477\n",
      "train loss:0.00195010333309294\n",
      "train loss:0.00661037521730839\n",
      "train loss:0.002450022349847819\n",
      "train loss:0.0006200108539667596\n",
      "train loss:0.0009013387058405052\n",
      "train loss:0.0009025086630299745\n",
      "train loss:0.00019849182872340318\n",
      "train loss:0.0006822398370950031\n",
      "train loss:0.0001471829935392476\n",
      "train loss:0.0022737316657487324\n",
      "train loss:0.0049390649960369066\n",
      "train loss:0.003389126399980045\n",
      "train loss:0.0014760845916608866\n",
      "train loss:0.0030018704457474314\n",
      "train loss:0.00145846312994724\n",
      "train loss:0.0041197705394350435\n",
      "train loss:0.00011251431155677517\n",
      "train loss:0.002344489361356864\n",
      "train loss:0.0034770017127972587\n",
      "train loss:0.0007451698638485422\n",
      "train loss:6.276908185249796e-05\n",
      "train loss:0.039560456009343645\n",
      "train loss:0.00137186847015086\n",
      "train loss:0.0005691139804478044\n",
      "train loss:0.0036539717481377915\n",
      "train loss:0.002574944791469386\n",
      "train loss:0.0021391902786354554\n",
      "train loss:0.0001495083902667493\n",
      "train loss:0.012165561099908824\n",
      "train loss:0.00029560448738251524\n",
      "train loss:0.0012575925076605088\n",
      "train loss:0.005009098373204288\n",
      "train loss:0.0008533654712724902\n",
      "train loss:0.00018472660652192908\n",
      "train loss:0.0006523827752336475\n",
      "train loss:0.0002456924508493254\n",
      "train loss:0.0012574494136598849\n",
      "train loss:0.0005131385917541487\n",
      "train loss:0.001351471905878169\n",
      "train loss:0.0038498547246392694\n",
      "train loss:0.003477721787794765\n",
      "train loss:0.014862913030318132\n",
      "train loss:0.0006858007097255727\n",
      "train loss:0.0011158209892032731\n",
      "train loss:0.014348329757291911\n",
      "train loss:0.00048369285309269065\n",
      "train loss:0.001145279537849777\n",
      "train loss:0.0010168320474951706\n",
      "train loss:0.002631860793559795\n",
      "train loss:0.011125506139592707\n",
      "train loss:0.0006386489869851669\n",
      "train loss:0.0013124057316585874\n",
      "train loss:0.0009444333784248371\n",
      "train loss:0.005961025261130599\n",
      "train loss:0.0034495925291515486\n",
      "train loss:0.0009618354053032914\n",
      "train loss:0.0007196654515372628\n",
      "train loss:0.009634156078911943\n",
      "train loss:0.0030663815160823487\n",
      "train loss:0.002448495799038443\n",
      "train loss:0.0073378539238179675\n",
      "train loss:0.0005831306797691826\n",
      "train loss:0.0018172781760643106\n",
      "train loss:0.0034446496412948975\n",
      "train loss:0.02851314784870642\n",
      "train loss:0.0018832345672155518\n",
      "train loss:0.001405616822240379\n",
      "train loss:0.000990981388982797\n",
      "train loss:0.001053509088194003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006783838457799611\n",
      "train loss:0.0015720934198330703\n",
      "train loss:0.001019304130601405\n",
      "train loss:0.0020926219834671014\n",
      "train loss:0.00030476399147513105\n",
      "train loss:0.0008428903947233899\n",
      "train loss:0.0037726336084897\n",
      "train loss:0.0019882267841801336\n",
      "train loss:0.00015787028975402723\n",
      "train loss:0.0006253139400571789\n",
      "train loss:0.001493368014134456\n",
      "train loss:0.017724707882549248\n",
      "train loss:0.0033292136124362355\n",
      "train loss:0.02138596522557793\n",
      "train loss:0.001497305832728196\n",
      "train loss:0.004045015066305667\n",
      "train loss:0.0012187691319176825\n",
      "train loss:0.0005605036798271525\n",
      "train loss:0.003242414689070736\n",
      "train loss:0.0003668375192294333\n",
      "train loss:0.0010014096872009322\n",
      "train loss:0.0017054252327150356\n",
      "train loss:5.0454223028679606e-05\n",
      "train loss:0.005562066264608212\n",
      "train loss:0.003319862456473162\n",
      "train loss:0.0025323487053523215\n",
      "train loss:0.0001212288785568057\n",
      "train loss:0.0004240273462362786\n",
      "train loss:0.0029292416353478984\n",
      "train loss:0.0009899334471780892\n",
      "train loss:0.00018401926762249911\n",
      "train loss:0.024359364128441592\n",
      "train loss:5.1425326884060215e-05\n",
      "train loss:0.0004899013563025443\n",
      "train loss:0.0003021422661072038\n",
      "train loss:0.0034609308097334895\n",
      "train loss:0.0034912284596126473\n",
      "train loss:0.00029888461730354093\n",
      "train loss:0.0017713340152288055\n",
      "train loss:0.020525909725344488\n",
      "train loss:0.0015922702554044352\n",
      "train loss:0.007702071646104877\n",
      "train loss:0.0001386372151280567\n",
      "train loss:0.00038668282306248065\n",
      "train loss:0.002743848829798417\n",
      "train loss:0.020503433767869065\n",
      "train loss:0.00199373018322003\n",
      "train loss:9.925264791907172e-05\n",
      "train loss:0.005729621085032819\n",
      "train loss:0.014822611173037055\n",
      "train loss:0.00037743145708629537\n",
      "train loss:0.0065228613376028255\n",
      "train loss:0.00084924880858657\n",
      "train loss:0.005057609517509406\n",
      "train loss:0.0007407629097295207\n",
      "train loss:0.0012635324239040158\n",
      "train loss:0.001436281319566579\n",
      "train loss:0.0054994244792095515\n",
      "train loss:0.002288358413930233\n",
      "train loss:0.0005184601243891906\n",
      "train loss:0.005095528044158043\n",
      "train loss:0.004783887044389928\n",
      "train loss:0.0028527707932056528\n",
      "train loss:0.022397380612055682\n",
      "train loss:0.005427696897940938\n",
      "train loss:0.014577325082237998\n",
      "train loss:0.0004415666906285353\n",
      "train loss:0.004950899054407953\n",
      "train loss:0.002538920751706958\n",
      "train loss:0.000440591464693649\n",
      "train loss:0.0019294502372227374\n",
      "train loss:0.0028933033656283057\n",
      "train loss:0.0013918207685099963\n",
      "train loss:9.86956269498485e-05\n",
      "train loss:0.002122285075609731\n",
      "train loss:0.0028327883401242844\n",
      "train loss:0.0002913406519948308\n",
      "train loss:0.0032552615142872722\n",
      "train loss:0.00019003635487508912\n",
      "train loss:0.0005121040966633276\n",
      "train loss:0.0006686206281218914\n",
      "train loss:0.009243165003251614\n",
      "train loss:0.0003711284077441166\n",
      "train loss:0.008205573066858705\n",
      "train loss:0.0014125911816362437\n",
      "train loss:0.0012972107893761322\n",
      "train loss:0.0006454990429942434\n",
      "train loss:0.001516307283415356\n",
      "train loss:0.003223369638181966\n",
      "train loss:0.0020176501042877097\n",
      "train loss:0.0004618957393375578\n",
      "train loss:0.006851689969214877\n",
      "train loss:0.0002824000407135264\n",
      "train loss:0.002179262560871892\n",
      "train loss:0.00571432320493723\n",
      "train loss:0.00036164056388722596\n",
      "train loss:0.0003539143923960731\n",
      "train loss:0.0009019172667664502\n",
      "train loss:0.00246981042686899\n",
      "train loss:0.0008701789717727131\n",
      "train loss:0.0016854308798464543\n",
      "train loss:0.0007969625146048448\n",
      "train loss:0.0003872121416318498\n",
      "train loss:0.0006148775912598119\n",
      "train loss:0.003821473812358525\n",
      "train loss:0.0016012051701817024\n",
      "train loss:0.0005299592350008997\n",
      "train loss:0.001499505667852446\n",
      "train loss:0.00010067428214043664\n",
      "train loss:0.000582326226887747\n",
      "train loss:0.002183509742739396\n",
      "train loss:0.0004828117914647792\n",
      "train loss:0.016117450946021603\n",
      "train loss:0.00012165024338919053\n",
      "train loss:0.003031043732866673\n",
      "train loss:0.0011094962040877042\n",
      "train loss:0.0004478768710605087\n",
      "train loss:0.0029917230443313584\n",
      "train loss:0.0012000245233083943\n",
      "train loss:0.0006709472824293372\n",
      "train loss:0.0023559841305773794\n",
      "train loss:7.865762576707712e-05\n",
      "train loss:0.0018544025357893907\n",
      "train loss:0.0014105989549607245\n",
      "train loss:0.0005913679678571006\n",
      "train loss:0.019550199319398297\n",
      "train loss:0.0003293242408895077\n",
      "train loss:0.0032701320130879502\n",
      "train loss:0.0003518978406012921\n",
      "train loss:0.0016420537272496005\n",
      "train loss:0.00018411744232209827\n",
      "train loss:0.0021474804475443664\n",
      "train loss:0.005748373643866086\n",
      "train loss:0.0006075469009503432\n",
      "train loss:0.002026701069235756\n",
      "train loss:0.00042743852082435476\n",
      "train loss:0.003591259827499548\n",
      "train loss:0.0001796431611776066\n",
      "train loss:0.0008334193451544004\n",
      "train loss:0.0018578643888110954\n",
      "train loss:0.002061865286612392\n",
      "train loss:0.003316316621855676\n",
      "train loss:0.003709787785943735\n",
      "train loss:0.009655120753976598\n",
      "train loss:8.284611285236057e-05\n",
      "train loss:7.86885534776003e-05\n",
      "train loss:0.0003406020931557647\n",
      "train loss:0.0011173592743629376\n",
      "train loss:0.0002293249409790146\n",
      "train loss:0.0005395259286466253\n",
      "train loss:0.00034860212653400294\n",
      "train loss:0.0006211897135069743\n",
      "train loss:0.0005389974654223721\n",
      "train loss:0.0003157135108653697\n",
      "train loss:0.003993203266011227\n",
      "train loss:0.004065237439920463\n",
      "train loss:0.00039583708231820657\n",
      "train loss:0.0004094605974212212\n",
      "train loss:0.01979833006162167\n",
      "train loss:0.0026961683503985336\n",
      "train loss:0.0019366328063793905\n",
      "train loss:0.0013660198293605052\n",
      "train loss:0.003934493025444461\n",
      "train loss:0.0010685057833459551\n",
      "train loss:0.00035172857652016856\n",
      "train loss:0.0027235292120281044\n",
      "train loss:0.018503913431497068\n",
      "train loss:0.002349344397115529\n",
      "train loss:0.0007029861207620753\n",
      "train loss:0.0049868654073820864\n",
      "train loss:0.001184052163714066\n",
      "train loss:0.0003743755952407705\n",
      "train loss:0.00013580913145112738\n",
      "train loss:0.0007825690267727249\n",
      "train loss:0.002265875198917158\n",
      "train loss:7.812722362643479e-05\n",
      "train loss:0.0010905735804446915\n",
      "train loss:0.00035933684965436247\n",
      "train loss:0.0017915385542038545\n",
      "train loss:0.002392819422302456\n",
      "train loss:0.01423871380138345\n",
      "train loss:0.0007781411355623415\n",
      "train loss:0.000639859897069094\n",
      "train loss:0.00013627980818397797\n",
      "train loss:0.0007051826142821342\n",
      "train loss:0.008574433744988726\n",
      "=== epoch:18, train acc:1.0, test acc:0.988 ===\n",
      "train loss:0.004283809577958824\n",
      "train loss:0.0024374213119502607\n",
      "train loss:0.001078203855581042\n",
      "train loss:0.0017924458915014937\n",
      "train loss:0.0001742640029418138\n",
      "train loss:0.00010339663139825545\n",
      "train loss:0.0005665202638671126\n",
      "train loss:0.0003602766803319766\n",
      "train loss:0.0002712943776542709\n",
      "train loss:0.00011794806273365253\n",
      "train loss:0.016159442509508643\n",
      "train loss:0.0009719456334523897\n",
      "train loss:0.000694992319366615\n",
      "train loss:0.0009868309630578372\n",
      "train loss:0.0002792827118443894\n",
      "train loss:0.002401758698712006\n",
      "train loss:2.2325791291083412e-05\n",
      "train loss:0.0009398228072859939\n",
      "train loss:0.0003943902639950501\n",
      "train loss:0.002687907269563072\n",
      "train loss:0.0004767093086847294\n",
      "train loss:0.0009815734359661199\n",
      "train loss:0.00011696620166030847\n",
      "train loss:0.00011564955076671181\n",
      "train loss:0.0016337073477391052\n",
      "train loss:0.0016612325285776423\n",
      "train loss:0.0011388034037430738\n",
      "train loss:0.0017076491081149748\n",
      "train loss:0.00012130644220996107\n",
      "train loss:0.0005886387539881029\n",
      "train loss:0.0005364169551425743\n",
      "train loss:0.00041331439193155386\n",
      "train loss:0.00010303970536410388\n",
      "train loss:0.002017073076548429\n",
      "train loss:0.0009352652332250271\n",
      "train loss:0.00022544570461064035\n",
      "train loss:0.007948080175174335\n",
      "train loss:0.0010810912122945994\n",
      "train loss:0.003811319052641225\n",
      "train loss:0.0036275506866384937\n",
      "train loss:0.0005191089192597463\n",
      "train loss:0.0014853576831844316\n",
      "train loss:0.002873103887358884\n",
      "train loss:0.000677224293271186\n",
      "train loss:0.003759278382639608\n",
      "train loss:0.0030229262197881564\n",
      "train loss:0.00019729345488370874\n",
      "train loss:0.0028089058158435897\n",
      "train loss:0.005303563330282736\n",
      "train loss:2.689356698878573e-05\n",
      "train loss:0.004427844756253789\n",
      "train loss:0.0011977880241472597\n",
      "train loss:0.00048341633568381383\n",
      "train loss:0.00012366017628522952\n",
      "train loss:0.004415894753438975\n",
      "train loss:0.0030253954405078044\n",
      "train loss:0.0009806134227776687\n",
      "train loss:0.0006549318151165437\n",
      "train loss:0.000481988940175906\n",
      "train loss:0.0004364386996928559\n",
      "train loss:0.0027839658260517615\n",
      "train loss:0.0007833194147969691\n",
      "train loss:0.00032598288623515346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.010246180391409397\n",
      "train loss:0.00315146534606544\n",
      "train loss:0.0005357250436077823\n",
      "train loss:0.002830358285054473\n",
      "train loss:0.000962100730806963\n",
      "train loss:0.0020126588394340115\n",
      "train loss:0.0018396177147878964\n",
      "train loss:0.002726232294647482\n",
      "train loss:0.0005177257497778177\n",
      "train loss:0.0006308562413920801\n",
      "train loss:0.000331763014774154\n",
      "train loss:0.0005025609534211828\n",
      "train loss:0.003716152549053914\n",
      "train loss:0.000597696296836123\n",
      "train loss:0.0007184971538526771\n",
      "train loss:0.0024027289739409607\n",
      "train loss:0.0013066874771741858\n",
      "train loss:8.326245920937202e-05\n",
      "train loss:0.011887425156203118\n",
      "train loss:0.003970212428206162\n",
      "train loss:0.0006214107933895216\n",
      "train loss:0.00040606415117241354\n",
      "train loss:0.007521715343483282\n",
      "train loss:0.00028923948734187535\n",
      "train loss:0.0011749350531737946\n",
      "train loss:0.0008530060253557455\n",
      "train loss:0.035344478962335446\n",
      "train loss:0.0036927262918337155\n",
      "train loss:0.0023537151157687376\n",
      "train loss:0.00028550721618038745\n",
      "train loss:0.00040351592083190705\n",
      "train loss:1.3222114277674566e-05\n",
      "train loss:0.0002591360050579756\n",
      "train loss:0.0004946547957193609\n",
      "train loss:0.001565597963929658\n",
      "train loss:0.0012185910202955341\n",
      "train loss:0.0015001074930234672\n",
      "train loss:0.005087408722887574\n",
      "train loss:0.0005822699708791193\n",
      "train loss:0.0018315039707986608\n",
      "train loss:0.0008181702656223088\n",
      "train loss:0.0008762258543323796\n",
      "train loss:0.010278933403419378\n",
      "train loss:0.00014995007262176406\n",
      "train loss:0.00032285889612189796\n",
      "train loss:0.0006000353224175194\n",
      "train loss:0.0025784882913254333\n",
      "train loss:0.002999759286777545\n",
      "train loss:0.005510893296833472\n",
      "train loss:0.001662960646471843\n",
      "train loss:0.0024531478096980813\n",
      "train loss:0.0002613185584176166\n",
      "train loss:0.00022484149700376362\n",
      "train loss:0.0022022582513438944\n",
      "train loss:0.00039575969887022355\n",
      "train loss:0.00012833019726845863\n",
      "train loss:0.001797538066079789\n",
      "train loss:0.0003211868007743083\n",
      "train loss:0.004060913320594369\n",
      "train loss:0.001188089846729629\n",
      "train loss:0.0011908301712068024\n",
      "train loss:0.00033673444482666464\n",
      "train loss:0.0009241292492739966\n",
      "train loss:0.0036152922003382638\n",
      "train loss:0.0006493936637513995\n",
      "train loss:0.0003538980661556809\n",
      "train loss:0.010341766763796483\n",
      "train loss:0.0007194596809991317\n",
      "train loss:0.00435814185935254\n",
      "train loss:0.0011334590182839053\n",
      "train loss:0.00033632094255953105\n",
      "train loss:3.8110482783966436e-05\n",
      "train loss:0.0009059800730401229\n",
      "train loss:0.0002647574509320056\n",
      "train loss:0.00912467694322842\n",
      "train loss:0.001714196700552396\n",
      "train loss:0.0005913139663283664\n",
      "train loss:0.0020431234135325567\n",
      "train loss:0.001075348445829479\n",
      "train loss:0.0009309073366382616\n",
      "train loss:0.005601407118493965\n",
      "train loss:0.0005117185643741567\n",
      "train loss:0.004337729739419352\n",
      "train loss:0.00015093826864649788\n",
      "train loss:0.0006008901576315205\n",
      "train loss:0.0024228137577660693\n",
      "train loss:0.0007511037709994772\n",
      "train loss:0.0002134747704804703\n",
      "train loss:0.0009248685914419321\n",
      "train loss:1.9996671294076953e-05\n",
      "train loss:0.004642023921275697\n",
      "train loss:0.0017409362345309932\n",
      "train loss:0.0004154435307265937\n",
      "train loss:0.00021172836047007228\n",
      "train loss:0.00014485274392887976\n",
      "train loss:0.000971043088895139\n",
      "train loss:0.007879487292521884\n",
      "train loss:2.2951526713219126e-05\n",
      "train loss:0.0005517723922743563\n",
      "train loss:0.005133815717860951\n",
      "train loss:0.004245223805904568\n",
      "train loss:0.0013206591390108415\n",
      "train loss:0.014630231948724244\n",
      "train loss:0.0009804981041606961\n",
      "train loss:0.0018568624226654488\n",
      "train loss:0.004012128964639859\n",
      "train loss:0.0005368828003427824\n",
      "train loss:7.221858547046138e-05\n",
      "train loss:0.0023443680040459943\n",
      "train loss:0.003332521224019341\n",
      "train loss:0.00030505502604688165\n",
      "train loss:0.00023148724802323322\n",
      "train loss:0.0004023357545608426\n",
      "train loss:5.678232799021351e-05\n",
      "train loss:0.0002375468157420294\n",
      "train loss:0.002609930264200606\n",
      "train loss:0.0007452458563322932\n",
      "train loss:0.03666249945788609\n",
      "train loss:0.003299637830083248\n",
      "train loss:0.0006856532719822704\n",
      "train loss:0.0010477288673686462\n",
      "train loss:0.00029276694266464927\n",
      "train loss:0.005376106676342187\n",
      "train loss:2.8686216966823508e-05\n",
      "train loss:0.0001818893628084872\n",
      "train loss:0.0007549281950909462\n",
      "train loss:0.0009620355183755239\n",
      "train loss:0.000662829338848347\n",
      "train loss:0.00010409073991861264\n",
      "train loss:0.006689100475094796\n",
      "train loss:0.004014869573034739\n",
      "train loss:0.00019668593111481044\n",
      "train loss:0.005050889806579266\n",
      "train loss:0.0012011668718104288\n",
      "train loss:0.004354189344609175\n",
      "train loss:0.0007166114519830822\n",
      "train loss:0.0003558174567952361\n",
      "train loss:0.000599950135529877\n",
      "train loss:0.0016599591588012039\n",
      "train loss:0.0035991193719568226\n",
      "train loss:0.0008489556883445181\n",
      "train loss:0.0012010065980871199\n",
      "train loss:0.00018137201631487074\n",
      "train loss:0.018355324158661323\n",
      "train loss:0.004024889350289501\n",
      "train loss:0.007479384935265049\n",
      "train loss:0.00024941236705596946\n",
      "train loss:0.00021459824733818792\n",
      "train loss:0.0013129848620424686\n",
      "train loss:0.001506013844908715\n",
      "train loss:0.00045348937710319444\n",
      "train loss:0.0011200357912219076\n",
      "train loss:0.0014025121162012384\n",
      "train loss:0.0024363308970365713\n",
      "train loss:0.0044510569038723954\n",
      "train loss:0.00036548756979497694\n",
      "train loss:0.0005849259513645132\n",
      "train loss:0.015453805065906458\n",
      "train loss:0.0005634190877845319\n",
      "train loss:0.004833128295518775\n",
      "train loss:0.0002078080391833087\n",
      "train loss:0.0009817585743009082\n",
      "train loss:0.000786204666188902\n",
      "train loss:0.0014259650335213777\n",
      "train loss:0.00023511366021511309\n",
      "train loss:0.0009469516557113851\n",
      "train loss:0.0008604160419368336\n",
      "train loss:0.004496149054185817\n",
      "train loss:0.00028564521812114615\n",
      "train loss:0.0014869923607062968\n",
      "train loss:0.0014860950914853776\n",
      "train loss:0.0022834787328983534\n",
      "train loss:0.0005475265944997444\n",
      "train loss:0.0010206767842081339\n",
      "train loss:0.0004394057627165748\n",
      "train loss:0.0009685974951631382\n",
      "train loss:0.004351772285182349\n",
      "train loss:0.00044139748693203566\n",
      "train loss:0.0029778032597212265\n",
      "train loss:0.001511297714019856\n",
      "train loss:0.0006229751669676745\n",
      "train loss:0.0013117283753374782\n",
      "train loss:0.0005777178010394394\n",
      "train loss:0.0021032572552961274\n",
      "train loss:0.002916176205046867\n",
      "train loss:0.0015581432488471828\n",
      "train loss:0.0009563199455376903\n",
      "train loss:0.0014863744059208815\n",
      "train loss:0.0024196085297009226\n",
      "train loss:0.002009659723283316\n",
      "train loss:0.0012064332590481558\n",
      "train loss:0.000920913263780522\n",
      "train loss:0.0013717003029479777\n",
      "train loss:0.0053558761023706535\n",
      "train loss:0.003303782390976146\n",
      "train loss:8.641575637130885e-05\n",
      "train loss:0.00021087644890919243\n",
      "train loss:0.0009081243081976834\n",
      "train loss:6.351977550489305e-05\n",
      "train loss:0.000259942590818172\n",
      "train loss:0.0011749634870488444\n",
      "train loss:0.0004494707593238321\n",
      "train loss:0.001807344460461009\n",
      "train loss:0.00018121089865491807\n",
      "train loss:0.0002044975935378224\n",
      "train loss:0.0013279176184761846\n",
      "train loss:0.0004775309856392447\n",
      "train loss:0.0011880174327967283\n",
      "train loss:0.0002531542194080498\n",
      "train loss:0.00031544770941671407\n",
      "train loss:0.00021340285199033458\n",
      "train loss:0.006850329453520442\n",
      "train loss:0.000364090372203843\n",
      "train loss:0.00036830074531151455\n",
      "train loss:0.0002022288753551163\n",
      "train loss:0.0013094566932788706\n",
      "train loss:0.003206411724707181\n",
      "train loss:0.00012279563993774587\n",
      "train loss:0.000585366041695335\n",
      "train loss:4.106215174741661e-05\n",
      "train loss:0.0005275772909614714\n",
      "train loss:0.0007017884007810185\n",
      "train loss:9.793471452289505e-05\n",
      "train loss:0.00014313265077691223\n",
      "train loss:0.0003855745850850021\n",
      "train loss:0.0006023545151732333\n",
      "train loss:0.00011689562371176148\n",
      "train loss:0.001057316645278375\n",
      "train loss:0.0012351635601928943\n",
      "train loss:0.0002723768990078578\n",
      "train loss:0.0005943255997034883\n",
      "train loss:0.001828459186207659\n",
      "train loss:0.00043432628684063877\n",
      "train loss:8.332461186643918e-05\n",
      "train loss:0.0007861624415665374\n",
      "train loss:0.002254181304562389\n",
      "train loss:0.0001833188344262602\n",
      "train loss:0.0006815823265139512\n",
      "train loss:0.0017737976894928226\n",
      "train loss:0.0023947347395812555\n",
      "train loss:0.0016364364130947125\n",
      "train loss:0.0011218504898658126\n",
      "train loss:0.001826090161267116\n",
      "train loss:0.0009497114174768557\n",
      "train loss:0.0039286363815192425\n",
      "train loss:0.0012988113029120132\n",
      "train loss:0.00024893129877927593\n",
      "train loss:0.000566231644152015\n",
      "train loss:0.0009515676528768765\n",
      "train loss:0.0001425013144580008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0005059401713829831\n",
      "train loss:0.0004483383300967627\n",
      "train loss:0.001013684796093765\n",
      "train loss:0.00011666706957021455\n",
      "train loss:0.00015858771113054493\n",
      "train loss:0.0013518515145560892\n",
      "train loss:0.0004366586548526451\n",
      "train loss:0.0005248255047804106\n",
      "train loss:0.0020967563924186657\n",
      "train loss:0.0009589667739573432\n",
      "train loss:0.0003602740387865322\n",
      "train loss:0.0007435607770432691\n",
      "train loss:0.000799517874696196\n",
      "train loss:0.005485571416896361\n",
      "train loss:0.0014837893062603477\n",
      "train loss:0.0020133383660976985\n",
      "train loss:0.00012442748252248045\n",
      "train loss:0.008866814558806512\n",
      "train loss:0.027137277273573797\n",
      "train loss:0.0007387273973773849\n",
      "train loss:0.001817784642203987\n",
      "train loss:0.0015173204972914625\n",
      "train loss:0.00045467136937336027\n",
      "train loss:0.0085521117302517\n",
      "train loss:0.006371580847326468\n",
      "train loss:0.0005983753642401956\n",
      "train loss:0.004284491725712577\n",
      "train loss:0.0007678572663309875\n",
      "train loss:0.0026150499779968995\n",
      "train loss:0.002291913807932353\n",
      "train loss:0.00020809521043638955\n",
      "train loss:0.032636555178569185\n",
      "train loss:0.0009659469740276667\n",
      "train loss:0.0003601158364333356\n",
      "train loss:0.00010278385331345494\n",
      "train loss:0.0002669558096578453\n",
      "train loss:0.003445159965028405\n",
      "train loss:0.000213374583163024\n",
      "train loss:0.00017855880752695223\n",
      "train loss:0.008543259443570383\n",
      "train loss:0.003237396238823427\n",
      "train loss:0.0013210715079475868\n",
      "train loss:0.0060730941872628105\n",
      "train loss:0.005191250682172528\n",
      "train loss:0.0016560432889194804\n",
      "train loss:0.0046342853716474725\n",
      "train loss:0.0012427026102514623\n",
      "train loss:0.003291639085807123\n",
      "train loss:0.0003459326511575011\n",
      "train loss:0.0015665379649207978\n",
      "train loss:0.0007907548186341206\n",
      "train loss:0.00022818372356711616\n",
      "train loss:0.0004706355354781252\n",
      "train loss:0.00018140092812449454\n",
      "train loss:0.006783178794517816\n",
      "train loss:0.0005580297397346443\n",
      "train loss:0.004611251538468516\n",
      "train loss:0.005706381327560562\n",
      "train loss:0.0008387188823940222\n",
      "train loss:0.0004275867840901664\n",
      "train loss:0.0012660780412269536\n",
      "train loss:0.0006748727718393683\n",
      "train loss:0.00014702937774347175\n",
      "train loss:0.0017092241325922556\n",
      "train loss:0.0030169848294332863\n",
      "train loss:2.8699534512514474e-05\n",
      "train loss:0.0008389066024334917\n",
      "train loss:0.0003581656539649155\n",
      "train loss:0.00011284285800740425\n",
      "train loss:0.0018300208711426237\n",
      "train loss:0.00043142531614625987\n",
      "train loss:0.0017660578264125258\n",
      "train loss:0.0007266736678807259\n",
      "train loss:0.000967989850861823\n",
      "train loss:0.0012854265813873444\n",
      "train loss:0.0005698368679883149\n",
      "train loss:0.003547505062278054\n",
      "train loss:0.0007586543811771726\n",
      "train loss:0.0006764702995399273\n",
      "train loss:1.9420177809839196e-05\n",
      "train loss:4.169568492872058e-05\n",
      "train loss:0.00228003178072525\n",
      "train loss:0.0021288477836064793\n",
      "train loss:0.0009558451915556655\n",
      "train loss:0.0010315738963137973\n",
      "train loss:0.002202980116082352\n",
      "train loss:0.004145287711045317\n",
      "train loss:0.0018451832064749188\n",
      "train loss:0.0026060912125156818\n",
      "train loss:0.0016443787241119496\n",
      "train loss:0.004431486200909145\n",
      "train loss:0.0011242169344720877\n",
      "train loss:0.0007996036601110972\n",
      "train loss:9.489009222669852e-05\n",
      "train loss:0.0006546542356670405\n",
      "train loss:0.004267655129797141\n",
      "train loss:0.00011959998646651594\n",
      "train loss:0.006167977413830522\n",
      "train loss:0.0017028317578221548\n",
      "train loss:0.03671232075474847\n",
      "train loss:0.0016156951705395906\n",
      "train loss:0.0042923493542037176\n",
      "train loss:0.00035778438710922796\n",
      "train loss:0.0014757031565728982\n",
      "train loss:9.742773274217962e-05\n",
      "train loss:0.002929825954124741\n",
      "train loss:0.0138530797465771\n",
      "train loss:0.0036962568189553378\n",
      "train loss:0.0021175157657593725\n",
      "train loss:0.00033542647021481386\n",
      "train loss:0.0002980417104911927\n",
      "train loss:0.0017257012060038618\n",
      "train loss:0.0011300985289948015\n",
      "train loss:0.0035402184755563755\n",
      "train loss:0.0033561729509237496\n",
      "train loss:0.0026532511160739097\n",
      "train loss:0.003037571281831961\n",
      "train loss:0.0005578473713011951\n",
      "train loss:0.0007279615430185671\n",
      "train loss:0.001690334844221569\n",
      "train loss:0.00041814852485736685\n",
      "train loss:0.002377434989960147\n",
      "train loss:0.0038317548005468377\n",
      "train loss:0.000573749277651267\n",
      "train loss:4.656154543852624e-05\n",
      "train loss:0.003654493740825921\n",
      "train loss:0.002133843044122249\n",
      "train loss:0.0001481438830358257\n",
      "train loss:0.0014468787341156994\n",
      "train loss:0.00043104870304425954\n",
      "train loss:0.000847544025676861\n",
      "train loss:0.0019819130773504013\n",
      "train loss:0.0003222505401636376\n",
      "train loss:0.008656699297950965\n",
      "train loss:0.00039018146946370237\n",
      "train loss:0.0011379277168263085\n",
      "train loss:0.001004066384359333\n",
      "train loss:0.001304026465464196\n",
      "train loss:0.00028516365927463283\n",
      "train loss:0.0005862964902677901\n",
      "train loss:0.0006148624779622816\n",
      "train loss:0.00010786876466836757\n",
      "train loss:0.0009790382892474491\n",
      "train loss:0.0012475102315484383\n",
      "train loss:0.004465920321423518\n",
      "train loss:0.00037895688646540993\n",
      "train loss:0.00029511611978288993\n",
      "train loss:0.003166360103007693\n",
      "train loss:0.00021487113932444347\n",
      "train loss:0.015454918638051178\n",
      "train loss:0.0036891278290084946\n",
      "train loss:0.0001619923636369232\n",
      "train loss:0.0006677164010421753\n",
      "train loss:0.0010662953586309965\n",
      "train loss:0.02171422081458039\n",
      "train loss:0.00253923396152297\n",
      "train loss:0.005012312697507243\n",
      "train loss:0.0008161535004795966\n",
      "train loss:0.0001976128503853611\n",
      "train loss:0.001835906204477213\n",
      "train loss:0.0010110926703284357\n",
      "train loss:0.0013337885981509231\n",
      "train loss:0.007091761838006853\n",
      "train loss:0.00017530062759119674\n",
      "train loss:0.0054544884125647605\n",
      "train loss:0.0013903697572432553\n",
      "train loss:0.00044151668409202286\n",
      "train loss:0.005502719414872373\n",
      "train loss:0.004603662592624787\n",
      "train loss:0.00892968838106532\n",
      "train loss:0.0015898684253967993\n",
      "train loss:0.00597910517001624\n",
      "train loss:0.0029627424833015997\n",
      "train loss:0.0010888305088409607\n",
      "train loss:0.0016174430673206925\n",
      "train loss:0.0010346971819627294\n",
      "train loss:0.0005409607749996399\n",
      "train loss:0.0008923320260577137\n",
      "train loss:0.001301134036908585\n",
      "train loss:0.008345266979407876\n",
      "train loss:0.005450806788207352\n",
      "train loss:0.0014064279585494699\n",
      "train loss:0.005100738007573077\n",
      "train loss:0.00017555383406347172\n",
      "train loss:0.0021347156349434543\n",
      "train loss:0.00012521678844448954\n",
      "train loss:0.00015826477810856266\n",
      "train loss:0.00020065429775310438\n",
      "train loss:7.942734170601107e-05\n",
      "train loss:0.0005074270575394369\n",
      "train loss:0.0012421174776762961\n",
      "train loss:0.0023067885618358154\n",
      "train loss:0.0003953651937087454\n",
      "train loss:0.0027107000507642794\n",
      "train loss:0.0009982800495962141\n",
      "train loss:0.008537016919563815\n",
      "train loss:0.002305956591150049\n",
      "train loss:0.0019527843864729343\n",
      "train loss:0.0019065162698268811\n",
      "train loss:0.004662807458645709\n",
      "train loss:9.876838446681628e-05\n",
      "train loss:0.00023917375565783193\n",
      "train loss:5.335569314225727e-05\n",
      "train loss:0.005746602384500228\n",
      "train loss:0.005901338516446662\n",
      "train loss:0.012658471731216652\n",
      "train loss:0.0019138254249396686\n",
      "train loss:0.003125151895211083\n",
      "train loss:0.0012238656267889942\n",
      "train loss:0.0004548904672519566\n",
      "train loss:0.004833689923678012\n",
      "train loss:0.0007986799329690324\n",
      "train loss:0.0008961470298355477\n",
      "train loss:0.0022406094238481083\n",
      "train loss:0.0018021606182107685\n",
      "train loss:0.0006026705808212712\n",
      "train loss:0.0015414641557871978\n",
      "train loss:9.837450083476071e-05\n",
      "train loss:0.0413700586831592\n",
      "train loss:0.011429722491270248\n",
      "train loss:8.273873017825993e-05\n",
      "train loss:0.0005744719885175252\n",
      "train loss:0.00046614663302695894\n",
      "train loss:0.0032911266185615077\n",
      "train loss:0.00014166344630658548\n",
      "train loss:0.00012205185884721763\n",
      "train loss:0.0005973559183938613\n",
      "train loss:0.0023181795208666906\n",
      "train loss:0.0009240553796236095\n",
      "train loss:0.00014183618247157485\n",
      "train loss:0.0050331630943210815\n",
      "train loss:0.0002859807074284524\n",
      "train loss:0.0013939884722958338\n",
      "train loss:0.0002745908984921523\n",
      "train loss:0.0001741100643160731\n",
      "train loss:0.0034729399498374426\n",
      "train loss:0.00033423642657712786\n",
      "train loss:0.0005710495935453118\n",
      "train loss:0.0005016706975431569\n",
      "train loss:0.0034955015366268834\n",
      "train loss:0.001868473621941058\n",
      "train loss:0.0033108592179916614\n",
      "train loss:0.0009386084517479545\n",
      "train loss:0.006673612914555656\n",
      "train loss:0.0011524767482849673\n",
      "train loss:0.0020738620447508416\n",
      "train loss:7.818618399644277e-05\n",
      "train loss:0.00015762565569570956\n",
      "train loss:0.0002660680780404615\n",
      "train loss:0.01048587564206944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014897394447555823\n",
      "train loss:0.0007352870542232491\n",
      "train loss:0.0018754739601372558\n",
      "train loss:0.0002444240494739339\n",
      "train loss:0.0007246124113397763\n",
      "train loss:0.004950328413653917\n",
      "train loss:0.0010817093017920583\n",
      "train loss:9.965533051889302e-05\n",
      "train loss:0.0006279129005274204\n",
      "train loss:0.001016921319063007\n",
      "train loss:0.0011532325671468077\n",
      "train loss:0.0009443108302677239\n",
      "train loss:2.8343403572212096e-05\n",
      "train loss:0.0005606556684557158\n",
      "train loss:0.00018564708163204376\n",
      "train loss:0.00012897022468071542\n",
      "train loss:0.0013970114102203424\n",
      "train loss:0.0008112452227750489\n",
      "train loss:0.0008285283875685278\n",
      "train loss:0.00011926466734501597\n",
      "train loss:0.00011604563722446832\n",
      "train loss:0.000402652040763788\n",
      "train loss:0.0003317689859493584\n",
      "train loss:0.0030549809314759546\n",
      "train loss:0.00023799879967926644\n",
      "train loss:0.0005722089909882369\n",
      "train loss:0.001342405490542767\n",
      "train loss:0.00046984165028811234\n",
      "train loss:0.0035644041280765704\n",
      "train loss:0.002588463429908894\n",
      "train loss:0.002223813217966329\n",
      "train loss:0.00015917707620833406\n",
      "train loss:0.00020465070324778424\n",
      "train loss:0.0028858500183840453\n",
      "train loss:0.000500235176369846\n",
      "train loss:0.00022899084485629353\n",
      "train loss:7.16270511029664e-05\n",
      "=== epoch:19, train acc:0.998, test acc:0.993 ===\n",
      "train loss:0.00016952049392270646\n",
      "train loss:0.001394441702693383\n",
      "train loss:0.008558329839582468\n",
      "train loss:9.011529996680911e-05\n",
      "train loss:0.00021275269844223216\n",
      "train loss:0.0032707210666656893\n",
      "train loss:0.00013148154907417677\n",
      "train loss:0.0003060261003752041\n",
      "train loss:0.0005171704867048498\n",
      "train loss:0.0013505827462964714\n",
      "train loss:0.001699407897612818\n",
      "train loss:0.0012629262715406714\n",
      "train loss:0.0005791846448885777\n",
      "train loss:0.0001641559905444153\n",
      "train loss:0.00025126136188589096\n",
      "train loss:7.314715137947357e-05\n",
      "train loss:0.0003953308849626082\n",
      "train loss:8.597869724311105e-05\n",
      "train loss:0.020118544572792142\n",
      "train loss:0.00031700116366024933\n",
      "train loss:0.0013644786622722639\n",
      "train loss:0.003349543275385786\n",
      "train loss:0.000604851512172211\n",
      "train loss:0.000828995494948066\n",
      "train loss:0.0018811222310808906\n",
      "train loss:0.0009421846578800784\n",
      "train loss:0.0023760539115080088\n",
      "train loss:0.0017881653469437912\n",
      "train loss:0.0004921319214882666\n",
      "train loss:0.0012882461424078555\n",
      "train loss:0.0005666295145379754\n",
      "train loss:0.001387669243654876\n",
      "train loss:9.299979048645239e-05\n",
      "train loss:0.0007708621869157602\n",
      "train loss:0.0016953169931487695\n",
      "train loss:6.310428906334831e-05\n",
      "train loss:0.002311820928390034\n",
      "train loss:0.001804337150478734\n",
      "train loss:0.001036216610051464\n",
      "train loss:0.00013925083603803516\n",
      "train loss:0.00016315807862980972\n",
      "train loss:0.0008773191315882298\n",
      "train loss:0.0009538206239118812\n",
      "train loss:0.002227078818232668\n",
      "train loss:0.0009494085745829911\n",
      "train loss:0.000441173376882079\n",
      "train loss:0.0005841615487592434\n",
      "train loss:0.001859685237245025\n",
      "train loss:0.004891283066248272\n",
      "train loss:0.00030957679583883536\n",
      "train loss:0.0009528576554863339\n",
      "train loss:0.0012198766783418637\n",
      "train loss:0.0002175383781690514\n",
      "train loss:4.230144679612643e-05\n",
      "train loss:0.0006340374841280158\n",
      "train loss:0.0005172949065280906\n",
      "train loss:0.009641767063490124\n",
      "train loss:0.0005544266487450706\n",
      "train loss:7.606427613047338e-05\n",
      "train loss:0.00013968588985689638\n",
      "train loss:0.001981137208554999\n",
      "train loss:0.0033303158563040996\n",
      "train loss:0.0011501261330983897\n",
      "train loss:0.0005541824098331683\n",
      "train loss:0.00043351690370952903\n",
      "train loss:0.008294784168384308\n",
      "train loss:0.0003910402688021291\n",
      "train loss:0.0016175988301553841\n",
      "train loss:0.0005673247066003515\n",
      "train loss:0.00012160874759773475\n",
      "train loss:0.0010598619695107577\n",
      "train loss:0.0006983940325175217\n",
      "train loss:0.0010059633005147207\n",
      "train loss:0.0004636096019363356\n",
      "train loss:0.001332569431740671\n",
      "train loss:0.0016383457773847274\n",
      "train loss:0.0012390396339962294\n",
      "train loss:0.0014269791573978648\n",
      "train loss:0.000266497441560476\n",
      "train loss:0.005193846138888679\n",
      "train loss:0.011067235546036912\n",
      "train loss:0.0022501625999462667\n",
      "train loss:0.0003532620633251021\n",
      "train loss:0.0013162106031252296\n",
      "train loss:0.00032108071308829464\n",
      "train loss:0.00020003312091931825\n",
      "train loss:0.0015197115702923355\n",
      "train loss:0.00015868026410187946\n",
      "train loss:0.00046868117144591994\n",
      "train loss:0.0006434009566464351\n",
      "train loss:0.0005993315335460718\n",
      "train loss:0.0011780686222903562\n",
      "train loss:0.00036384263729490035\n",
      "train loss:0.0005043273763796344\n",
      "train loss:0.00010525654724529314\n",
      "train loss:0.0006723509680642455\n",
      "train loss:0.0005829991125669338\n",
      "train loss:0.0025172810171060728\n",
      "train loss:0.0021698533564506023\n",
      "train loss:0.0006274266446434599\n",
      "train loss:4.878073054352449e-05\n",
      "train loss:0.0003529843852816863\n",
      "train loss:0.0014831045447859497\n",
      "train loss:0.004346280669367256\n",
      "train loss:0.0009111911987933789\n",
      "train loss:0.0002634036417690815\n",
      "train loss:0.0012721733273599136\n",
      "train loss:0.007743010853917808\n",
      "train loss:0.0017644025652671094\n",
      "train loss:0.0017658037179486116\n",
      "train loss:0.0013112166956261476\n",
      "train loss:0.00036304746767688666\n",
      "train loss:0.0006011557104749018\n",
      "train loss:2.1917440964988544e-05\n",
      "train loss:0.0016993305984340267\n",
      "train loss:0.005986158209766833\n",
      "train loss:0.0011529458539737256\n",
      "train loss:0.0008095682394266893\n",
      "train loss:0.006791386316779128\n",
      "train loss:0.0013946998707163882\n",
      "train loss:0.0002749914662972117\n",
      "train loss:0.0002800281695899347\n",
      "train loss:0.0004373936972243095\n",
      "train loss:0.0037533286755305983\n",
      "train loss:0.0004669053630428005\n",
      "train loss:0.0016957368544685957\n",
      "train loss:0.00022575288754820514\n",
      "train loss:0.0006278946139769741\n",
      "train loss:0.0012850840547252668\n",
      "train loss:0.0014284409226918771\n",
      "train loss:0.0005773117818686174\n",
      "train loss:0.0030373536730279936\n",
      "train loss:3.246035879744004e-05\n",
      "train loss:0.00157272517617646\n",
      "train loss:0.00028697575431615703\n",
      "train loss:0.0036942593172607247\n",
      "train loss:0.002190484213902005\n",
      "train loss:0.0009150036164922465\n",
      "train loss:0.00020359970625569116\n",
      "train loss:0.005683932312841825\n",
      "train loss:0.0031657516557776523\n",
      "train loss:0.0008994414423646155\n",
      "train loss:0.001688393946309963\n",
      "train loss:0.0003396026085317765\n",
      "train loss:0.0016512043392590053\n",
      "train loss:0.0014217203652099777\n",
      "train loss:0.0003741170827899111\n",
      "train loss:0.03625109586816345\n",
      "train loss:0.0016186443147801965\n",
      "train loss:0.0014188330868532908\n",
      "train loss:0.0007357403541778819\n",
      "train loss:0.0003840682502623149\n",
      "train loss:0.0003453236910836722\n",
      "train loss:0.00022027707810442238\n",
      "train loss:0.0005751812318401449\n",
      "train loss:0.0025496983726521504\n",
      "train loss:0.0004875847038624291\n",
      "train loss:0.0012785602690578164\n",
      "train loss:0.008087960057087416\n",
      "train loss:0.0013810246002711045\n",
      "train loss:0.0009209872767368954\n",
      "train loss:0.005131030095866043\n",
      "train loss:0.0004232854945635781\n",
      "train loss:0.0012174803583728797\n",
      "train loss:0.00045467657861798745\n",
      "train loss:0.0021404626783559193\n",
      "train loss:0.0026153474997526395\n",
      "train loss:0.0009712446209857313\n",
      "train loss:0.00039614355893287693\n",
      "train loss:0.0024365851329134834\n",
      "train loss:0.0007715949818631446\n",
      "train loss:0.0008122876389334039\n",
      "train loss:0.0001264572486853845\n",
      "train loss:0.0005393569124363173\n",
      "train loss:0.0023284316262979755\n",
      "train loss:0.0027998887900027914\n",
      "train loss:0.001686201829769445\n",
      "train loss:0.00042825428495302714\n",
      "train loss:0.0012811884406183926\n",
      "train loss:0.003914434267722746\n",
      "train loss:0.002463136966614348\n",
      "train loss:0.0003135167804837382\n",
      "train loss:0.0008345553841702205\n",
      "train loss:0.0024291312605183952\n",
      "train loss:0.00011276237705971487\n",
      "train loss:0.0001076881975239823\n",
      "train loss:0.0012465777345804718\n",
      "train loss:0.002521184953971642\n",
      "train loss:0.0005900310181271664\n",
      "train loss:0.012189329664698283\n",
      "train loss:0.001503752967175933\n",
      "train loss:0.00037295381710108393\n",
      "train loss:0.0005521250284567274\n",
      "train loss:0.00123326328832108\n",
      "train loss:0.0010263385042264953\n",
      "train loss:0.0013374406020997098\n",
      "train loss:0.0015284406990281074\n",
      "train loss:0.0005571227652683821\n",
      "train loss:0.0004255145808537268\n",
      "train loss:0.0008231828958746397\n",
      "train loss:0.001484467026880944\n",
      "train loss:0.00017098315488568383\n",
      "train loss:0.002298732220508939\n",
      "train loss:0.002493910157915678\n",
      "train loss:2.905889790765634e-05\n",
      "train loss:0.00138327432475389\n",
      "train loss:0.0021381020022840417\n",
      "train loss:0.0004187772537812233\n",
      "train loss:0.00033414922394889\n",
      "train loss:0.0014644223638696102\n",
      "train loss:0.00035616769608029655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006949972991119066\n",
      "train loss:0.00034088513199196534\n",
      "train loss:0.011370868599175252\n",
      "train loss:0.0003832188848901011\n",
      "train loss:0.00031455335847750817\n",
      "train loss:0.0014063091088938038\n",
      "train loss:0.0016459431977609495\n",
      "train loss:0.0034369956066876827\n",
      "train loss:0.004901956499709988\n",
      "train loss:0.000561946532086487\n",
      "train loss:0.0004922405696454044\n",
      "train loss:0.001283109808067296\n",
      "train loss:0.000793005805700265\n",
      "train loss:0.0006281087683219604\n",
      "train loss:0.0004377619072227446\n",
      "train loss:0.0009820077589982807\n",
      "train loss:0.00013541422443266247\n",
      "train loss:0.0009441216143382521\n",
      "train loss:0.00013735840593672103\n",
      "train loss:0.003456445938862843\n",
      "train loss:0.0006345677809808406\n",
      "train loss:0.0010046801652237273\n",
      "train loss:0.00037751997027255375\n",
      "train loss:0.0008692615752301072\n",
      "train loss:0.0016320508075403533\n",
      "train loss:0.004592955340142185\n",
      "train loss:0.005457450922743385\n",
      "train loss:0.0009338684438039442\n",
      "train loss:0.0013551131334098398\n",
      "train loss:0.0007918923746938421\n",
      "train loss:0.0016479091305325593\n",
      "train loss:0.002962932989136224\n",
      "train loss:0.0002618480943120838\n",
      "train loss:0.003643132621018165\n",
      "train loss:0.0021679171809965117\n",
      "train loss:0.005469489062811738\n",
      "train loss:0.0015381760205210135\n",
      "train loss:0.0018846114580365883\n",
      "train loss:9.191133244374924e-05\n",
      "train loss:0.0016394290499203536\n",
      "train loss:0.0032149686989470056\n",
      "train loss:0.0009920254983873604\n",
      "train loss:0.00017973501797935692\n",
      "train loss:0.00035271504761159915\n",
      "train loss:0.00038291396852820097\n",
      "train loss:0.002309804793272931\n",
      "train loss:0.0006383426127569713\n",
      "train loss:0.004545608976223953\n",
      "train loss:0.006221976326735795\n",
      "train loss:0.0004620321052608637\n",
      "train loss:0.0026588321216910156\n",
      "train loss:0.00032626541902159315\n",
      "train loss:0.004603956048490588\n",
      "train loss:0.00037348458312820256\n",
      "train loss:0.0033484709782901872\n",
      "train loss:0.0011969504494762702\n",
      "train loss:0.0001460434200217595\n",
      "train loss:0.0006923369632819554\n",
      "train loss:0.001016311586247985\n",
      "train loss:3.531906478361535e-05\n",
      "train loss:0.0011895067473666505\n",
      "train loss:0.00105250045813605\n",
      "train loss:0.0005906888528948213\n",
      "train loss:0.0007317299807481424\n",
      "train loss:3.766480337914346e-05\n",
      "train loss:9.632183963942288e-05\n",
      "train loss:0.002078335619541686\n",
      "train loss:0.0021699747948050307\n",
      "train loss:0.0003645307545305208\n",
      "train loss:0.0002776295095789525\n",
      "train loss:0.0009443053427550594\n",
      "train loss:0.0010564627008849163\n",
      "train loss:0.03771430429101434\n",
      "train loss:0.00021405454863689883\n",
      "train loss:0.0006252989827272428\n",
      "train loss:0.0019806030888808\n",
      "train loss:0.0010564374217817956\n",
      "train loss:0.000996023822308173\n",
      "train loss:0.00019649199757760302\n",
      "train loss:0.00037461498925751624\n",
      "train loss:0.004620018545356794\n",
      "train loss:0.0003209786937973175\n",
      "train loss:0.0008825951151097474\n",
      "train loss:0.0010429071650465951\n",
      "train loss:0.000707557385402357\n",
      "train loss:0.002877030195097037\n",
      "train loss:0.00040740197006452816\n",
      "train loss:0.0012552971499630438\n",
      "train loss:0.0002456846531732393\n",
      "train loss:0.0019767192339168243\n",
      "train loss:0.0003208445573045299\n",
      "train loss:0.0005371508342101075\n",
      "train loss:0.0013414999295622667\n",
      "train loss:0.00018645500412692317\n",
      "train loss:0.005522885952707748\n",
      "train loss:0.00020877448360473544\n",
      "train loss:0.0001415852450719807\n",
      "train loss:0.0012878877374323547\n",
      "train loss:0.001528267540799066\n",
      "train loss:0.0040814293943148856\n",
      "train loss:0.005459530376461157\n",
      "train loss:0.0010897662856220202\n",
      "train loss:2.6170182755135808e-05\n",
      "train loss:0.002409157122282893\n",
      "train loss:0.0001864074127174346\n",
      "train loss:0.003462739811621317\n",
      "train loss:0.00029599561578140077\n",
      "train loss:0.005642950598884037\n",
      "train loss:0.0005069561195109959\n",
      "train loss:0.00010387994239820956\n",
      "train loss:0.0006479573977194776\n",
      "train loss:0.00025828119535691816\n",
      "train loss:0.008490032187727306\n",
      "train loss:0.000783059323716732\n",
      "train loss:0.0024287243154689337\n",
      "train loss:0.00044469893500012956\n",
      "train loss:0.002198546401236505\n",
      "train loss:0.0031947925380410623\n",
      "train loss:0.0021562694810186474\n",
      "train loss:0.001421297217542013\n",
      "train loss:0.0036870944538005875\n",
      "train loss:0.004951693827408083\n",
      "train loss:0.0004655594922480569\n",
      "train loss:0.00011637178919826886\n",
      "train loss:0.0019173119146407667\n",
      "train loss:0.001005245323675911\n",
      "train loss:5.757602353003695e-05\n",
      "train loss:0.002245566090849989\n",
      "train loss:0.0014844010149428846\n",
      "train loss:0.0017719364789423014\n",
      "train loss:0.002695439188045828\n",
      "train loss:0.00014709184111365433\n",
      "train loss:0.0009838232640520138\n",
      "train loss:0.00020976021378100066\n",
      "train loss:0.000612543663847311\n",
      "train loss:0.0010348916115328335\n",
      "train loss:0.059394901615615385\n",
      "train loss:0.0014219489830903597\n",
      "train loss:0.01086116578156948\n",
      "train loss:0.009522596707799395\n",
      "train loss:0.0005768171863774789\n",
      "train loss:0.0006820934062286467\n",
      "train loss:0.0009458099981286659\n",
      "train loss:0.0004288518660885552\n",
      "train loss:0.0018578634171513475\n",
      "train loss:0.0024866336032794687\n",
      "train loss:0.00013577099809322597\n",
      "train loss:0.0003723127468321083\n",
      "train loss:0.00024858655165472545\n",
      "train loss:0.001151132935118821\n",
      "train loss:0.02664681576420577\n",
      "train loss:0.006116667115544745\n",
      "train loss:0.0014504669725666163\n",
      "train loss:0.0004989692830213673\n",
      "train loss:0.0011722007434568434\n",
      "train loss:0.0008108649184328411\n",
      "train loss:0.0010205259568013855\n",
      "train loss:0.0011203277959826831\n",
      "train loss:0.0025869144878389373\n",
      "train loss:2.833891873925161e-05\n",
      "train loss:0.00039213657464413297\n",
      "train loss:0.0030859594642691935\n",
      "train loss:0.003446627139617773\n",
      "train loss:0.002991932907045745\n",
      "train loss:0.0003303756107239943\n",
      "train loss:0.00038830352988870615\n",
      "train loss:0.00038368991204933194\n",
      "train loss:0.0011350450788310568\n",
      "train loss:0.0007542043274146792\n",
      "train loss:0.00030098105874981065\n",
      "train loss:0.004643632860836191\n",
      "train loss:0.0006635869857277686\n",
      "train loss:0.00024920107025146285\n",
      "train loss:0.0035480212766655517\n",
      "train loss:0.0005796225103702734\n",
      "train loss:0.0005253327653277613\n",
      "train loss:0.0004986588362695228\n",
      "train loss:0.015111999347168921\n",
      "train loss:0.005017370091198023\n",
      "train loss:0.0025942154188778096\n",
      "train loss:0.0026057946447545694\n",
      "train loss:0.0005673129578352404\n",
      "train loss:0.0009995506036458602\n",
      "train loss:0.000511165353982793\n",
      "train loss:0.00012327199695732143\n",
      "train loss:0.0002271010408525433\n",
      "train loss:0.0014905780399440008\n",
      "train loss:0.0017550013992598365\n",
      "train loss:0.0005509639862554123\n",
      "train loss:0.005456761221640537\n",
      "train loss:0.004863045120073575\n",
      "train loss:0.0007837604260586962\n",
      "train loss:0.00022499055306110418\n",
      "train loss:0.004059091914525697\n",
      "train loss:0.0005031876417462428\n",
      "train loss:0.0008398474640500982\n",
      "train loss:0.0005706814410423617\n",
      "train loss:0.00162689904102883\n",
      "train loss:0.002308251150062816\n",
      "train loss:0.004213083548954112\n",
      "train loss:0.001287835079880867\n",
      "train loss:0.0007301673727369798\n",
      "train loss:0.0008493341572249248\n",
      "train loss:0.0029316595667952627\n",
      "train loss:0.0011469938579132134\n",
      "train loss:0.0005266590224822252\n",
      "train loss:0.00012962788084227737\n",
      "train loss:0.00331491172213215\n",
      "train loss:2.183966904524421e-05\n",
      "train loss:0.0003873488054861434\n",
      "train loss:0.0024279260100128776\n",
      "train loss:0.003475817987044847\n",
      "train loss:0.00012679192812039205\n",
      "train loss:0.000913227959379035\n",
      "train loss:0.00013773039664949883\n",
      "train loss:0.004965034975611309\n",
      "train loss:0.0009817781120926073\n",
      "train loss:6.727223855298255e-05\n",
      "train loss:0.000717360256373856\n",
      "train loss:0.00017814889283143865\n",
      "train loss:0.002725147066322108\n",
      "train loss:0.0019892325049389965\n",
      "train loss:0.00047129153402821535\n",
      "train loss:0.006682677762638477\n",
      "train loss:0.002374132056147754\n",
      "train loss:0.002609534547642634\n",
      "train loss:0.00034972435953411487\n",
      "train loss:0.0035894753756729137\n",
      "train loss:0.0037745877718523683\n",
      "train loss:0.0007816344399840228\n",
      "train loss:0.001845091704640486\n",
      "train loss:0.021393623460485945\n",
      "train loss:0.0009915012110362565\n",
      "train loss:0.0010409108630636988\n",
      "train loss:0.0010135261127180329\n",
      "train loss:0.0002481267114003959\n",
      "train loss:0.003048932225104371\n",
      "train loss:0.000682459311595076\n",
      "train loss:0.0011656073622904142\n",
      "train loss:0.0025348948113556075\n",
      "train loss:0.001906657842346556\n",
      "train loss:0.0005520679896107297\n",
      "train loss:0.0008799562257861381\n",
      "train loss:0.001590100955754798\n",
      "train loss:0.06497055449392507\n",
      "train loss:0.0020516797194064453\n",
      "train loss:0.0028987530328666196\n",
      "train loss:0.0002965800591642614\n",
      "train loss:0.00023564322565669765\n",
      "train loss:0.0025710554590062775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012531057244298872\n",
      "train loss:0.01551794870422123\n",
      "train loss:0.0001135209615758701\n",
      "train loss:0.0016466492843405511\n",
      "train loss:0.016912482393436137\n",
      "train loss:0.001341174537506428\n",
      "train loss:0.002365365115337918\n",
      "train loss:0.05008832452405674\n",
      "train loss:0.001598882751998692\n",
      "train loss:0.0003009935079591226\n",
      "train loss:0.00044221701216542265\n",
      "train loss:0.0006371036861273245\n",
      "train loss:0.00207755615294691\n",
      "train loss:0.00014194031495127666\n",
      "train loss:0.0012138199042460555\n",
      "train loss:0.0007777815563460973\n",
      "train loss:0.0032808216753613816\n",
      "train loss:0.0042630969872759885\n",
      "train loss:0.0031496946181777514\n",
      "train loss:0.01852211666334727\n",
      "train loss:0.0006514834069148951\n",
      "train loss:0.0026181966571317723\n",
      "train loss:0.001094434381718903\n",
      "train loss:0.0008600008610337132\n",
      "train loss:0.00358385911270896\n",
      "train loss:0.005062246803869594\n",
      "train loss:0.0009806659375764042\n",
      "train loss:0.0009197177959412033\n",
      "train loss:0.0037586450957308713\n",
      "train loss:0.0008813828498064169\n",
      "train loss:0.0006538841475192199\n",
      "train loss:0.003958961282399126\n",
      "train loss:0.002872377947760499\n",
      "train loss:0.0010161517028890344\n",
      "train loss:0.0008879355289353211\n",
      "train loss:0.0020773057941758837\n",
      "train loss:0.0023392982743306533\n",
      "train loss:0.0010622337458165603\n",
      "train loss:7.02010896469236e-05\n",
      "train loss:0.001660292148970395\n",
      "train loss:0.00025293817739049305\n",
      "train loss:0.000413708224796182\n",
      "train loss:0.00587675475685211\n",
      "train loss:0.0017271642993421598\n",
      "train loss:0.0062155166521605295\n",
      "train loss:0.00201031933795842\n",
      "train loss:0.0005303068439012263\n",
      "train loss:0.0012353237467849594\n",
      "train loss:0.0002604386040234364\n",
      "train loss:0.0015651754266201678\n",
      "train loss:0.0022669553940047947\n",
      "train loss:8.761941823218802e-05\n",
      "train loss:9.988966784830887e-05\n",
      "train loss:0.019732601715047756\n",
      "train loss:0.0005504812203447988\n",
      "train loss:7.51393626310161e-05\n",
      "train loss:0.002381752098476152\n",
      "train loss:0.0010423513332557472\n",
      "train loss:0.00010147693732476475\n",
      "train loss:0.0011044111417603504\n",
      "train loss:0.0015824797585785547\n",
      "train loss:0.0007873437795013048\n",
      "train loss:0.0062509455203122654\n",
      "train loss:0.0064770059444292935\n",
      "train loss:0.00030255788267587614\n",
      "train loss:0.0004683687534627458\n",
      "train loss:0.00016420944447591068\n",
      "train loss:0.0066005394421442265\n",
      "train loss:0.0010109621989545512\n",
      "train loss:0.007214635367948566\n",
      "train loss:0.00013487624429205027\n",
      "train loss:0.008882187227121\n",
      "train loss:0.0008342412803108444\n",
      "train loss:0.00021253954032873331\n",
      "train loss:0.003179097402860297\n",
      "train loss:0.0001378851936102384\n",
      "train loss:0.0008027888943521267\n",
      "train loss:0.001480881094157483\n",
      "train loss:0.00123932694342673\n",
      "train loss:0.0016971620520349064\n",
      "train loss:0.000916427483434934\n",
      "train loss:0.00289537102947635\n",
      "train loss:0.0018186070158169685\n",
      "train loss:0.0019378254708600053\n",
      "train loss:0.004409339730800446\n",
      "train loss:4.6889539375483084e-05\n",
      "train loss:0.0013899819636229338\n",
      "train loss:0.0030457262084370037\n",
      "train loss:0.0005134053463673791\n",
      "train loss:0.03902584113370937\n",
      "train loss:0.00019952003034211116\n",
      "train loss:0.0009241064561317413\n",
      "train loss:0.0014351276547958528\n",
      "train loss:7.840316138193652e-05\n",
      "train loss:0.0005879774883313739\n",
      "train loss:0.0018248700683338966\n",
      "train loss:0.003432031395591296\n",
      "train loss:6.625749416348517e-05\n",
      "train loss:0.0018716608274157163\n",
      "train loss:0.0017691952425916593\n",
      "train loss:0.0008624424580459933\n",
      "train loss:0.0003400058468106205\n",
      "train loss:0.003091269565685512\n",
      "train loss:0.0001292648054445942\n",
      "train loss:0.0004138113660474002\n",
      "train loss:0.0015705790076239814\n",
      "train loss:0.003346430556021694\n",
      "train loss:0.0003162404061775875\n",
      "train loss:0.0005791330527234731\n",
      "train loss:0.000699235798679253\n",
      "train loss:0.001116750016284495\n",
      "train loss:0.0026959347869386693\n",
      "train loss:0.0009238618154489719\n",
      "train loss:0.005908932670935975\n",
      "train loss:0.002766903620928671\n",
      "train loss:0.0008130476689078856\n",
      "train loss:0.0014704633639369882\n",
      "train loss:2.6472828510716576e-05\n",
      "train loss:0.0024740633991227243\n",
      "train loss:0.0017633777164110587\n",
      "train loss:0.0005524821503015955\n",
      "train loss:0.0002990769171667056\n",
      "train loss:0.00032556736932286344\n",
      "train loss:0.0030709558203547826\n",
      "train loss:0.010038627829819022\n",
      "train loss:0.0020215000992811634\n",
      "train loss:0.00013358467810158537\n",
      "train loss:0.0006929554025617995\n",
      "train loss:0.0009556773136006974\n",
      "train loss:0.0008868249947227257\n",
      "train loss:0.003293629869197744\n",
      "train loss:0.00026992859584647465\n",
      "train loss:1.1345682107640152e-05\n",
      "train loss:0.01007319574358\n",
      "train loss:1.9060371326575747e-05\n",
      "train loss:0.0019870370774550256\n",
      "train loss:0.005164264729429312\n",
      "train loss:7.112459803162381e-05\n",
      "train loss:0.0025008690907637964\n",
      "=== epoch:20, train acc:1.0, test acc:0.99 ===\n",
      "train loss:0.0004934526299836462\n",
      "train loss:0.0003008701957109607\n",
      "train loss:0.0004334717427000298\n",
      "train loss:0.0012159596608522947\n",
      "train loss:0.0005597050656287691\n",
      "train loss:0.0008294867923916488\n",
      "train loss:1.1437875132168703e-05\n",
      "train loss:0.0003072168122688401\n",
      "train loss:0.0017818933459098874\n",
      "train loss:0.00019571772062139216\n",
      "train loss:0.00043071859042079674\n",
      "train loss:0.0016204223532337947\n",
      "train loss:4.527349287798064e-05\n",
      "train loss:0.0005904895657716726\n",
      "train loss:0.0001563849811307737\n",
      "train loss:0.0001518045426907049\n",
      "train loss:0.0034140817276116075\n",
      "train loss:0.0012734675641338422\n",
      "train loss:0.0008899343362913506\n",
      "train loss:0.0006596005200089745\n",
      "train loss:0.0005736945063274409\n",
      "train loss:0.001424929138852774\n",
      "train loss:0.0013125540103121655\n",
      "train loss:0.0005212619566010212\n",
      "train loss:2.333289880916896e-05\n",
      "train loss:0.0013203986844397778\n",
      "train loss:0.00405957756426566\n",
      "train loss:0.0004171375635746806\n",
      "train loss:6.123920028959466e-05\n",
      "train loss:0.0001512599686632047\n",
      "train loss:3.4803003419364806e-05\n",
      "train loss:0.00019642757734699963\n",
      "train loss:0.001001299577629474\n",
      "train loss:0.0015807359767690443\n",
      "train loss:0.0010960037068413185\n",
      "train loss:0.00012574072995900608\n",
      "train loss:0.001999353647984101\n",
      "train loss:0.004686750881139367\n",
      "train loss:0.0009773462619752226\n",
      "train loss:0.00014902612340267316\n",
      "train loss:0.0024350491786707435\n",
      "train loss:0.004711259715522586\n",
      "train loss:0.003537803304461599\n",
      "train loss:0.0009168716136841572\n",
      "train loss:0.002654201302804192\n",
      "train loss:0.0007693054987378315\n",
      "train loss:0.0002980260326505104\n",
      "train loss:0.0004452328577957761\n",
      "train loss:0.0028632604803747476\n",
      "train loss:0.0007193808978037876\n",
      "train loss:0.0005437732570469185\n",
      "train loss:0.0006381860685545587\n",
      "train loss:0.0005277973129001704\n",
      "train loss:0.008073452992874802\n",
      "train loss:0.003008666369402652\n",
      "train loss:0.0001971826016191205\n",
      "train loss:0.0011645686651522585\n",
      "train loss:0.0032781888356534423\n",
      "train loss:0.001534483809611545\n",
      "train loss:0.0005266909550911969\n",
      "train loss:0.0008481272043993456\n",
      "train loss:0.0036886306748396924\n",
      "train loss:0.0002622004407597174\n",
      "train loss:0.0012947323128732501\n",
      "train loss:0.0008022674676249212\n",
      "train loss:0.0008544812692664575\n",
      "train loss:0.0003693870866550817\n",
      "train loss:0.0028423163136227147\n",
      "train loss:0.006924694632847011\n",
      "train loss:7.331233746496453e-05\n",
      "train loss:0.00334337621038753\n",
      "train loss:0.001557651907984217\n",
      "train loss:0.0014408586092993613\n",
      "train loss:0.01555054249025567\n",
      "train loss:0.0023574026921442458\n",
      "train loss:0.0003733541994520951\n",
      "train loss:0.0011401499341956792\n",
      "train loss:0.0001355455449930313\n",
      "train loss:0.0011119354003528905\n",
      "train loss:2.8547954780326405e-05\n",
      "train loss:0.010162661903147513\n",
      "train loss:0.004279554900336161\n",
      "train loss:0.0021232736673696736\n",
      "train loss:0.0009613735699079305\n",
      "train loss:0.0020272783001593526\n",
      "train loss:0.0011235472342314983\n",
      "train loss:0.0002633012149792335\n",
      "train loss:0.009804387686770314\n",
      "train loss:0.0011620764412794934\n",
      "train loss:9.34659155171236e-05\n",
      "train loss:0.00015193001378463692\n",
      "train loss:0.0002190319889936245\n",
      "train loss:0.0017503752563310185\n",
      "train loss:0.0016819828254563177\n",
      "train loss:0.0018933880686780602\n",
      "train loss:0.0005071472783728548\n",
      "train loss:0.0012553190290353938\n",
      "train loss:0.006172732974025021\n",
      "train loss:0.004189818470768486\n",
      "train loss:0.0011689723095039534\n",
      "train loss:0.0007959381736033449\n",
      "train loss:0.0010881231581199825\n",
      "train loss:0.000787753769660074\n",
      "train loss:0.0011891010168613811\n",
      "train loss:0.009181008806347615\n",
      "train loss:0.0003093309354434078\n",
      "train loss:0.0001085099642685542\n",
      "train loss:0.002111031345448698\n",
      "train loss:0.004314118624507615\n",
      "train loss:0.003343920769006398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006775644253216148\n",
      "train loss:0.0007726041047067523\n",
      "train loss:0.00020553643922689962\n",
      "train loss:0.0002555789367126244\n",
      "train loss:0.0005563862787558138\n",
      "train loss:0.000325476848759699\n",
      "train loss:0.00019102245296354094\n",
      "train loss:0.0010186403281235482\n",
      "train loss:5.401457162297259e-05\n",
      "train loss:0.0021562819992509102\n",
      "train loss:0.0012407582248641499\n",
      "train loss:4.0622246147446886e-05\n",
      "train loss:6.243228697078764e-05\n",
      "train loss:0.0008960560053975814\n",
      "train loss:0.0003877874534136376\n",
      "train loss:0.004195522343927378\n",
      "train loss:0.0011786271274058866\n",
      "train loss:0.0024844535170257935\n",
      "train loss:0.002748714826629003\n",
      "train loss:0.0008285729267077033\n",
      "train loss:0.0012185680289737808\n",
      "train loss:0.0012840958163086694\n",
      "train loss:0.00021878800327036183\n",
      "train loss:0.0012587567701520274\n",
      "train loss:0.0021211488084917516\n",
      "train loss:0.001277623953567044\n",
      "train loss:0.0006462656101579127\n",
      "train loss:0.0018293114411744235\n",
      "train loss:0.000476380923711681\n",
      "train loss:9.077389893200985e-05\n",
      "train loss:0.0024709874902337408\n",
      "train loss:0.002828475625087947\n",
      "train loss:0.0006141313704023944\n",
      "train loss:0.0015808955605873995\n",
      "train loss:0.00518931346745425\n",
      "train loss:0.015393088988380842\n",
      "train loss:0.0005460101514428572\n",
      "train loss:0.0010350881020107737\n",
      "train loss:0.0006085863903241819\n",
      "train loss:0.0010926111403058816\n",
      "train loss:0.000327562800841505\n",
      "train loss:0.0001495299042767278\n",
      "train loss:0.0004144112791151139\n",
      "train loss:6.907635604744501e-05\n",
      "train loss:0.0011075720346766433\n",
      "train loss:4.5538327011432686e-05\n",
      "train loss:0.0007227390372203791\n",
      "train loss:0.0035047569810146184\n",
      "train loss:7.395699702620682e-05\n",
      "train loss:0.004164670787251272\n",
      "train loss:0.0019473039971428482\n",
      "train loss:0.0011368416520989287\n",
      "train loss:0.00037817632707592925\n",
      "train loss:0.0003225286236728648\n",
      "train loss:0.0005638349888894823\n",
      "train loss:0.0015023242157974777\n",
      "train loss:3.510032726356112e-05\n",
      "train loss:0.00016845345375388323\n",
      "train loss:0.005353974472328902\n",
      "train loss:0.0019047364005084126\n",
      "train loss:0.0010200478773325595\n",
      "train loss:0.004743142761853857\n",
      "train loss:0.0014218246034610647\n",
      "train loss:0.0010327553065298202\n",
      "train loss:0.00010809242573440167\n",
      "train loss:0.0005651825735257596\n",
      "train loss:0.002041094971692892\n",
      "train loss:0.00021249090904632692\n",
      "train loss:0.0012702846945116947\n",
      "train loss:0.001177552480354655\n",
      "train loss:0.0003900021127657989\n",
      "train loss:0.001276274874986741\n",
      "train loss:5.8770917022006475e-05\n",
      "train loss:0.0011656309218480692\n",
      "train loss:0.0010642898724635204\n",
      "train loss:0.0009235537904291237\n",
      "train loss:0.0004251879163509299\n",
      "train loss:0.0003605390775852611\n",
      "train loss:0.00177880020680274\n",
      "train loss:0.0029395981551773504\n",
      "train loss:0.00015485089494228385\n",
      "train loss:0.00025214570600107315\n",
      "train loss:0.006005864845629668\n",
      "train loss:0.0005994788064163891\n",
      "train loss:0.0015700257332346534\n",
      "train loss:0.002091622821872066\n",
      "train loss:0.0003476249553708688\n",
      "train loss:0.00021877031264687128\n",
      "train loss:0.000792704561486091\n",
      "train loss:0.00018416176399306227\n",
      "train loss:3.336395491421955e-05\n",
      "train loss:0.0011534387413593711\n",
      "train loss:0.00015683435610476046\n",
      "train loss:0.0003663635623079316\n",
      "train loss:0.0010856669864013377\n",
      "train loss:0.0005194411976156397\n",
      "train loss:0.00149551319332824\n",
      "train loss:0.001267677527276979\n",
      "train loss:0.015658192006174024\n",
      "train loss:0.0021759791763450945\n",
      "train loss:0.0032685219787752635\n",
      "train loss:0.0010225997297723247\n",
      "train loss:0.0006426585608632928\n",
      "train loss:0.0012968259123777336\n",
      "train loss:0.0003263264529548434\n",
      "train loss:0.0021287774757095734\n",
      "train loss:0.0009506857887772506\n",
      "train loss:7.665632717065891e-05\n",
      "train loss:6.883328490028849e-06\n",
      "train loss:0.0009813495206868717\n",
      "train loss:3.106331943463752e-05\n",
      "train loss:0.0008871648448293074\n",
      "train loss:0.001286705033043251\n",
      "train loss:0.0012074237338645093\n",
      "train loss:0.0034367969269576215\n",
      "train loss:0.0005949176856850884\n",
      "train loss:0.0011274037512120998\n",
      "train loss:0.0007301162314550215\n",
      "train loss:0.0013861241326415918\n",
      "train loss:0.0005994164396710568\n",
      "train loss:5.0004946665831504e-05\n",
      "train loss:0.003639351919253849\n",
      "train loss:0.0012868647233936093\n",
      "train loss:0.00013184684423447727\n",
      "train loss:0.0004094908930012589\n",
      "train loss:0.0002846365183308372\n",
      "train loss:0.0014096825744069153\n",
      "train loss:0.0018426359537116674\n",
      "train loss:5.638128448356502e-05\n",
      "train loss:0.0012831526199969813\n",
      "train loss:0.00014807661495334904\n",
      "train loss:0.0016774552204158633\n",
      "train loss:0.0010823213455105607\n",
      "train loss:0.000729242983323338\n",
      "train loss:0.001119331094750581\n",
      "train loss:6.550074199461048e-05\n",
      "train loss:0.0022551784755277275\n",
      "train loss:0.00016044222623898808\n",
      "train loss:1.9632772654531872e-05\n",
      "train loss:0.0005568263619095339\n",
      "train loss:0.003725914214445457\n",
      "train loss:0.0027760406726873334\n",
      "train loss:1.647612884807572e-05\n",
      "train loss:0.00656429075982897\n",
      "train loss:0.00033730769915624555\n",
      "train loss:0.0007915842471069843\n",
      "train loss:0.0002126551009066471\n",
      "train loss:0.0019216826069364983\n",
      "train loss:0.00040681598710984486\n",
      "train loss:0.00010327328770162233\n",
      "train loss:0.0019631189065815392\n",
      "train loss:0.00027689681739532016\n",
      "train loss:6.425686679713678e-05\n",
      "train loss:0.0004712142657652154\n",
      "train loss:0.00010385942624012033\n",
      "train loss:0.0016586668765751092\n",
      "train loss:6.0141821895329185e-05\n",
      "train loss:0.001764475780755557\n",
      "train loss:0.00251244386923347\n",
      "train loss:0.0007045689001237295\n",
      "train loss:1.642502054090039e-05\n",
      "train loss:0.0009510329617944363\n",
      "train loss:0.0030243808731481\n",
      "train loss:0.00020480280746017733\n",
      "train loss:0.0003134332332334979\n",
      "train loss:0.0029263559290093554\n",
      "train loss:0.0005507580232531512\n",
      "train loss:0.0004641074554459439\n",
      "train loss:0.000522896141612128\n",
      "train loss:0.0014989430864658629\n",
      "train loss:0.0005790716524355062\n",
      "train loss:0.001342528615633407\n",
      "train loss:0.0013905521733328574\n",
      "train loss:0.02354077926150263\n",
      "train loss:3.3760239083208054e-05\n",
      "train loss:0.00018941072413308305\n",
      "train loss:0.00014867816890428844\n",
      "train loss:0.0003717211377771239\n",
      "train loss:0.001700144712916435\n",
      "train loss:0.00012208207380456638\n",
      "train loss:0.007120462473961765\n",
      "train loss:0.0002496069810442992\n",
      "train loss:0.00015288044893522188\n",
      "train loss:0.0011276586306417946\n",
      "train loss:0.001427300841335704\n",
      "train loss:0.0007780852963349044\n",
      "train loss:0.00042978158636151036\n",
      "train loss:0.0015103838519446664\n",
      "train loss:0.0009277684139611013\n",
      "train loss:0.0010511082319189507\n",
      "train loss:0.00033416601619411403\n",
      "train loss:0.0018242531606499793\n",
      "train loss:0.00010789547409149213\n",
      "train loss:0.0011322827053655686\n",
      "train loss:0.0012353509267552132\n",
      "train loss:0.0001339988157718436\n",
      "train loss:0.007302432516868186\n",
      "train loss:0.0005037850517988452\n",
      "train loss:0.0005382943692813235\n",
      "train loss:0.00024587168312777927\n",
      "train loss:0.004360235474220931\n",
      "train loss:0.0018542942376009717\n",
      "train loss:0.0005407233545489054\n",
      "train loss:0.0004460771316280406\n",
      "train loss:0.001570446979343074\n",
      "train loss:7.429876078191073e-05\n",
      "train loss:0.0017868619898960061\n",
      "train loss:0.0003242381191908586\n",
      "train loss:0.0017294663773552957\n",
      "train loss:0.000425607804359321\n",
      "train loss:0.008522586618359217\n",
      "train loss:2.757433237951862e-05\n",
      "train loss:0.0002573363813234117\n",
      "train loss:0.0010522330260692772\n",
      "train loss:0.00010989289152290712\n",
      "train loss:0.0011352894583221162\n",
      "train loss:0.005402873868507685\n",
      "train loss:6.438780025686703e-05\n",
      "train loss:0.0001532431735171522\n",
      "train loss:0.00043232411140848713\n",
      "train loss:0.0021207018963795062\n",
      "train loss:0.0008500772943925801\n",
      "train loss:0.002166278864247319\n",
      "train loss:0.0001331466322405645\n",
      "train loss:0.0019647482339378063\n",
      "train loss:0.0035845188999451567\n",
      "train loss:0.00014153610271826604\n",
      "train loss:9.438359565517343e-05\n",
      "train loss:0.00041278138964705044\n",
      "train loss:0.000806968259749108\n",
      "train loss:0.0007145704090192298\n",
      "train loss:0.0008277900650858984\n",
      "train loss:0.013262811901509712\n",
      "train loss:0.0005937283229130627\n",
      "train loss:0.0012682817248909142\n",
      "train loss:0.0003574891349763281\n",
      "train loss:0.0008723733622110115\n",
      "train loss:0.010545162048840628\n",
      "train loss:0.00012782015321288255\n",
      "train loss:0.004651951318138115\n",
      "train loss:4.3925025782710145e-05\n",
      "train loss:0.0019062497720483743\n",
      "train loss:0.0034905819530687216\n",
      "train loss:0.0011375350564487648\n",
      "train loss:0.0007241919828064628\n",
      "train loss:0.0017222322200239346\n",
      "train loss:0.0017618136075175474\n",
      "train loss:0.0016353022049379606\n",
      "train loss:0.007816144620588314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011233962253088862\n",
      "train loss:0.0005444992231009051\n",
      "train loss:0.00013204271948167483\n",
      "train loss:0.001041748900444546\n",
      "train loss:0.0026932913919456548\n",
      "train loss:0.00043521111525529003\n",
      "train loss:0.0008558220683540381\n",
      "train loss:0.00015003308492584467\n",
      "train loss:0.0010359617972275773\n",
      "train loss:0.0008837685248834965\n",
      "train loss:0.0053819944750652295\n",
      "train loss:0.006600295180596862\n",
      "train loss:0.00153788582692756\n",
      "train loss:0.0020609839987759367\n",
      "train loss:0.006103264101575019\n",
      "train loss:0.00027168162062887145\n",
      "train loss:0.000806161081774107\n",
      "train loss:0.009110687273394778\n",
      "train loss:0.0002744882169228853\n",
      "train loss:0.00011467597256678757\n",
      "train loss:0.00017852148812543063\n",
      "train loss:0.0016087446389574241\n",
      "train loss:0.006163850078734172\n",
      "train loss:0.007194918022175474\n",
      "train loss:0.0018777535348620345\n",
      "train loss:9.644422922555728e-05\n",
      "train loss:0.0018456525053435215\n",
      "train loss:0.0008045846910878065\n",
      "train loss:0.0016886707229182988\n",
      "train loss:0.00040674909992892053\n",
      "train loss:0.0003977557579727486\n",
      "train loss:0.012709573768069004\n",
      "train loss:0.001426554470619163\n",
      "train loss:0.00010956763338104499\n",
      "train loss:0.001888148959394678\n",
      "train loss:0.0034621631903273037\n",
      "train loss:0.0019290282398799618\n",
      "train loss:0.0008428097736356887\n",
      "train loss:0.002376078306378543\n",
      "train loss:0.0014591971977708717\n",
      "train loss:0.0002835985916194967\n",
      "train loss:0.008847424120170375\n",
      "train loss:0.0007080034406017157\n",
      "train loss:0.0009859803403579925\n",
      "train loss:0.0005499095032804671\n",
      "train loss:0.007342638797382974\n",
      "train loss:0.0003890473742945233\n",
      "train loss:0.0005820145355588814\n",
      "train loss:0.0007024534642156491\n",
      "train loss:0.0002648485807571175\n",
      "train loss:0.0002410510948176083\n",
      "train loss:0.0009283283967051675\n",
      "train loss:0.0007394278196006661\n",
      "train loss:0.0034849716461275958\n",
      "train loss:0.0013637271687722023\n",
      "train loss:0.0009715164043526494\n",
      "train loss:4.101978410849585e-05\n",
      "train loss:0.00011308660312415544\n",
      "train loss:0.00326076991258385\n",
      "train loss:0.00015362068033764422\n",
      "train loss:0.00035132878122779343\n",
      "train loss:0.00011988849075141127\n",
      "train loss:0.0006722632516187006\n",
      "train loss:0.0004313733288929684\n",
      "train loss:0.0004921505878762937\n",
      "train loss:0.0019578415478041645\n",
      "train loss:0.0019196472409659334\n",
      "train loss:0.0012039997533083591\n",
      "train loss:0.00017461530150353563\n",
      "train loss:2.6667924938458253e-05\n",
      "train loss:0.025475004288192955\n",
      "train loss:0.0011116889139703957\n",
      "train loss:0.0009395411664025926\n",
      "train loss:0.0008774861754895274\n",
      "train loss:0.00010963618222775181\n",
      "train loss:0.0014816774628674872\n",
      "train loss:0.0019730889138391615\n",
      "train loss:0.001929073883680495\n",
      "train loss:0.00011879805428898739\n",
      "train loss:0.00020495939977265668\n",
      "train loss:0.00036436782643710196\n",
      "train loss:0.00042669182244438233\n",
      "train loss:0.001223690822756058\n",
      "train loss:0.002413097654263072\n",
      "train loss:0.0018894393508884935\n",
      "train loss:0.00021372942523984696\n",
      "train loss:0.0038065291332673085\n",
      "train loss:0.0003652826755647756\n",
      "train loss:0.001165524571166929\n",
      "train loss:0.002501293466462943\n",
      "train loss:0.0003808913442039139\n",
      "train loss:0.0007150375332624126\n",
      "train loss:0.002006886187377859\n",
      "train loss:0.0031768020925094565\n",
      "train loss:0.00025532403268533813\n",
      "train loss:0.0030245745815326935\n",
      "train loss:0.0001846270943013363\n",
      "train loss:7.507735335868307e-05\n",
      "train loss:0.00030923682450104936\n",
      "train loss:0.00026048119869383137\n",
      "train loss:1.719768921035333e-05\n",
      "train loss:0.0003077914697781727\n",
      "train loss:0.0011662126425514684\n",
      "train loss:0.0004831860235633188\n",
      "train loss:0.0009936418235268973\n",
      "train loss:0.0037439148129940177\n",
      "train loss:0.00015424261272047575\n",
      "train loss:0.00010657663961430024\n",
      "train loss:0.0002439328410599234\n",
      "train loss:0.001812823531813528\n",
      "train loss:0.0008524072155174752\n",
      "train loss:0.00025366521404865606\n",
      "train loss:0.0014129138734353258\n",
      "train loss:0.003181163476029569\n",
      "train loss:0.00024338030243513858\n",
      "train loss:0.0022233535784353248\n",
      "train loss:0.0028436310013895995\n",
      "train loss:0.007957912704481939\n",
      "train loss:0.002424703073791991\n",
      "train loss:0.0005160258128813863\n",
      "train loss:0.0003316137535170181\n",
      "train loss:0.00028039950092882904\n",
      "train loss:6.947218440573511e-05\n",
      "train loss:0.00038839400781328975\n",
      "train loss:0.0038256387600483135\n",
      "train loss:0.00020605119382472863\n",
      "train loss:0.0036807038093344072\n",
      "train loss:0.006996905190670217\n",
      "train loss:0.0017554312923250609\n",
      "train loss:0.0015569760039011173\n",
      "train loss:0.0019856031867716874\n",
      "train loss:0.0001801590500028084\n",
      "train loss:0.0010078517981667895\n",
      "train loss:0.0013776975274367163\n",
      "train loss:0.0023781517197357764\n",
      "train loss:0.00011953130097862365\n",
      "train loss:0.005044988346759437\n",
      "train loss:0.00045228841665930224\n",
      "train loss:1.532388800335153e-05\n",
      "train loss:0.0006625155726522077\n",
      "train loss:0.0023422586694267556\n",
      "train loss:0.0004867288683985447\n",
      "train loss:0.0027698283018869757\n",
      "train loss:6.714058172281096e-05\n",
      "train loss:0.00016575515376459273\n",
      "train loss:0.0007049618521451806\n",
      "train loss:0.0005594726377888649\n",
      "train loss:0.00011022176450275464\n",
      "train loss:0.005770448670069701\n",
      "train loss:0.0018413781895052304\n",
      "train loss:0.00015848941168877196\n",
      "train loss:0.00022306937432045498\n",
      "train loss:0.0009521107872266728\n",
      "train loss:0.003453509853969654\n",
      "train loss:0.0002775670996775088\n",
      "train loss:0.00042867176354174425\n",
      "train loss:0.0010298531739532238\n",
      "train loss:0.006912767310523862\n",
      "train loss:0.00232651257915718\n",
      "train loss:0.0003997438119357443\n",
      "train loss:0.006995642740091328\n",
      "train loss:0.0002330291026508883\n",
      "train loss:0.0005058656202911495\n",
      "train loss:0.0008713381807611509\n",
      "train loss:0.0005584354959714695\n",
      "train loss:0.0001315936147573595\n",
      "train loss:0.00023960225397696056\n",
      "train loss:0.00012346168766739365\n",
      "train loss:0.00015541848341849734\n",
      "train loss:0.00038042862932214657\n",
      "train loss:0.0008311062928945514\n",
      "train loss:7.123840856940313e-05\n",
      "train loss:0.0017606200121205123\n",
      "train loss:0.00026880965487273623\n",
      "train loss:0.00011564064448521513\n",
      "train loss:5.517647281189863e-05\n",
      "train loss:0.0001311688276773287\n",
      "train loss:0.000917217692575919\n",
      "train loss:0.0004499456336405346\n",
      "train loss:0.003254560004947104\n",
      "train loss:0.00013485139187374893\n",
      "train loss:0.001180434103275637\n",
      "train loss:0.002211060936656373\n",
      "train loss:0.0003766089400690668\n",
      "train loss:1.72646709730095e-05\n",
      "train loss:0.004658229235714385\n",
      "train loss:0.0002280024957175705\n",
      "train loss:0.0003640031434312415\n",
      "train loss:0.0013387938799428077\n",
      "train loss:4.738578882602722e-05\n",
      "train loss:0.0020734319409261236\n",
      "train loss:0.0014975643587537618\n",
      "train loss:8.344287481999094e-05\n",
      "train loss:0.0006099087206891024\n",
      "train loss:3.28690289277559e-05\n",
      "train loss:0.0002645683938586812\n",
      "train loss:0.0008732907393318852\n",
      "train loss:0.0007164381713375623\n",
      "train loss:0.0027005730500140107\n",
      "train loss:0.008710561943943408\n",
      "train loss:0.00013388917493623804\n",
      "train loss:0.0010948866739556363\n",
      "train loss:0.0010784443812412586\n",
      "train loss:0.002127739285393185\n",
      "train loss:0.0023030771084277873\n",
      "train loss:0.0010600286689145574\n",
      "train loss:0.00039246990260448215\n",
      "train loss:9.582366969179091e-05\n",
      "train loss:0.0008057658959517982\n",
      "train loss:0.00019773808242583548\n",
      "train loss:0.001950669594407564\n",
      "train loss:0.001704864975828951\n",
      "train loss:0.00023420004093653986\n",
      "train loss:0.008813375172229253\n",
      "train loss:0.00018536354421478122\n",
      "train loss:0.000354789043594476\n",
      "train loss:3.9297826563953364e-05\n",
      "train loss:0.00011282619652506702\n",
      "train loss:0.0009005567179601742\n",
      "train loss:9.410755660338247e-05\n",
      "train loss:0.0004616558266292143\n",
      "train loss:0.0002130269455501597\n",
      "train loss:0.0015183600939381713\n",
      "train loss:5.665175661179763e-05\n",
      "train loss:0.0007218498692619863\n",
      "train loss:0.0005837833369533886\n",
      "train loss:0.00033009499137783054\n",
      "train loss:0.0004179320271569113\n",
      "train loss:0.00016597754271361083\n",
      "train loss:0.00045538929959351547\n",
      "train loss:0.0013716077368574628\n",
      "train loss:0.0028206296967529564\n",
      "train loss:0.0016055488809689343\n",
      "train loss:0.00133580349971706\n",
      "train loss:0.0008900605429485855\n",
      "train loss:0.0003878322754608901\n",
      "train loss:0.0013993458440454624\n",
      "train loss:0.000225297467204763\n",
      "train loss:0.0003412597003883359\n",
      "train loss:0.0007466657959845266\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9893\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bc7edf1337b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m's'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_acc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "#from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAliklEQVR4nO3de5gcdZ3v8fe3e3ruk8w1dySRxQAqgmRRFnF1vUDQFfBxPerKethLRGEXzzlwgLOr4Lo+B2V1fdhFsqyLl/WuIKBEQRTl7CpCgHAJFxMQmMkkmcllZjL36e7v+aNqkk6ne6bnUtOTqc/refrpql9VdX27pqa+XZff72fujoiIxFei3AGIiEh5KRGIiMScEoGISMwpEYiIxJwSgYhIzCkRiIjEXGSJwMxuMbMuM3uyyHQzsxvMbLuZPW5mr40qFhERKS7KM4KvAOdMMH09cHz42gDcFGEsIiJSRGSJwN3vB/ZNMMt5wNc88ADQaGbLo4pHREQKqyjjulcC7TnjHWHZzvwZzWwDwVkDdXV1p51wwglzEuBC0TM4xq6+YcYyWVLJBMsWVdNYm5qz9fuuJ7Bs+sjyRAW27NULav0OZN3xbPCeded3ewZIZ4+swZ80o6W+kqwfmtcdslk/rCzr4OH7dKzlBSrIHFGeJsk2W42ZYQAGBlg4YOF8ZmHZwe8YxDn+ffGgDMA9LCOIGSj43ePk1fZ80WlP+Mun9Flt9VUsW1w9rTgefvjhPe7eVmhaOROBFSgruMe4+83AzQDr1q3zzZs3RxnXgnL7ozu4+rYnaB07dCBIpZL83btfzfmnrsTdGUlnGR7LMDSWYXA0w9BoMDw0GoyPTxsazZDJOulscIBKZ5yMO5lslkyWw9/dyWSD12effGPR+C485saDn5X18LOzwecWKkuYkUwYyfH3hFGRMBJ5ZbnTvvS7txZd/1+v/beSt2XWnZGxLENj6XAbZRkaTR/cbsNjGcYyR+7CL1R9hDbrPaK82xfz+yP/RH0qSW1lkurwvaYySU2qwHsqSSJR6N9mYv/nwdcXnXblq75/2N9q/HXwbxxu+3Q2SzYbJIWKpJGwYNsevr0TJI3gPXHo/bJH31H0+//knPuprEgEr2QyZzh4r8oZT1UkgoSYJYgnjC+TzSs7uF8Gr1d+c13R9f/2wkeC71L0Ox2+X2Wywf/L6FiG9MgAmcH9+OB+GN4PQz3Y8H4Sw70kR3tJjvSQGu3j97q6im7/F5e8Cq+oxVM1eKoWUjWQqsMqa0hU1mKV9SSraklU1VFRXUdN62rqlxw75X0AwMxeLDatnImgAzgmZ3wV0FmmWOa1sUyW57r72d7Vz9BohtFMltF0ziscH8kZHn99avsFPJ3sheThn9l9+2Je+YObGRrLTPpL08jSwCCLbJAqxqhijErSVDJGpaWptjTViQxVlqbG0lRZmno7NG0ia3v/i5FkHcPJOsaSdYxU1DGSrMOSVSRyDvIVieAfNZt30Eqkh6nO9FGT7qM6c4Dq0QPUZQ5Qmz30PpGPbNtQyp/goLFEFelENelkNZlkDZlUDdmaGryiFiprsVQNVNYF/7yVtVRU19N2/5EHIYA26+V37+nCRg7A+Gs0Z3jkAAzmjQMkKiCRDN4tGQ5PMD6Bz/AFqKiCikpI5r5XQbIy772qwLoqIJHIG0+CJSBhwfCW4t//wkVbYGwIxgZgaAhGB2Fs8FDZWF5ZsjI8WAbbORiuDV6V4Xt+WYEkML7+tpH/PHxdY0MwOlBk/YMw3AtDPTDcA5nR4hvWElDdCDWNE27/Y9kFQ4PQm/OdPVt8gTMvg7f9/YSfOR3lTAR3Apea2beB1wG97n7EZaGj3vXHw0CBXwR1S+CKbUcUD4ykeWZXH1s7+3iqM3h/dvcBRtPFdw4zDv8FFQ5XViQK/hKC4J/gmt97nkXeTwP91Gf7qc0eoCZzgOp0H1VjfaTGeqkY7SU50ocVPlkrzilyfne4v+v7ZOEJyUqoash5LQr+sUf7YSj49cXQfsiMTPDpBtWLJ1z/SWuOmXD64RzSI+GBoi84MIwOQv8gpIem8Dk5Ef7oY4dirazP+84N0LA8+O5VDcGBD8AzkE1DNpszHL57Nm88A91PFw+gc0twQEuPBO/jw37kpaRIfO9DR5Ylqw4dzCsP/UqmshYyaRjce+jAPDp+AB2kpB2upPVXHlpnquZQgqmsg0UrDh3ga5rC4aZgPHe4siFIkADXTrAPfvTXh4+7B3+D/O82/lo8lf21dJElAjP7FvAmoNXMOoBrgBSAu28ENgHnAtuBQeCiqGIpq0JJICzf0z/C1s4+nu7Yw0sdHXTt3MFQ726a6aPZDvDyVD9vrRthZdsgbYkD1PsBkp7GPIN5FvM0Fv7jWzYTHhQykMnAWHrSf+b3Pnf1oRFLHr5DNyyDmhPydvTFUFF96NdhMnVoeKJflJ9qLR7EX/08/LXbn/PLt+/wX8EHfx3vCQ6Wrcfn/BM2FhluCg6gicTE/4gX3jbhNipZNgvp4bwDVPj6yjuKL/c/nw4O8qm6QweO2TbR9/+bRwqXZzNhchiB9Oih9/HkcjDZZCZPRoUOtuM+8qvDf71X1EByGocl93D7F/hF/+X1k6w/56Cfqp3e+meLWXiGVhXsw3Mksm/s7u+fZLoDl0S1/qPBgc++mlPtAH9og4cKKw8NOoZlmyDZCrWtUHNccKDNPQVPJPPGK8LT8nD8/uuLB/Dh/5fzC6Y+2Ann2srT5n6dUUgkggNZZe3Ullu0Ipp4ZiqRDL/LFL9PId+bYNrSV8788yHYd8cvGdU2l77cbK1/InVLil8VmCfKeWloYRsdgO0/m3CW7LLXMNC0lMrWFVQ3LgkO9nWtB9+tpin4h5yJiRLB8pNn9tmlKvc/QrnXX25x//7lVuAS8HyjRDCb+rvhtz/Gn7mL7HP3kZzw+jUc99GJfiotIOX+Ryj3+st9II779y/3+o8CSgQzte95eOYueOYu/KUHMJzd1samsTfzm8oz+NfsNeWNT/8E5VfuA3G5lfv7l3v9RwElgqlyh51bDh786XoKgM7q47kt+242jZ1G7TGncOEfrOafX7Uc/unGeP8aFJF5T4mgVMN9cN+n4ekfQt8O3BLsbVnHDxsu5t/3nMiezFLOe81KPnvGsbxqZc5TGjoQi8g8p0RQqm33wG82MrLmrfxi6V/yj79bzbaOKl7WXMuH1h/Ln6xbRWNt5eSfIyIyzygRlGhsXzsp4PRnP0Bvtpo3rW3j6jOO5Q9fsYTkNKr9i4jMF0oEJWp/cRutXsMfn/4K/vINL2d1a125QxIRmRVKBKXq62SXN3PV+hOpr9JmE5GFQ11VlqhqcBdd1qokICILjhJBiepGuuir1LP3IrLwKBGUIj3Kosw+hmuWljsSEZFZp0RQiv5dJHAy9fO0gTARkRlQIihBuqcDgMTilWWORERk9ikRlOBAV9DDW1VLNJ1CiIiUkxJBCQa72wFomGZfoSIi85kSQQnG9rfT79W0tkzQ05aIyFFKiaAEHlYmW944C701iYjMM0oEJagc2MluWmiqTZU7FBGRWadEUIK6kd30pJZg5ejTV0QkYkoEk8mkWZTex5Aqk4nIAqVEMJn+XSTIkq5bXu5IREQioUQwCe/dAagymYgsXEoEk+jf8xIAqaZVZY5ERCQaSgSTGOgKEkG9KpOJyAKlRDCJ0f3tDHoVra1qglpEFiYlgkl47w52ejPLGmvKHYqISCSUCCaRGtjJbpppq68qdygiIpFQIphEzfBu9le0UZHUphKRhUlHt4lkMywa28NgtSqTicjCpUQwkf4ukmQZrVVlMhFZuJQIJtLXCYCpMpmILGBKBBMY2hv0TKbKZCKykCkRTKB/vDJZ28vKHImISHSUCCYwsq+dYU/R1Lqs3KGIiEQm0kRgZueY2bNmtt3MriowfbGZ/dDMHjOzrWZ2UZTxTFU2rEy2XJXJRGQBiywRmFkSuBFYD5wEvN/MTsqb7RLgKXd/DfAm4HNmVhlVTFNV0b+TXd7C0kXV5Q5FRCQyUZ4RnA5sd/fn3X0U+DZwXt48DjRY0PVXPbAPSEcY05TUDO1ib7KF6lSy3KGIiEQmykSwEmjPGe8Iy3L9C3Ai0Ak8AVzm7tn8DzKzDWa22cw2d3d3RxXv4bJZGsa6GVBlMhFZ4KJMBIU6+PW88bOBLcAK4BTgX8xs0RELud/s7uvcfV1bW9tsx1nYQDcVZBit1Y1iEVnYokwEHcAxOeOrCH7557oIuM0D24HfASdEGFPp+oKeybxBdQhEZGGLMhE8BBxvZmvCG8DvA+7Mm+cl4C0AZrYUWAs8H2FMJRvr6QAg1axEICILW0VUH+zuaTO7FLgbSAK3uPtWM7s4nL4R+BTwFTN7guBS0pXuvieqmKaiv+tFmoDalmMmnVdE5GgWWSIAcPdNwKa8so05w53A26OMYbqG97Yz4hU0tanBORFZ2FSzuIhMzw52exPLGmvLHYqISKSUCIpI9HeykxaWLVZlMhFZ2JQIiqge3E23tdBQFenVMxGRslMiKCSbpWGsiwNVSwkqPYuILFxKBIUM7iXlY6pMJiKxoERQSFiZLFu/osyBiIhET4mggExvkAgqmtRFpYgsfEoEBQx2Bz2TVbceW+ZIRESip0RQwOCelxjzJI2tujQkIgufEkEB6Z4OdtPEclUmE5EYUCIoIHGgk53erMpkIhILSgQFVA3uYjctNNfOm14zRUQio0SQz5360S76KpeQSKgymYgsfEoE+Yb2U+mjDNeoMpmIxIMSQb7eoEOabL2anxaReFAiyONhreJko3omE5F4UCLIM7SnHYCqZvVMJiLxoESQZ3DvS6Q9weIlOiMQkXhQIsgztj+oTLassa7coYiIzAklgjzW18kuVSYTkRhRIshTObCTXd7MkoaqcociIjInlAhyuVM/0kVPqo1UUptGROJBR7tcwz1U+jBDqkwmIjGiRJCrrxOATJ2anxaR+FAiyBX2TJZoVM9kIhIfSgQ5RvaPVyZTHQIRiQ8lghyD3S+RcaOhVWcEIhIfSgQ5Rvd30E0jS5sayh2KiMicUSLI1dfJTm9h+eKackciIjJnlAhypAbCLioXqVaxiMSHEsE4d+qGd7Mv2UpNZbLc0YiIzBklgnEjfVRlhxiqXlruSERE5pQSwbiwMtlYnXomE5F4USIYF/ZMZov16KiIxEukicDMzjGzZ81su5ldVWSeN5nZFjPbama/jDKeiaR7gkSQalLPZCISLxVRfbCZJYEbgbcBHcBDZnanuz+VM08j8EXgHHd/ycyWRBXPZAa7X6TejUVtqlUsIvES5RnB6cB2d3/e3UeBbwPn5c3zAeA2d38JwN27IoxnQqP72tnDYpaoMpmIxEyUiWAl0J4z3hGW5XoF0GRmvzCzh83szwp9kJltMLPNZra5u7s7kmCzvWEdAvVMJiIxE2UisAJlnjdeAZwGvAM4G/i4mb3iiIXcb3b3de6+rq2tbfYjBSoGdga1ihepVrGIxEtJicDMbjWzd5jZVBJHB5B753UV0Flgnp+4+4C77wHuB14zhXXMmtrh3XRbC4tqIrttIiIyL5V6YL+J4Hr+NjO7zsxOKGGZh4DjzWyNmVUC7wPuzJvnDuAsM6sws1rgdcDTJcY0e0YOUJ3pZ7B6KWaFTmRERBaukn7+uvu9wL1mthh4P/BTM2sH/g34uruPFVgmbWaXAncDSeAWd99qZheH0ze6+9Nm9hPgcSALfMndn5yVbzYVYWWy0Vp1USki8VPydRAzawE+CFwIPAp8A3gD8CHgTYWWcfdNwKa8so1549cD108l6FkXViZDlclEJIZKSgRmdhtwAvAfwB+7+85w0nfMbHNUwc2VbO8OEkCqSXUIRCR+Sj0j+Bd3/3mhCe6+bhbjKYuhPe3UAfVtqlUsIvFT6s3iE8NawACYWZOZfTSakObeyL6X6PZFtDUuKncoIiJzrtRE8Ffu3jM+4u77gb+KJKIyyPbsYJc3s1yVyUQkhkpNBAnLea4ybEeoMpqQ5l6yfye7vEU9k4lILJV6j+Bu4LtmtpGgdvDFwE8ii2qOVQ/tZjeraamvKncoIiJzrtREcCXwYeAjBE1H3AN8Kaqg5tToADWZPg5ULSWZUGUyEYmfUiuUZQlqF98UbThlEFYmG1FlMhGJqVLrERwP/F/gJODghXR3f3lEcc2d8cpkDapMJiLxVOrN4i8TnA2kgTcDXyOoXHbU894gEVQ0KRGISDyVmghq3P1ngLn7i+5+LfBH0YU1d0b2dwBQ26LKZCIST6XeLB4Om6DeFjYktwMoW7eSs2l4TzsD3kBbc2O5QxERKYtSzwg+BtQCf0PQkcwHCRqbO+plejrYpZ7JRCTGJj0jCCuPvdfdrwD6gYsij2oOJfqDLirXqjKZiMTUpGcE7p4BTrMF2mNL9eAudnkzS5UIRCSmSr1H8Chwh5l9DxgYL3T32yKJaq6MDVGT7qWvcgmVFVF23ywiMn+Vmgiagb0c/qSQA0d3Iggrkw2rMpmIxFipNYsX1H2Bg8JEkK1fUeZARETKp9SaxV8mOAM4jLv/+axHNJfCWsXJRlUmE5H4KvXS0I9yhquBC4DO2Q9nbo3t7yAF1La+rNyhiIiUTamXhm7NHTezbwH3RhLRHBre+xIDXkdLU1O5QxERKZtSzwjyHQ8c9T+jx/bvYLd6JhORmCv1HsEBDr9HsIugj4KjWuJAJzu9hWOVCEQkxkq9NNQQdSDlUDW4k11+Kq9TZTIRibGSalGZ2QVmtjhnvNHMzo8sqrkwNkzN2H72VbRSVzXdK2QiIke/UqvTXuPuveMj7t4DXBNJRHPlwE4AhqtVmUxE4q3URFBovqP7Z3RYmSzTsLzMgYiIlFepiWCzmX3ezI4zs5eb2T8BD0cZWOTCRJBoXFXmQEREyqvURPDXwCjwHeC7wBBwSVRBzYVMTzsA1c1KBCISb6U+NTQAXBVxLHNqeF87Ga+lpbm13KGIiJRVqU8N/dTMGnPGm8zs7siimgNj+zrY6c0sW1xV7lBERMqq1EtDreGTQgC4+36O9j6LD3QGXVQuqil3JCIiZVVqIsia2cEmJcxsNQVaIz2aVA7sotNb1LyEiMReqY+A/i3wn2b2y3D8jcCGaEKaA+lRakb30m0tNNamyh2NiEhZlXqz+Cdmto7g4L8FuIPgyaGj04GdGM5QzVIWaFfMIiIlK/Vm8V8CPwP+V/j6D+DaEpY7x8yeNbPtZlb0qSMz+30zy5jZe0oLe4bGK5PVqzKZiEip9wguA34feNHd3wycCnRPtICZJYEbgfXAScD7zeykIvN9Bpi7p5DCnslssXomExEpNREMu/swgJlVufszwNpJljkd2O7uz7v7KPBt4LwC8/01cCvQVWIsM+bhGUFl81HfpYKIyIyVerO4I6xHcDvwUzPbz+RdVa4E2nM/A3hd7gxmtpKg28s/IjjjKMjMNhDenH7Zy2Z+8B7Z186Y19Dc3DLjzxIROdqVerP4gnDwWjO7D1gM/GSSxQrdhc1/5PQLwJXunpnopq273wzcDLBu3boZP7Y6urddPZOJiISm3IKou/9y8rmA4AzgmJzxVRx5FrEO+HaYBFqBc80s7e63TzWuqfC+HWGtYlUmExGJsinph4DjzWwNsAN4H/CB3Bncfc34sJl9BfhR1EkAIDWwi11+Iq9Qz2QiIiXfLJ4yd08DlxI8DfQ08F1332pmF5vZxVGtd1KZMWpGutltLbQ1qJ0hEZFIO5dx903ApryyjUXm/e9RxnJQ/24Mp79qKcmEKpOJiER2RjBv9QZ1CMZq1UWliAjEMRGoMpmIyGFimAiCB5dSTeqZTEQEjvYO6KdhdH87aa+iqbmt3KGIiMwLsUsEI/s66PJmljWqDoGICMTw0pD3hpXJVIdARASIYSKo6O9kFy0sV61iEREgbokgk6Z6eA87vZkli1SZTEQE4pYIBrpIkKEv1UZ1KlnuaERE5oV4JYLw0dHRuhVlDkREZP6IVyLo7QjeFykRiIiMi1ciCM8IKlSZTETkoFjVI0j3dpD2FI1NS8odiojIvBGrRDC6t4Pd3sxSVSYTETkoVpeGMr072OUt6qJSRCRHrBJBsr+TTlSrWEQkV3wSQTZD9VAXu7yZZTojEBE5aOHfI7j+eBjoAoKsd0nFnXBdK9QtgSu2lTc2EZF5YOGfEYRJoORyEZGYWfiJQEREJqREICISc0oEIiIxp0QgIhJzCz4RDFe1TKlcRCRuFvzjo2+xL7FjeOiI8pXVNfxXGeIREZlvFvwZQWfPkUlgonIRkbhZ8IlgRZEG5oqVi4jEzYJPBFecvZaavG4pa1JJrjh7bZkiEhGZXxb8PYLzT10JwPV3P0tnzxArGmu44uy1B8tFROJuwScCCJKBDvwiIoUt+EtDIiIyMSUCEZGYUyIQEYk5JQIRkZiLNBGY2Tlm9qyZbTezqwpM/1Mzezx8/crMXhNlPCIicqTIEoGZJYEbgfXAScD7zeykvNl+B/yhu58MfAq4Oap4RESksCjPCE4Htrv78+4+CnwbOC93Bnf/lbvvD0cfAFZFGI+IiBQQZSJYCbTnjHeEZcX8BfDjQhPMbIOZbTazzd3d3bMYooiIRJkIrECZF5zR7M0EieDKQtPd/WZ3X+fu69ra2mYxRBERibJmcQdwTM74KqAzfyYzOxn4ErDe3fdGGI+IiBQQ5RnBQ8DxZrbGzCqB9wF35s5gZi8DbgMudPffRhiLiIgUEdkZgbunzexS4G4gCdzi7lvN7OJw+kbgE0AL8EUzA0i7+7qoYhIRkSOZe8HL9vPWunXrfPPmzeUOQ0TkqGJmDxf7oR2L1kdFRMbGxujo6GB4eLjcoUSqurqaVatWkUqlSl5GiUBEYqGjo4OGhgZWr15NeCl6wXF39u7dS0dHB2vWrCl5ObU1JCKxMDw8TEtLy4JNAgBmRktLy5TPepQIRCQ2FnISGDed76hEICISc0oEIiIF3P7oDs687uesueouzrzu59z+6I4ZfV5PTw9f/OIXp7zcueeeS09Pz4zWPRklAhGRPLc/uoOrb3uCHT1DOLCjZ4irb3tiRsmgWCLIZDITLrdp0yYaGxunvd5S6KkhEYmdT/5wK0919hWd/uhLPYxmsoeVDY1l+N/ff5xvPfhSwWVOWrGIa/74lUU/86qrruK5557jlFNOIZVKUV9fz/Lly9myZQtPPfUU559/Pu3t7QwPD3PZZZexYcMGAFavXs3mzZvp7+9n/fr1vOENb+BXv/oVK1eu5I477qCmpmYaW+BwOiMQEcmTnwQmKy/Fddddx3HHHceWLVu4/vrrefDBB/n0pz/NU089BcAtt9zCww8/zObNm7nhhhvYu/fIpte2bdvGJZdcwtatW2lsbOTWW2+ddjy5dEYgIrEz0S93gDOv+zk7eoaOKF/ZWMN3PnzGrMRw+umnH/as/w033MAPfvADANrb29m2bRstLS2HLbNmzRpOOeUUAE477TReeOGFWYlFZwQiInmuOHstNankYWU1qSRXnL121tZRV1d3cPgXv/gF9957L7/+9a957LHHOPXUUwvWBaiqqjo4nEwmSafTsxKLzghERPKcf2rQh9b1dz9LZ88QKxpruOLstQfLp6OhoYEDBw4UnNbb20tTUxO1tbU888wzPPDAA9Nez3QoEYiIFHD+qStndODP19LSwplnnsmrXvUqampqWLp06cFp55xzDhs3buTkk09m7dq1vP71r5+19ZZCrY+KSCw8/fTTnHjiieUOY04U+q4TtT6qewQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzqkcgIpLv+uNhoOvI8rolcMW2aX1kT08P3/zmN/noRz865WW/8IUvsGHDBmpra6e17snojEBEJF+hJDBReQmm2x8BBIlgcHBw2uuejM4IRCR+fnwV7Hpiest++R2Fy5e9GtZfV3Sx3Gao3/a2t7FkyRK++93vMjIywgUXXMAnP/lJBgYGeO9730tHRweZTIaPf/zj7N69m87OTt785jfT2trKfffdN724J6BEICIyB6677jqefPJJtmzZwj333MP3v/99HnzwQdydd73rXdx///10d3ezYsUK7rrrLiBog2jx4sV8/vOf57777qO1tTWS2JQIRCR+JvjlDsC1i4tPu+iuGa/+nnvu4Z577uHUU08FoL+/n23btnHWWWdx+eWXc+WVV/LOd76Ts846a8brKoUSgYjIHHN3rr76aj784Q8fMe3hhx9m06ZNXH311bz97W/nE5/4ROTx6GaxiEi+uiVTKy9BbjPUZ599Nrfccgv9/f0A7Nixg66uLjo7O6mtreWDH/wgl19+OY888sgRy0ZBZwQiIvmm+YjoRHKboV6/fj0f+MAHOOOMoLez+vp6vv71r7N9+3auuOIKEokEqVSKm266CYANGzawfv16li9fHsnNYjVDLSKxoGao1Qy1iIgUoUQgIhJzSgQiEhtH26Xw6ZjOd1QiEJFYqK6uZu/evQs6Gbg7e/fupbq6ekrL6akhEYmFVatW0dHRQXd3d7lDiVR1dTWrVq2a0jJKBCISC6lUijVr1pQ7jHkp0ktDZnaOmT1rZtvN7KoC083MbginP25mr40yHhEROVJkicDMksCNwHrgJOD9ZnZS3mzrgePD1wbgpqjiERGRwqI8Izgd2O7uz7v7KPBt4Ly8ec4DvuaBB4BGM1seYUwiIpInynsEK4H2nPEO4HUlzLMS2Jk7k5ltIDhjAOg3s2enGVMrsGeay86F+R4fzP8YFd/MKL6Zmc/xHVtsQpSJwAqU5T+3Vco8uPvNwM0zDshsc7Eq1vPBfI8P5n+Mim9mFN/MzPf4iony0lAHcEzO+CqgcxrziIhIhKJMBA8Bx5vZGjOrBN4H3Jk3z53An4VPD70e6HX3nfkfJCIi0Yns0pC7p83sUuBuIAnc4u5bzezicPpGYBNwLrAdGAQuiiqe0IwvL0VsvscH8z9GxTczim9m5nt8BR11zVCLiMjsUltDIiIxp0QgIhJzCzIRzOemLczsGDO7z8yeNrOtZnZZgXneZGa9ZrYlfEXfe/Xh63/BzJ4I131Ed3Bl3n5rc7bLFjPrM7OP5c0z59vPzG4xsy4zezKnrNnMfmpm28L3piLLTri/Rhjf9Wb2TPg3/IGZNRZZdsL9IcL4rjWzHTl/x3OLLFuu7fednNheMLMtRZaNfPvNmLsvqBfBjenngJcDlcBjwEl585wL/JigHsPrgd/MYXzLgdeGww3AbwvE9ybgR2Xchi8ArRNML9v2K/C33gUcW+7tB7wReC3wZE7ZZ4GrwuGrgM8U+Q4T7q8Rxvd2oCIc/kyh+ErZHyKM71rg8hL2gbJsv7zpnwM+Ua7tN9PXQjwjmNdNW7j7Tnd/JBw+ADxNUJv6aDJfmgZ5C/Ccu79YhnUfxt3vB/blFZ8HfDUc/ipwfoFFS9lfI4nP3e9x93Q4+gBBPZ6yKLL9SlG27TfOzAx4L/Ct2V7vXFmIiaBYsxVTnSdyZrYaOBX4TYHJZ5jZY2b2YzN75dxGhgP3mNnDYfMe+ebF9iOom1Lsn6+c22/cUg/rxYTvSwrMM1+25Z8TnOUVMtn+EKVLw0tXtxS5tDYftt9ZwG5331Zkejm3X0kWYiKYtaYtomRm9cCtwMfcvS9v8iMElzteA/wzcPtcxgac6e6vJWgd9hIze2Pe9Pmw/SqBdwHfKzC53NtvKubDtvxbIA18o8gsk+0PUbkJOA44haD9sc8VmKfs2w94PxOfDZRr+5VsISaCed+0hZmlCJLAN9z9tvzp7t7n7v3h8CYgZWatcxWfu3eG713ADwhOv3PNh6ZB1gOPuPvu/Anl3n45do9fMgvfuwrMU+598UPAO4E/9fCCdr4S9odIuPtud8+4exb4tyLrLff2qwDeDXyn2Dzl2n5TsRATwbxu2iK8nvjvwNPu/vki8ywL58PMTif4O+2do/jqzKxhfJjghuKTebPNh6ZBiv4KK+f2y3Mn8KFw+EPAHQXmKWV/jYSZnQNcCbzL3QeLzFPK/hBVfLn3nS4ost6ybb/QW4Fn3L2j0MRybr8pKffd6iheBE+1/JbgaYK/DcsuBi4Oh42g05zngCeAdXMY2xsITl0fB7aEr3Pz4rsU2ErwBMQDwB/MYXwvD9f7WBjDvNp+4fprCQ7si3PKyrr9CJLSTmCM4FfqXwAtwM+AbeF7czjvCmDTRPvrHMW3neD6+vh+uDE/vmL7wxzF9x/h/vU4wcF9+XzafmH5V8b3u5x553z7zfSlJiZERGJuIV4aEhGRKVAiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhCJmAWtof6o3HGIFKNEICISc0oEIiEz+6CZPRi2G/+vZpY0s34z+5yZPWJmPzOztnDeU8zsgZy2/JvC8t8zs3vDBu8eMbPjwo+vN7PvW9D+/zdyaj5fZ2ZPhZ/zj2X66hJzSgQigJmdCPw3ggbCTgEywJ8CdQRtGr0W+CVwTbjI14Ar3f1kgtqv4+XfAG70oMG7PyCojQpBK7MfA04iqG16ppk1EzSd8Mrwc/4hyu8oUowSgUjgLcBpwENhT1NvIThgZznUoNjXgTeY2WKg0d1/GZZ/FXhj2KbMSnf/AYC7D/uhNnwedPcODxpQ2wKsBvqAYeBLZvZuoGB7PyJRUyIQCRjwVXc/JXytdfdrC8w3UZsshZpEHjeSM5wh6BksTdAS5a0Endb8ZGohi8wOJQKRwM+A95jZEjjY3/CxBP8j7wnn+QDwn+7eC+w3s7PC8guBX3rQr0SHmZ0ffkaVmdUWW2HYJ8ViD5rK/hhBu/sic66i3AGIzAfu/pSZ/R1BT1IJglYmLwEGgFea2cNAL8F9BAiald4YHuifBy4Kyy8E/tXM/j78jD+ZYLUNwB1mVk1wNvE/ZvlriZRErY+KTMDM+t29vtxxiERJl4ZERGJOZwQiIjGnMwIRkZhTIhARiTklAhGRmFMiEBGJOSUCEZGY+//qb09S05GKIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6  CNN 시각화하기\n",
    "\n",
    "![cnn.png](https://sean-parkk.github.io/assets/images/DLscratch/7/Untitled%2011.png)\n",
    "\n",
    "합성 곱 계층을 여러겹 쌓으면, 층이 깊어지면서 더 복잡하고 추상화된 정보가 추출됨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 대표적인 CNN\n",
    "\n",
    "#### LeNet\n",
    "손글씨 숫자를 인식하는 네트워크\n",
    "![lenet.png](https://lh3.googleusercontent.com/proxy/VRzAs2UH2vQsxc1_tFTkRUQ7sXkgaFg1FFNqROUSFOQjQrafVOSNmvZj0_vVkeLdlOjrkGVZ_aSoNjPnCCLOt1UEgDFOaq1gsmnecggEtAkEsKE1hbk-6_UgrJ5NMR_vU7OrnVdRauJQUj2ggeq1VtDtbHkHzHcg1SYOJJ7UHMEB0g)\n",
    "\n",
    "현재의 CNN과 비교하면 몇가지 차이가 있음\n",
    "- 활성화 함수로 시그모이드를 사용한다\n",
    "- LeNet은 서브샘플링을 하여 중간 데이터의 크기가 작아지지만 현재는 최대풀링이 주류이다\n",
    "\n",
    "#### AlexNet\n",
    "- 활성화함수로 ReLU를 이용한다\n",
    "- LRN이라는 국소적 정규화를 실시하는 계층을 이용한다\n",
    "- 드롭아웃을 사용한다\n",
    "\n",
    "![alexnet.png](https://t1.daumcdn.net/cfile/tistory/99FEB93C5C80B5192E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8 정리\n",
    "\n",
    "* CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.\n",
    "* 합성곱 계층과 풀링 계층은 im2col (이미지를 행렬로 전개하는 함수)을 이용하면 간단하고 효율적으로 구현할 수 있다.\n",
    "* CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.\n",
    "* 대표적인 CNN에는 LeNet과 AlexNet이 있다.\n",
    "* 딥러닝의 발전에는 빅 데이터와 GPU가 크게 기여했다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
