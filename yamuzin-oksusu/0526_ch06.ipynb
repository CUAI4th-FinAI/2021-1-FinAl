{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 6 게이트가 추가된 RNN\n",
    "\n",
    "5장에서 본 RNN은 순환 경로를 포함하여 과거의 정보를 기억할 수 있으며 구조가 단순하여 구현도 쉽게 가능하지만 성능이 좋지 못하였는데 그 원인은 시계열 데이터에서 시간적으로 멀리 떨어진, 즉 **장기 의존 관계를 잘 학습할 수 없기 때문**\n",
    "\n",
    "### 6.1 RNN의 문제점\n",
    "\n",
    "RNN은 시계열 데이터의 장기 의존 관계를 학습하기 어려움. BPTT에서 **기울기 소실 혹은 기울기 폭발**이 때문\n",
    "\n",
    "![1](https://media.vlpt.us/post-images/dscwinterstudy/1159e620-4b07-11ea-a7ae-e999224db48a/fig-6-4.png)\n",
    "\n",
    "RNNLM의 관점에서 보면 정답 레이블이 'Tom'임을 학습할 때 중요한 것이 바로 RNN 계층의 존재<br>\n",
    "RNN 계층이 과거 방향으로 '의미 있는 기울기'를 전달함으로 시간 방향의 의존 관계를 학습할 수 있음\n",
    "\n",
    "여기서 기울기는 학습해야 할 의미가 있는 정보가 들어 있고, 그것을 과거로 전달함으로써 장기 의존 관계를 학습<br>\n",
    "하지만 중간에 기울기가 사그라들면 가중치 매개변수는 전혀 갱신되지 않게 되어 장기 의존 관계를 학습할 수 없게 됨<br>\n",
    "현재는 RNN 계층에서 시간을 거슬러 올라가 기울기가 작아지거나 커져 소실 혹은 폭발되는 상황\n",
    "\n",
    "#### 기울기 소실과 기울기 폭발의 원인\n",
    "\n",
    "![2](https://media.vlpt.us/post-images/dscwinterstudy/979eea50-4b07-11ea-a39d-699a549f4f48/fig-6-5.png)\n",
    "\n",
    "위의 RNN 계층의 그림에서 시간 방향 기울기 전파에만 주목함.\n",
    "길이가 T인 시계열 데이터를 가정, T번째 정답 레이블로부터 전해지는 기울기의 변화?\n",
    "- 앞의 문제에 대입하면 T번째 정답 레이블이 'Tom'인 경우에 해당\n",
    "- 이때 시간 방향 기울기에 주목하면 역전파로 전해지는 기울기는 차례로 'tanh','+','MatMul(행렬 곱)' 연산을 통과\n",
    "\n",
    "'+'의 역전파는 상류에서 전해지는 기울기를 그대로 하류로 흘러보내 기울기는 변하지 않음\n",
    "\n",
    "'tanh'의 경우와 미분된 경우의 그래프\n",
    "![3](https://media.vlpt.us/post-images/dscwinterstudy/3aab0710-4b08-11ea-a39d-699a549f4f48/fig-6-6.png)\n",
    "\n",
    "점선이 y=tanh(x)의 미분이고 값은 1.0 이하이며, x가 0으로부터 멀어질수록 작아짐<br>\n",
    "역전파에서 기울기가 tanh 노드를 지날 때마다 값은 계속 작아짐. tanh 함수를 T번 통과하면 기울기도 T번 반복해서 작아짐.\n",
    "\n",
    "'MatMul(행렬 곱)' 노드의 경우 tanh 노드를 무시-> 그러면 RNN 계층의 역전파 시 기울기는 아래 그림과 같이 'MatMul' 연산에 의해서만 변화\n",
    "\n",
    "![4](https://media.vlpt.us/post-images/dscwinterstudy/98f8df90-4b08-11ea-bee9-c16c025c7fb9/fig-6-7.png)\n",
    "\n",
    " 행렬 곱의 기울기는 시간에 비례해 지수적으로 증가/감소함\n",
    "\n",
    "- 증가할 경우? **기울기 폭발**\n",
    "기울기 폭발이 일어나면 오버플로를 일으켜 NaN 같은 값을 발생시킴\n",
    "\n",
    "- 감소할 경우? **기울기 소실**\n",
    "일정 수준 이하로 작아지면 가중치 매개변수가 더 이상 갱신되지 않으므로 장기 의존 관계를 학습할 수 없게 됨\n",
    "\n",
    "#### 기울기 폭발 대책\n",
    "\n",
    "**기울기 클리핑**\n",
    "\n",
    "![5](https://blog.kakaocdn.net/dn/uiIIw/btqCjQAh2xa/seoggvNOcOCLooXWNOIQZ0/img.png)\n",
    "\n",
    "기울기의 L2노름이 문턱값을 초과하면 두 번째 줄의 수식과 같이 기울기를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: [5.57658499 1.04908355 8.00622884 6.81465691 4.74151504 1.88437192\n",
      " 8.15692658 9.31937732 0.68789136]\n",
      "after: [1.04226449 0.19607386 1.49636525 1.27366029 0.8861898  0.35218937\n",
      " 1.52453068 1.74179288 0.12856699]\n"
     ]
    }
   ],
   "source": [
    "# 기울기 클리핑 구현\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "\n",
    "print('before:', dW1.flatten())\n",
    "clip_grads(grads, max_norm)\n",
    "print('after:', dW1.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 기울기 소실과 LSTM\n",
    "\n",
    "![6](https://media.vlpt.us/images/dscwinterstudy/post/211ad6bf-24f1-4132-9f84-a5d414f753c8/fig%206-11.png)\n",
    "\n",
    "LSTM계층의 인터페이스엔 **C**라는 경로가 있음\n",
    "\n",
    "c: 기억셀이라고 하며, LSTM 전용 기억 메커니즘\n",
    "\n",
    "#### LSTM 계층 조립하기\n",
    "\n",
    "![7](https://media.vlpt.us/images/dscwinterstudy/post/46398c57-b304-434b-aebb-2ca665da6a1a/fig%206-12.png)\n",
    "\n",
    "그림에서 현재의 기억 셀 c_t는 3개의 입력 (c(t-1),h_(t-1),x_t)으로부터 '어떤 계산'을 수행하여 구할 수 있음<br>\n",
    "핵심? 갱신된 c_t를 사용해 은닉 상태 h_t를 계산한다는 것<br>\n",
    "또한 이 계산은 h_t=tanh(c_t)인데, 이는 c_t의 각 요소에 tanh 함수를 적용한다는 뜻\n",
    "\n",
    " 문을 열거나 닫을 수 있듯이, 게이트는 데이터의 흐름을 제어한다.\n",
    "\n",
    "![8](https://media.vlpt.us/images/dscwinterstudy/post/253159b7-0240-41e7-a944-24090e7876bf/fig%206-14.png)\n",
    "\n",
    "게이트의 열림 사애는 그림에서처럼 0.0~1.0 사이의 실수로 나타나며 1.0은 완전한 개방을 의미함<br>\n",
    "그 값이 다음으로 흐르는 물의 양을 결정\n",
    "\n",
    "- 여기서 중요한 것은 '게이트를 얼마나 열까'라는 것도 데이터로부터 자동으로 학습한다는 점이다.\n",
    "\n",
    "#### output 게이트\n",
    "\n",
    "output 게이트의 열림 상태는 입력 xt와 이전 상태 h(t-1)로부터 구함\n",
    "\n",
    "![9](https://media.vlpt.us/images/dscwinterstudy/post/494a88a1-9718-408c-abb5-95199d97126c/fig%206-15.png)\n",
    "\n",
    "#### forget 게이트\n",
    "\n",
    "기억 셀에 '무엇을 잊을까'를 명확하게 지시\n",
    "\n",
    "![10](https://media.vlpt.us/images/dscwinterstudy/post/f03b9010-3343-4ee3-87b7-d7b06dfe955b/fig%206-16.png)\n",
    "\n",
    "#### 새로운 기억 셀\n",
    "\n",
    "forget 게이트를 거치면서 이전 시각의 기억 셀로부터 잊어야 할 기억이 삭제됨\n",
    "\n",
    "![11](https://media.vlpt.us/images/dscwinterstudy/post/db1a12f0-084e-41ee-8f99-5107002ead3e/fig%206-17.png)\n",
    "\n",
    "#### input 게이트\n",
    "\n",
    "input 게이트는 g의 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단<br>\n",
    "새 정보를 무비판적으로 수용하는 게 아니라, 적절히 취사선택하는 것이 이 게이트의 역할<br>\n",
    "input 게이트에 의해 가중된 정보가 새로 추가되는 셈\n",
    "\n",
    "![12](https://media.vlpt.us/images/dscwinterstudy/post/7f655948-5f3d-4a7f-b2df-7f37d534570a/fig%206-18.png)\n",
    "\n",
    "#### LSTM의 기울기 흐름\n",
    "\n",
    "![13](https://media.vlpt.us/images/dscwinterstudy/post/24d75848-2a19-4403-a78d-7a558042c8d0/fig%206-19.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향（4개분의 편향이 담겨 있음）\n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time LSTM 구현\n",
    "\n",
    "Time LSTM은 T개분의 시계열 데이터를 한꺼번에 처리하는 계층\n",
    "\n",
    "![14](https://media.vlpt.us/images/dscwinterstudy/post/44954a14-f9b5-4224-9a8a-cc6cb26e8265/fig%206-25.png)\n",
    "\n",
    "Truncated BPTT는 역전파의 연결은 적당한 길이로 끊으며, 순전파의 흐름은 그래도 유지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구현\n",
    "\n",
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM을 사용한 언어 모델\n",
    "\n",
    "앞장에서 구현한 언어모델과의 차이는 LSTM을 사용한다는 것 뿐임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/minjuKim/Desktop/[FIN_AI]_study_myself/deep-learning-from-scratch-2-master\")\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10000.25\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 8[s] | 퍼플렉서티 2665.65\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 17[s] | 퍼플렉서티 1241.45\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 26[s] | 퍼플렉서티 972.71\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 34[s] | 퍼플렉서티 795.81\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 43[s] | 퍼플렉서티 651.71\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 52[s] | 퍼플렉서티 651.76\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 60[s] | 퍼플렉서티 588.22\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 69[s] | 퍼플렉서티 587.36\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 77[s] | 퍼플렉서티 569.51\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 86[s] | 퍼플렉서티 502.83\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 95[s] | 퍼플렉서티 483.23\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 104[s] | 퍼플렉서티 447.63\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 114[s] | 퍼플렉서티 467.36\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 123[s] | 퍼플렉서티 444.66\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 132[s] | 퍼플렉서티 383.40\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 140[s] | 퍼플렉서티 339.12\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 150[s] | 퍼플렉서티 404.52\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 159[s] | 퍼플렉서티 401.52\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 168[s] | 퍼플렉서티 333.94\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 176[s] | 퍼플렉서티 350.04\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 185[s] | 퍼플렉서티 336.99\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 193[s] | 퍼플렉서티 328.15\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 201[s] | 퍼플렉서티 328.30\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 210[s] | 퍼플렉서티 302.33\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 219[s] | 퍼플렉서티 310.44\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 228[s] | 퍼플렉서티 302.60\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 236[s] | 퍼플렉서티 323.07\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 244[s] | 퍼플렉서티 282.79\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 253[s] | 퍼플렉서티 258.43\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 261[s] | 퍼플렉서티 334.48\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 269[s] | 퍼플렉서티 310.16\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 277[s] | 퍼플렉서티 284.14\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 285[s] | 퍼플렉서티 267.97\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 294[s] | 퍼플렉서티 229.67\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 303[s] | 퍼플렉서티 249.18\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 312[s] | 퍼플렉서티 262.41\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 321[s] | 퍼플렉서티 223.48\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 329[s] | 퍼플렉서티 231.11\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 337[s] | 퍼플렉서티 218.81\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 346[s] | 퍼플렉서티 241.94\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 354[s] | 퍼플렉서티 225.26\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 362[s] | 퍼플렉서티 227.39\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 371[s] | 퍼플렉서티 222.07\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 379[s] | 퍼플렉서티 204.32\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 388[s] | 퍼플렉서티 254.91\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 397[s] | 퍼플렉서티 225.79\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 405[s] | 퍼플렉서티 231.76\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 414[s] | 퍼플렉서티 244.17\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 423[s] | 퍼플렉서티 228.71\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 432[s] | 퍼플렉서티 191.77\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 440[s] | 퍼플렉서티 226.41\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 448[s] | 퍼플렉서티 207.45\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 456[s] | 퍼플렉서티 197.48\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 464[s] | 퍼플렉서티 169.84\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 474[s] | 퍼플렉서티 189.43\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 482[s] | 퍼플렉서티 227.44\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 490[s] | 퍼플렉서티 207.65\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 499[s] | 퍼플렉서티 198.97\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 508[s] | 퍼플렉서티 190.29\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 517[s] | 퍼플렉서티 163.06\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 525[s] | 퍼플렉서티 159.65\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 533[s] | 퍼플렉서티 188.54\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 541[s] | 퍼플렉서티 171.34\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 549[s] | 퍼플렉서티 178.58\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 558[s] | 퍼플렉서티 222.46\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 567[s] | 퍼플렉서티 211.07\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 570[s] | 퍼플렉서티 224.52\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 580[s] | 퍼플렉서티 204.79\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 588[s] | 퍼플렉서티 191.06\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 597[s] | 퍼플렉서티 176.54\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 605[s] | 퍼플렉서티 159.43\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 614[s] | 퍼플렉서티 152.15\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 623[s] | 퍼플렉서티 160.37\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 631[s] | 퍼플렉서티 178.48\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 640[s] | 퍼플렉서티 193.86\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 648[s] | 퍼플렉서티 201.81\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 656[s] | 퍼플렉서티 187.01\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 665[s] | 퍼플렉서티 185.22\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 673[s] | 퍼플렉서티 176.03\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 681[s] | 퍼플렉서티 185.82\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 689[s] | 퍼플렉서티 185.39\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 698[s] | 퍼플렉서티 166.08\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 706[s] | 퍼플렉서티 138.49\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 715[s] | 퍼플렉서티 172.56\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 723[s] | 퍼플렉서티 198.54\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 731[s] | 퍼플렉서티 154.37\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 740[s] | 퍼플렉서티 169.92\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 748[s] | 퍼플렉서티 158.19\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 756[s] | 퍼플렉서티 164.97\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 765[s] | 퍼플렉서티 157.62\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 773[s] | 퍼플렉서티 157.06\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 782[s] | 퍼플렉서티 171.61\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 790[s] | 퍼플렉서티 173.34\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 799[s] | 퍼플렉서티 176.04\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 808[s] | 퍼플렉서티 154.99\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 817[s] | 퍼플렉서티 139.90\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 826[s] | 퍼플렉서티 189.88\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 836[s] | 퍼플렉서티 183.16\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 847[s] | 퍼플렉서티 166.39\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 860[s] | 퍼플렉서티 154.70\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 870[s] | 퍼플렉서티 131.23\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 878[s] | 퍼플렉서티 151.64\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 887[s] | 퍼플렉서티 160.24\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 895[s] | 퍼플렉서티 135.82\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 904[s] | 퍼플렉서티 130.56\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 912[s] | 퍼플렉서티 134.88\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 920[s] | 퍼플렉서티 147.46\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 930[s] | 퍼플렉서티 145.53\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 939[s] | 퍼플렉서티 144.71\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 947[s] | 퍼플렉서티 147.44\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 956[s] | 퍼플렉서티 131.45\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 964[s] | 퍼플렉서티 166.54\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 973[s] | 퍼플렉서티 146.31\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 981[s] | 퍼플렉서티 155.44\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 990[s] | 퍼플렉서티 164.11\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 1000[s] | 퍼플렉서티 154.57\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 1009[s] | 퍼플렉서티 131.50\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 1018[s] | 퍼플렉서티 157.32\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 1026[s] | 퍼플렉서티 142.84\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 1034[s] | 퍼플렉서티 129.56\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 1042[s] | 퍼플렉서티 112.19\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 1050[s] | 퍼플렉서티 120.78\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 1057[s] | 퍼플렉서티 155.99\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 1065[s] | 퍼플렉서티 142.07\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 1074[s] | 퍼플렉서티 134.68\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 1082[s] | 퍼플렉서티 136.41\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 1089[s] | 퍼플렉서티 113.87\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 1097[s] | 퍼플렉서티 110.75\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 1105[s] | 퍼플렉서티 131.54\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 1113[s] | 퍼플렉서티 123.21\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 1121[s] | 퍼플렉서티 123.73\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 1129[s] | 퍼플렉서티 157.89\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 1137[s] | 퍼플렉서티 152.54\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 1140[s] | 퍼플렉서티 160.97\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 1147[s] | 퍼플렉서티 144.30\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 1156[s] | 퍼플렉서티 137.68\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 1163[s] | 퍼플렉서티 127.83\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 1171[s] | 퍼플렉서티 117.92\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 1179[s] | 퍼플렉서티 107.20\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 1187[s] | 퍼플렉서티 117.43\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 1195[s] | 퍼플렉서티 126.76\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 1203[s] | 퍼플렉서티 141.96\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 1211[s] | 퍼플렉서티 151.52\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 1219[s] | 퍼플렉서티 142.13\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 1227[s] | 퍼플렉서티 142.46\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 1234[s] | 퍼플렉서티 135.14\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 1242[s] | 퍼플렉서티 141.57\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 1250[s] | 퍼플렉서티 144.20\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 1258[s] | 퍼플렉서티 124.96\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 1267[s] | 퍼플렉서티 103.08\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 1275[s] | 퍼플렉서티 124.83\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 1283[s] | 퍼플렉서티 153.51\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 1291[s] | 퍼플렉서티 115.61\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 1299[s] | 퍼플렉서티 131.24\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 1306[s] | 퍼플렉서티 116.36\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 1315[s] | 퍼플렉서티 125.96\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 1323[s] | 퍼플렉서티 118.51\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 1331[s] | 퍼플렉서티 120.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 501 / 1327 | 시간 1339[s] | 퍼플렉서티 130.65\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 1347[s] | 퍼플렉서티 139.74\n",
      "| 에폭 3 |  반복 541 / 1327 | 시간 1355[s] | 퍼플렉서티 137.20\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 1362[s] | 퍼플렉서티 119.30\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 1370[s] | 퍼플렉서티 107.11\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 1378[s] | 퍼플렉서티 150.22\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 1386[s] | 퍼플렉서티 144.38\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 1394[s] | 퍼플렉서티 131.33\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 1402[s] | 퍼플렉서티 121.02\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 1409[s] | 퍼플렉서티 101.73\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 1417[s] | 퍼플렉서티 120.43\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 1425[s] | 퍼플렉서티 126.32\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 1433[s] | 퍼플렉서티 108.41\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 1441[s] | 퍼플렉서티 105.18\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 1449[s] | 퍼플렉서티 106.30\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 1457[s] | 퍼플렉서티 116.34\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 1464[s] | 퍼플렉서티 117.63\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 1472[s] | 퍼플렉서티 113.95\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 1480[s] | 퍼플렉서티 120.36\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 1488[s] | 퍼플렉서티 107.00\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 1495[s] | 퍼플렉서티 132.81\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 1503[s] | 퍼플렉서티 118.45\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 1511[s] | 퍼플렉서티 128.84\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 1519[s] | 퍼플렉서티 132.22\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 1526[s] | 퍼플렉서티 124.65\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 1534[s] | 퍼플렉서티 110.45\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 1542[s] | 퍼플렉서티 129.78\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 1550[s] | 퍼플렉서티 119.02\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 1558[s] | 퍼플렉서티 103.50\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 1566[s] | 퍼플렉서티 90.19\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 1573[s] | 퍼플렉서티 97.34\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 1581[s] | 퍼플렉서티 123.17\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 1589[s] | 퍼플렉서티 114.91\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 1597[s] | 퍼플렉서티 108.14\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1605[s] | 퍼플렉서티 111.78\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1613[s] | 퍼플렉서티 95.19\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1621[s] | 퍼플렉서티 90.15\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1629[s] | 퍼플렉서티 106.59\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1637[s] | 퍼플렉서티 104.55\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1645[s] | 퍼플렉서티 101.92\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1653[s] | 퍼플렉서티 129.74\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1661[s] | 퍼플렉서티 125.75\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1664[s] | 퍼플렉서티 130.36\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 1672[s] | 퍼플렉서티 122.70\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 1680[s] | 퍼플렉서티 108.14\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 1687[s] | 퍼플렉서티 108.72\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 1695[s] | 퍼플렉서티 96.74\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 1703[s] | 퍼플렉서티 88.12\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 1711[s] | 퍼플렉서티 95.54\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 1718[s] | 퍼플렉서티 104.06\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 1726[s] | 퍼플렉서티 117.29\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 1734[s] | 퍼플렉서티 129.17\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 1742[s] | 퍼플렉서티 121.13\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 1749[s] | 퍼플렉서티 122.40\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 1757[s] | 퍼플렉서티 115.26\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 1765[s] | 퍼플렉서티 117.33\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 1773[s] | 퍼플렉서티 122.86\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 1781[s] | 퍼플렉서티 105.73\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 1788[s] | 퍼플렉서티 84.25\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 1797[s] | 퍼플렉서티 101.51\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 1805[s] | 퍼플렉서티 128.99\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 1813[s] | 퍼플렉서티 98.52\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 1821[s] | 퍼플렉서티 111.09\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 1829[s] | 퍼플렉서티 95.29\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 1837[s] | 퍼플렉서티 105.78\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 1845[s] | 퍼플렉서티 99.86\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 1853[s] | 퍼플렉서티 104.73\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 1860[s] | 퍼플렉서티 110.02\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 1868[s] | 퍼플렉서티 117.97\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 1876[s] | 퍼플렉서티 114.02\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 1884[s] | 퍼플렉서티 102.95\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 1892[s] | 퍼플렉서티 90.19\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 1900[s] | 퍼플렉서티 127.91\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 1907[s] | 퍼플렉서티 123.40\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 1916[s] | 퍼플렉서티 112.93\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 1923[s] | 퍼플렉서티 103.44\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 1931[s] | 퍼플렉서티 86.04\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 1939[s] | 퍼플렉서티 102.43\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 1947[s] | 퍼플렉서티 109.10\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 1954[s] | 퍼플렉서티 95.92\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 1962[s] | 퍼플렉서티 88.43\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 1970[s] | 퍼플렉서티 88.36\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 1978[s] | 퍼플렉서티 99.75\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 1986[s] | 퍼플렉서티 102.85\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 1994[s] | 퍼플렉서티 97.98\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 2002[s] | 퍼플렉서티 105.00\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 2009[s] | 퍼플렉서티 92.75\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 2017[s] | 퍼플렉서티 115.75\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 2025[s] | 퍼플렉서티 104.05\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 2033[s] | 퍼플렉서티 113.35\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 2041[s] | 퍼플렉서티 111.19\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 2049[s] | 퍼플렉서티 107.97\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 2057[s] | 퍼플렉서티 98.03\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 2065[s] | 퍼플렉서티 113.80\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 2072[s] | 퍼플렉서티 103.76\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 2080[s] | 퍼플렉서티 89.48\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 2088[s] | 퍼플렉서티 79.10\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 2096[s] | 퍼플렉서티 81.20\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 2104[s] | 퍼플렉서티 104.83\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 2112[s] | 퍼플렉서티 99.69\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 2119[s] | 퍼플렉서티 92.57\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 2127[s] | 퍼플렉서티 96.20\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 2135[s] | 퍼플렉서티 83.15\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 2143[s] | 퍼플렉서티 77.02\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 2151[s] | 퍼플렉서티 92.14\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 2159[s] | 퍼플렉서티 93.57\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 2167[s] | 퍼플렉서티 90.16\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 2175[s] | 퍼플렉서티 112.49\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 2183[s] | 퍼플렉서티 109.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+kklEQVR4nO3deXyc1Xno8d8ZzabRaLSvljfZ8o4xxgYDgYSdhiRk49ZZKOklJe1Nmma5aaFpm7a53NI2bdI2CyGBhGwQbiCFkBD23XgFb3iVZVuSrX0dLaPZzv3jXTQjjXaNtfj5fj7+aObVO6PzMsn7zDnPOc9RWmuEEEIIAMdMN0AIIcTsIUFBCCGETYKCEEIImwQFIYQQNgkKQgghbBIUhBBC2NIaFJRSp5RSB5RSe5VSu81j+Uqp55RSx82feQnn362UqlZKHVVK3ZjOtgkhhBjuXPQUrtZab9BabzKf3wW8oLWuAl4wn6OUWgNsBdYCNwHfVUplnIP2CSGEMM3E8NEtwEPm44eADyYcf0RrPaC1PglUA5ec++YJIcT5y5nm99fAs0opDXxfa30/UKK1bgDQWjcopYrNcxcA2xNeW28eS6KUuhO4EyArK+viVatWpbP9ANR19NE7EGNVaXba/5YQQqTbnj17WrXWRal+l+6gcIXW+qx5439OKXVklHNVimPDanCYgeV+gE2bNundu3dPT0tH8c3njvGfLx7nja/fhMcpI1pCiLlNKXV6pN+ldfhIa33W/NkM/BpjOKhJKVVmNqwMaDZPrwcWJry8AjibzvaN16J8H1rDmY7+mW6KEEKkVdqCglIqSymVbT0GbgAOAk8Ct5un3Q48YT5+EtiqlPIopZYCVcDOdLVvIhYV+ACobe+b4ZYIIUR6pXP4qAT4tVLK+ju/0Fr/Xim1C3hUKXUHUAvcCqC1fkcp9ShwCIgCn9Vax9LYvnFbnG8EhToJCkKIeS5tQUFrXQNcmOJ4G3DtCK+5B7gnXW2arKJsDx6ng9NtEhSEEPObrGgeB6UUi/J9MnwkhJj3JCiM06J8H3WSaBZCzHMSFMap0O+hvXdgppshhBBpJUFhnHJ9Ljr6Isj2pUKI+UyCwjjl+tyEo3H6I7NiQpQQQqSFBIVxyvO5AOjoi8xwS4QQIn0kKIxTrs8NQEdveIZbIoQQ6SNBYZwGewph2nok4SyEmJ8kKIxTXpbRU3h4Zy2X3fsirRIYhBDzkASFccrNNHoKrx9vJRyNc7qtd4ZbJIQQ00+CwjhZOYXuUBSAM52hmWyOEEKkhQSFcXI7HWS5B/dSaOiU1c1CiPlHgsIEWL0FgLMSFIQQ85AEhQnIy3LZj892yfCREGL+kaAwAbmZRk8hw6GkpyCEmJckKExArrlWYd2CHBqkpyCEmIckKExAnplT2LI0n/beMP1hqYMkhJhf0rkd57xz1Yoi2nvDrCzNBqChq5/KIv8Mt0oIIaaP9BQm4Po1JXznExspDXgBaOqWVc1CiPlFgsIkZHmMDlZfODrDLRFCiOklQWESfOYitj7JKQgh5hkJCpOQaQYFSTQLIeYbCQqT4HPL8JEQYn6SoDAJ9vCRbM0phJhnJChMgsfpQCkZPhJCzD8SFCZBKYXPlSGJZiHEvCNBYZIy3U4JCkKIeUeCwiT53Bn0S6JZCDHPSFCYJJ9bho+EEPOPBIVJynRn0C+zj4QQ84wEhUmSnoIQYj6SoDBJmS5JNAsh5h8JCpMkiWYhxHwkQWGSZPhICDEfSVCYpEx3hqxoFkLMO2kPCkqpDKXU20qpp8zn+Uqp55RSx82feQnn3q2UqlZKHVVK3Zjutk2Fz51BXySG1pqvP3WIf3r6MFrrmW6WEEJMybnoKfwFcDjh+V3AC1rrKuAF8zlKqTXAVmAtcBPwXaVUxjlo36T43E5icU04FueB10/y/VdqePCNUzPdLCGEmJK0BgWlVAVwM/DDhMO3AA+Zjx8CPphw/BGt9YDW+iRQDVySzvZNRaZrcE+FomwPAI/uqpvJJgkhxJSlu6fwLeAvgXjCsRKtdQOA+bPYPL4ASLyr1pvHkiil7lRK7VZK7W5paUlLo8fDKp/dH4kRMhexyWI2IcRcl7agoJR6H9Cstd4z3pekODZskF5rfb/WepPWelNRUdGU2jgVmQlbckpQEELMF840vvcVwAeUUu8FvEBAKfUzoEkpVaa1blBKlQHN5vn1wMKE11cAZ9PYvimxho+CoSiRmBG7QjIbSQgxx6Wtp6C1vltrXaG1XoKRQH5Ra/1J4EngdvO024EnzMdPAluVUh6l1FKgCtiZrvZNlbUlZ3vvAABup0N6CkKIOS+dPYWR3As8qpS6A6gFbgXQWr+jlHoUOAREgc9qrWftXdYaPmrtCQOQ73PT2B0iEovjypDlH0KIuemcBAWt9cvAy+bjNuDaEc67B7jnXLRpqqxEc3uvERTysoyg0B+JSVAQQsxZcveapKFBoSDLDWAnnYUQYi6SoDBJWR6jk9USNHIKeVZQCMdHfI0QQsx2EhQmKdtrBIXmYAiAfJ8LkGmpQoi5TYLCJHmcGbidDpq7k3sKEhSEEHOZBIUpCHhdNJvDR1ZOQSqnCiHmMgkKUxDwOunqjwAJOQXpKQgh5jAJClNg5RXAWKcAMnwkhJjbJChMQbbXZT/Ok+EjIcQ8IEFhChJ7CnnSUxBCzAMSFKbACgoepwOfx1jMJjkFIcRcJkFhCqzho0x3RtKmO0IIMVdJUJiCgBUUXBm4Mhw4HUqGj4QQc5oEhSmwho+siqmZrgwJCkKIOU2CwhTYQcEcOvK6MySnIISY0yQoTEF2wvCR9bMvHKOzLzyTzRJCiEmToDAFgRTDR0/sPcuWf3qBtp6BmWyaEEJMigSFKRjaU/C6rWmpcfbVd85Us4QQYtIkKExBIHNoT2HwP+eB+u4ZaZMQQkyFBIUpSJVTsBw40zkTTRJCiCmRoDAFQ6ekRmIaAKXgwJmuGWuXEEJMlgSFKXBlOKgq9rO82A/Amc5+AC5fVkBT9wDN3aGZbJ4QQkyYBIUpeu5L7+YTly4GoK69D4BbL14IwI6T7WO+ftepdrr6IulroBBCTIAEhWl08eI8AG5eX0auz8VLR5pHPT8ai/PxH2znx9tOnYPWCSHE2JxjnyLG6we3b6IlOIArw8HVK4t56Wgzsbgmw6FSnh+KxonENPUdfee4pUIIkZr0FKZRwOtiWZGRX7hmVTEdfRH+6MEd7DndkfJ8qyRGU1AWugkhZgcJCmnynpVFXLIkn+017Ty1/2zKc+yg0CUJaSHE7CBBIU2yvS4e/dPLWJzvo7l7sCcQDEXsXEMoEgegUWYpCSFmCQkKaVYc8NAcHLzpP7Kzjj/+8S46esN2T6GrPyLVVYUQs4IEhTQrCXhpSugpnGrrBaC9L8xAdDAQNElvQQgxC0hQSDMjKITQ2ljtXNdhLHDr7o8wYA4fATRKXkEIMQtIUEiz4mwPA9E43f1RAOrNBW5d/RFCiT0FmYEkhJgFJCikWUnAC0BTMEQ8rqk3S2F0h6J2ohlkBpIQYnaQxWtpVpztAeArv9pPvs9FOGoEgq7+CFnuwaqqMgNJCDEbSFBIM6unsK+uM+l4d3+EDGWsdM50ZUiiWQgxK6Rt+Egp5VVK7VRK7VNKvaOU+gfzeL5S6jml1HHzZ17Ca+5WSlUrpY4qpW5MV9vOpeKAJ+Xx7oRpqIsLfBIUhBCzQjpzCgPANVrrC4ENwE1KqS3AXcALWusq4AXzOUqpNcBWYC1wE/BdpVRGqjeeS3xuJ9le49+SAh8AOZmupETzonyfDB8JIWaFtAUFbegxn7rMfxq4BXjIPP4Q8EHz8S3AI1rrAa31SaAauCRd7TuX1lfk8JGNFdxxZSVXryyiKNtDV8KUVKOnMGBPWxVCiJmS1pyC+U1/D7Ac+I7WeodSqkRr3QCgtW5QShWbpy8Atie8vN48NvQ97wTuBFi0aFE6mz9tfnbHpQAopbhty2I+8r1tdIeMnoLb6aA0J5NwNE5nX4S8LPcMt1YIcT5L65RUrXVMa70BqAAuUUqtG+X0VPWlh3111lrfr7XepLXeVFRUNE0tTS+lFEoNXp41fDQQieN1Oig1k9EyhCSEmGnnZJ2C1roTeBkjV9CklCoDMH9aO9HUAwsTXlYBpC4vOscFvE66+6OEIjG8rgxKzGS0JJuFEDMtnbOPipRSuebjTOA64AjwJHC7edrtwBPm4yeBrUopj1JqKVAF7ExX+2aSnWiOxPC4HIML3CQoCCFmWDpzCmXAQ2ZewQE8qrV+Sin1JvCoUuoOoBa4FUBr/Y5S6lHgEBAFPqu1npelQ3MyXXSHIvRHYnidGfa01cYuKXUhhJhZaQsKWuv9wEUpjrcB147wmnuAe9LVptkikOlCa2jrCeN1ZeBxZpCf5aYpKD0FIcTMktpHMyCQ6QKgOTiA12V8BCUBr9Q/EkLMOAkKMyDHDApN3SG8LmN93oJcL/VmWW0hhJgpEhRmQKHfyCEMRON4nEZQWFbs52RrL9FYfLSXCiFEWklQmAFlOV77scccPlpe5Ccci1Nr7rcghBAzYVyJZqXU341xSrPW+r5paM95oSjbg1KgNXjNnkJVSTYA1c09VBb5Z7J5Qojz2HhnH23BKFaXatUxGDWMJCiMkyvDQZHfk5RoXlaUBcDx5h5uWDuTrRNCnM/GGxRiWuvukX6plJJKbhNUmuM1g4LRU8j2uigNeDnR3DPGK4UQIn3Gm1MY66YvQWGCrHpHVk8BoKrEz3EJCkKIGTTenoJLKRUY4XcKmPP7HpxrpWay2Zp9BEYJ7f31DTPVJCGEGHdQ2A58YZTfPz31ppxfrKCQ2FPI87npDkWIxzUOx0jpGyGESJ+JTElVo/wTEzQ4fDTYU8gxy18EQ1Eauvq54O+f4e3ajplqohDiPDTensKlyOyjaWX3FBKGj3J9xgY7Xf0R3q7rIBiKcqwpyEWL8lK+hxBCTDeZfTRDlhX5cWc4WJCXaR+zyl909oc5eKYLMAKEEEKcKzL7aIaUBLzs+dvruHxZgX0s12cEha7+CAcmEBTuffoIzx1qSk9DhRDnFZl9NIOyva6k51ZPoaMvwjtnjI5ZZ9/YQeFn20/T2NXP9WtKpr+RQojzisw+mkVyzaCwv66T4EAUGLunoLWmNxyltSec9vYJIea/iWyyI7OM0szaZ2H7yTYAMl0ZYwaFvnAMraG1R3ZtE0JMncw+mkW8rgy8LgdHG4MArC0P0D1GUOgxexRWUIjHNeFYPGmqqxBCjNd4E80xrXW31ror1T8k0TxtcjPdRGKa/Cw35bmZdCYEhUgsTq8ZBCxWUGjrDRONxfnp9tNcce+LhKOyL4MQYuJk9tEsYyWbF+b7yPW5koaPvvHMUT783W1J51tBQmto7wvz2vEW2nrDnGztPXeNFkLMG+MNCi6lVGCEfznI7KNpk2NOS12c7yMn00V3v1H2AuBQQzdHm4J27wBIetwaDLO3zpjKeqwpeA5bLYSYL2T20Sxj9RQWmUEhrqEnHCXgddHQFQLgZEsvF1TkANATGgwK++s77dzCcQkKQohJkNpHs4w1LXVRgc+ejdTVF0FrTUNnPwDVLYM3/N7wYFB4/nAzAK4MxVEJCkKISZDZR7NMYk/Byic8e6iJS5fm0xuOAXCieTBf0DMQsx8/f7gJd4aDK6sKOd4k+zIIISZOah/NMlapi0X5Pura+wD4+lOH7O06AU60DN7wh85G2rKsgLULcnjpaDOhSEympgohJkRmH80y772gjC9cV0VZjtdOOgOcaDF6BwVZbp4+2MjtD+6ktWeAnlAUldB/++MrlrCsKIu4hvqOPrZVtw4LHEcbg9z2wA76wsnHhRBCZh/NMpVFfr5w3QqUUvZQUqJLK/MBeOVYC99/5QQ9A1H87sEO37urisjPMkpw17T08okHdvDwztqk99h5so3XjrdypHH8eYdn3mlkz+n2yVySEGIOmY7ZRwqZfZQWeeb+ChaHgrv/YDUbF+Xxdl0nP9tey+XLCsjyOPnt569EKXA4FLmZxuuqW3rQerCXYbGK7NW197FxlL0aYnHNP/3uMLdfvoS/fvwAa8oD/PSOS6f5KoUQs4kkmmcxryuDX/+vy1lSkMXme56nKNvDwnwfn76ykoNnuvjt/gZeOtpMZZGfRQU++3VWXuKUuYCttn1IUOgfDAqjOdnaww9fP8kvd9cRDEWp7+ifzssTQsxCkmie5axd19aWB/AkJI2rSvw4FMQ1ZHmSP0YrF2Gtaj7Vmnzzt2Y11Y4RFPrM2U5Bcy1EfUcfsbgmQ/aPFmLeGm9QkETzDPvW1ouSnnucGVTk+aht78PvSU7pZHucZDgUJ81g0NDVz0A0hsfc+tMaPhorKARDyYnoSEzT2B1iQW7mCK8QQsx1kmieI5YWZrG0MCvp2BLzuX9IT0EpRW6ma7ByqiZp6Ker39h7oa599OGgYGh4hdbattEDiRBibptoonmkcYPfT0trxIRUFmbx6rGWYcNHYAwhtfUObrxT29bHsiI/MNhTaOjqJxyN43am/m7QndBT2Lgol7dqO6lr7+OyhC1EhRDzy7iCgtb6H9LdEDFxS0foKcBguQyP08FANM6ptsFkc1d/xD5+trPf7nEMZe3lcOvFFXxgQzmf+tGuMYechBBz20RqH4lZxgoKqXoKueZ01qWFWfg9TnsVtNaazv4IFywwCuqNViPJyinc+5H1XFlVRHmuV4KCEPNc2oKCUmqhUuolpdRhpdQ7Sqm/MI/nK6WeU0odN3/mJbzmbqVUtVLqqFLqxnS1bb4YT08hP8vNxsV5bK8xFp6FInHC0ThXrSgi2+PkpSPNI75/MBTFbyatwSi9cbpN9mkQYj5LZ08hCnxZa70a2AJ8Vim1BrgLeEFrXQW8YD7H/N1WYC1wE/BdpZQksEdRkZfJ565ezo1rS4f9zpqWmudzc8WyAqqbe2jqDtnTUQv9Hq5aUcQLR5rt/RqG6g5FCHgHA05VcTbHm3uIjXA+wBvVrfzXC8encllCiBmUtqCgtW7QWr9lPg4Ch4EFwC0Yi90wf37QfHwL8IjWekBrfRKoBi5JV/vmA6UU//vGlSwv9g/7nbUaOi/LxRXLCwHjht1pzjzK9bm4dnUxLcEBDpzpSvn+wVCEbO9gqY01ZQH6wrFRewvffO4Y33z+GKFIbMRzwBjGko2AhJh9zklOQSm1BLgI2AGUaK0bwAgcQLF52gKgLuFl9eaxoe91p1Jqt1Jqd0tLS1rbPZflJvQU1pQFyPO52HaizZ55lJPp4uqVxTiUUXI7lWAoSnZCT2FNeQCAww2pb+aNXSF2n+4grhmzdPcrx1q44ZuvUtMiJb6FmE3SHhSUUn7gMeALo62KJvV012HjFFrr+7XWm7TWm4qKiqarmfOOVUwv1+fG4VCsKg1wqrXXHj7KyXSRl+Vm0+J8e3OeoYKhqL3RD8DyYj8ZDsWhhtQ9i2feabQfH2kc7aOG0+Z6h6bugfFflBAi7dIaFJRSLoyA8HOt9ePm4SalVJn5+zLAuiPVAwsTXl4BnE1n++Yza/ZRfpZxUy8OeGgODtCV0FMAuHZ1MYcbujnTOXwhW3coktRT8LoyWF7kH7Gn8OKRZiqLsvC6HBwdowJrU3fI/htCiNkjnbOPFPAAcFhr/e8Jv3oSuN18fDvwRMLxrUopj1JqKVAF7ExX++a7JQU+MhyKykIj31Dk99ASHEjKKQBct6YEgBdTDCENHT4CWF2WzaGzqXsBRxq72bAwl6ri7DHLcls9hKGlNMZytDE46owpIcTUpLOncAVwG3CNUmqv+e+9wL3A9Uqp48D15nO01u8AjwKHMFZIf1ZrPXq2UoxocUEW+792AxcuzAWgKNtDfyRGbXsfrgxlT2NdVuQnP8vNIfPb/2/2neW2B3agtR6WaAYjr9DYHaI9YbU0QGdfmKbuAVaWZLOydOyg0Bw0egqpSmmM5uM/2M4f/3iX3eMRQkyvdM4+el1rrbTW67XWG8x/v9Nat2mtr9VaV5k/2xNec4/WepnWeqXWWvZomKLERW1F2R4A3jrdSUWeD5WwXVtxttGLANh2wtiA52xXiEhMExgSFFaXWcnm5N7CMTOxvKI0mw0Lc2ntGeDLj+4jEotz12P7+fzDb/NWbYd9vjV8NNGegrVm4ol9Zyb0OiHE+MiK5vNEcbYXMIZ4Fub7kn5XlO2hxfzmbgWHfXWdACmGj0YKCkbPYEVJNn+4eSGfeXclj71Vz/dePsEju+p4ct9Zvv/KCfv8weGjiX3jX1JgLNh7ZGfdGGcKISZDgsJ5wuopxDUsyk8ufV2c7aXZDAZWZdWRgkKh30NxtmdYXuFYUxC/x0l5jhdXhoMvX7+SLHeGHQhWlWZTa1ZlDUVi9iyoifYUesz9pg81dNMxZAhLCDF1EhTOE1ZQAFicnzXsd609A8Tj2g4Kb5tBIZBin+g15QEODekpHG0MUlXit4el3E4HVywvpDcco7Ioiy2VBdS29aK1tnsjMLmgYAWqmlZZ4yDEdJOgcJ7IzXThNMfjhw4fFWd7iMSMQnlWUNhz2hj/XzTkXDCGkKqbexiIDs4DONHSQ9WQldXvWWmsS3zX8kIWF/joDcdo6w3b+QQYe0pqPK55dFcdzeZregeibDCT5yeapQ6TENNNgsJ5wuFQdm9h6I2+OGAcP9naQygSByAW16wtD9h7MCRaVZpNNK7tBWjBUITWnjBLC5PPvW51MeU5Xt5/YTmLzT2ka9v77HxCcbYnac+GoWJxzV//+gB/+dh+HnrzlPG3BqKsLMnGneGwK78KIaaPBIXziB0UCoYkmv3GcWtaalmOkZT+0EXDqowA2GsfTjQbN2VrD+ilhUODjZdtd1/L5iX5diCqbeuzewrLivwjJpo7+8J89L5tPLLLSCi3BsNEYkaF10Cmi6WFWRIUhEgDCQrnkSK/h4Is97BS28UBIwhYyeObLyijKNvDBzaUp3yfpUVGTqKm1Ri+OWkWyBtpsx7AnAZrlLdo7w3jULAwP5Ouvgh/+tM9vHmiLen8p/Y38HZtJ//60fVcuDCXM5399JpJZr/HybLiLE60yPCRENNNgsJ55PbLl/DlG1YOO16cbfUUjKDw4Y0V7PrqdfY01qH8HielAa/9Tf2UGRyGJrATeV0ZlAa8nG7vpaMvTK7PTa7PTVtvmN+/08jjb9UnnX+ksZtsr5OPXlzBwrxM6jv67KS03+NkWZGf2va+pLzGeHX2hTk4QmVYIc53EhTOI1etKOLjly4adjzL48TnzuCw2VMozHaP+V6VRYPf1E+19lKW4yXTPfr2FwvzfdS399PRFybP5yI7oceyp7aDX+2pt4PDkYYgq0sDKKWoyPNxprN/MCh4nSwv9hOL60klm3/wWg233vemvS/EwTNdRGLxCb+PEPORBAUBGL2FcCyOUpDvG19QqGnpQWtNTWuvvahsNKUBL81Bo0RGfpY7aQ1ETUsvX3viIP/wm0OEIjGONAZZVZYNGJsJRWLanoKa5XHaM5DerusY9nfG0tg1QH8kRmN3iOrmIO/7r9d5eGfthN9HiPlIgoIA4Ob1ZQBoDc6Msf9nYSSJo7T2hDnV1jtqPsFSlG1Uau3ojZDncw+rq9QbNha1/XxHLT0DUVaVGqunK/KMxXZW5VW/x8mifB8FWW7eOt1pv/6p/Wd55djYe2x09hmL3mrb+uyy4dNdZO+5Q0184NuvE45KD0TMLRIUBABfvG4FC3IzuXhx3tgnY2zNCfDo7jo6+yJcsCBnzNcUZXvoC8c409lvBgWjp7ClMp8Mh2JxgXGj//aLxnaeiT0FGNzcx+9xopRi4+I8u55SJBbnrx8/wHdeqh6zHR1mUKjr6ONFMxhsr2lnIBrjbGc/J1snn8B++Wgzvz/YyM93nGZ/fZfsaS3mnOE7vovzkjPDwStfeQ+jbL+c5JKl+eT6XPzH88dRCq5bUzzma6yEds9AlLwst71a+sKFuVyytIA1ZQGqm4N849ljeF0OVpYYQWFBrjGd9WiTkfPI8hi5i42L8njuUBPtvWGONHbTHYomLYwbibX73DtnuthzuoO15QHeOdvNnlMd/GjbKWrb+njmi1clveZv/vsA719fzqWVBaO+96d+tAsAt9nbOtHSQ5V5HULMBRIUhG08w0YWt9PBzReU8fMdtWxanDfiTKVEiaU28rNcFGQZuYvVpQE+aK+JKOXWTQsZiMTtKq+Z7gwK/R7qzNpJ2R4jmFy0KBeA/fWdvHqsFTC2BNVaJ1WBHcrqKTz+9hlicc3df7Ca23+0k+01bdR39HOsOUhfOIrPbfz9/nCMn22vZSASHzMoWMJm4no6p81+7+UTbFqSx+Yl+dP2nkIMJcNHYtI+vLECgJvWlY7r/MSgkOtzU1WSzYOf2mTnMywlAe+wBXYrSgZXS1s9BWuV9NnOEC8eMTYJGojG7Z5AKrG4TirGl5/l5rJlBZQGvNR39NPcHUJrkvaDsILI0HpPqeSZmxeVBDyUBDxUN4++wK69N8wnf7jDntY7knhc82/PHuXxtyZWMlxrzfGm0fe2ECKRBAUxaRcvzuPnn76U2y5bPK7zrZXTMDjD6ZpVJbjG0UNZWWoMwbidDrtHU+T34FBwuq2XU2199nBTY8IQktaD42GxuKa7P5I0RPaelUVkOBTluV5OtfXSZlZeTawCawWFY03BURPHsbhRP+ozV1Xyu89fyYqS7DFXXT93qJHXq1v5772j3+y7+iNEzfZPxPaadq7/5qs8tO3UhF4nzl8SFMSUXLG8EI9z9PUJljyf2y7Kl5c19rTXRNYNP/Gm7MxwUBLwsuuUsU/T5qVGkryxywgK1c1B1n7tGf7pd4c53dbLFfe+yOcefguASnO21DWrjFxIWU4m7yQEgsRegdXziMT0qN/8u/sjaA2lOV4K/B6WFfk50dyTFJiGevW4Mew11qypFrNQobWd6nhZO+Td+/SRCb1OnL8kKIhzxuFQFJq9hfyJBoXS1Mna0hwv++uN1cnWWLvVU3j9eCt94Rjff7WGd//ryzR2h3ij2iincfP6MjYszOXdK4oAKMv1MmAGHKdDJQUIq6cAow8htZvnWde2rNhPbzhGQ1fq5Hcsrnn9eCtOh2JfXac9VRZg16l2vvX8Mft5q1lufLShsVSs0iD9kVjSzndCjESCgjinrLyCNfY+XiPN4CnPySRqjgdtXJSHUtg34f31XRRne3jszy7jM++uZFPCdNtrV5fw35+9wl4rUZ4zuPHQ5iX5HGnoJmomizvMG7FSjFoew9r0J9ccGttoJsKfO9SU8vwDZ7ro6o/wyS2LiWu48Vuv8vMdp9lR08at973Jt54/bu9FbfcUJhgUEkuTvzqONRxCSFAQ51RxtpEHGLr381iGFvGzlJoVXd1OBwtyMynye2gyg8Le+k7WV+Ry8eJ87v6D1UklPoYGJasyLBhDSgPROKfMNQbWzf7Spfm8eKR5xOEgK3hY+ZK15TmsWxDg4Z21KV9j7W5351WV3HpxBU6Hg++/UsM//OaQfc7pdqMN1sZEY+UUfrr9NL/YMbg6uzsURSljBbrUexLjIUFBnFML832U5WTicIw8ZXQk37j1Qr798YuSjlk384pc4z1Lc7w0dIfoDkWoaenlworBRXXWgjsY/DZvKc81egpOh+KK5YUA9hBSR18Yv8fJhzdWUNvex+vVrXbeIpEVPPKyBgPOxy5ZxJHGoD3ElehoU5Bcn4uyHC//euuFfPH6FdS293GooZtPbjECmLVnRWuP8d7BgeiIdZpCkRj3/PYQf/3rA/Y2qN39EfweJxsqcjkgQUGMgwQFcU598boV/PzTl07qtR+9uIL3rU8u511mDvssMFc9lwa8nGztYX+dcQO80KyRBLCs2EguZzgUgSF7T1vBpTjbQ1WJH7fTYc9A6uyLkOtzcdO6UtxOB7c9sJP3/udrw9pn5R7yEgLO+y4oRyl46ejwMhpHG4OsKMm211TcuLYEr8tBljuDz19bBRibEgFJW5iO1FvYebKdUCROod/Dj83ZRsFQlIDXxboFOTR1D9g72AkxEgkK4pzK8bnGVSdpvMpyjZu5tcXoTetKqWvv568e2298QzbH9QF8bicVeZnkZrqGLW7Lz3LjcTooDnhxZRirqa2kslHV1U3A6+Ljlxjf4Nt7w/SYSVxr3UN7Xxi304EvoVpsjs/FuvIctg3ZL0JrzbHGoD2rCiDb6+JL16/gL29aRXG2l0K/h1q7pzAYFDpHCAovHW3G43Rw66YKGrpC9IdjdIciZHudrDd7TJPpLYSjcf72vw/aq8WPNgbtOlRi/pGgIOa0Beawz2IzKHzgwnKWFmZxprOfL9+wYljuYlVpwN5UKJFSRu0lq87SmrIAh852o7Wmw+wpAPz9B9byH1s3ANDQ2U9DVz+b/s9zPPNOIx29YfJ97mEB5/JlBbxd20F/eHDvh4aukLG16JBZVXdetYzbL19iXFOBz84ptPYM2KUz/u6Jg3z6oV3DruHloy1ctswoFwJwqq2XYChCINPFmvIADjWYx5iIww3d/HT7aZ7a38CJlh4+8r1t3PHQLrTWRGNxXj/eOuq029GEIjG2nWglEovzjWeOjrmID4wgJaXO00eCgpjTSgJe7vvkRrZuNr7BOzMc/N8PXcBtWxZz25bhi+r+8Za1/NfHNqR8r/s+eTF/+741AKwuy6atN0xLcIBOs6dgsQLRmc5+jjX1EIlpnth7Jil4JLpsWQGRmGb36Xb72FFzlfFIU23BCHRWT6ElOMBSs4f1RnUbrxxrSboxnjEL+V1ZVWSfd6q1l+7+KAGvE5/bydryHLafbB/+h8ZgTfE93NDNlx/dR284Sn1HP2/XdfLsoSY++cCOSU93ffytM3z8Bzu49b43+fZL1dz/Ws2Yr/nkAzv4q1/tH/O8H79xklu+88aE2/SbfWd5+zyevitBQcx5N60rIyfhZnzZsgK+/sF1KWs5ledmsrw49Y24sshPidmLsM450dJLR284abaSlZQ+2xmivsO4ab98tIXGrlDK9Rebl+TjdKikIaTD5tDUihHaAsaQWEN3iFAkRltvmOXFg6U+IjHNS0eaufvx/YQiMXs708uXFdjDczWtvXSHInZv6bJlBeyt7SQUMXos2060svX+N8fcvc7KQ7x5oo29dZ382buX4XY6eHLvWXuf7qHbqY6XlYfZa/Zgnj7QMGovoHcgyu5T7fzuYAN94eio7/12XSf76jrtqcXj9ecPv82HvrttzPefryQoCJGCtQ91dXOQ7lA0abaSNa32bGe/XaSvLxzjwJmulCu1rU2BEoPCmyfaWFHiTwpmQy0u8KG1kQeIxTXLEoICwNd/e4iHd9bx/OEm3jzRRp7PxcqSbPweJ0XZHk619hIMRe0S5ZdVFhCOxdlz2vgW/G/PHmN7TfuYu9c1dRv5jDOdxrXesLaUq1cW8cw7jXYifMeQHsjxpiAvp0iuD2XlSq6sKuQrN66koy/CG9WtI56/r76TuIZQJM5zh5rsdRxgBDkr4MFgct5a1T0eicNg970ydq9lPpKgIEQKZQEvXpeDt2s7geR1Dc4MB6UBL2e7+qnv6GNBbiarSrOpKvbz/iHF/SyXLy/kQH0n3aEIoUiMnSfb7amvI7GGqXaaN9w1Zcm9CisgPbH3LNtr2thSWWBP9V1amEVN62BOAWDzUmPfim0nWnmrtsMODqdG2PMhEotzrCmYVI7c73GyrjzA5iX5NHSFeNv8hr/ndEfSN/xvv1TNZ366Z8xv283BASoLs/jpHZfy6SuXkuXO4IXDIwcT6/MIeJ38xSN7ufrfXqY/HOON6lY+/oMd/PrtwRpSzWZQsKbzjkdfQt7nsT31k86VzGUSFIRIweFQLCnIsmsSleVmJv2+PDeTs5391Hf0s7Qwi99/4Sqe+9K7uWndCEFhWQFxDTtr2tlzuoOBaJwrq8YICnnJQWFhvs/+1m8FjIDXyXOHmjjT2W+X7ACjttPBM13ENfZr/B4nK0uyOXimmyf3nsXrMv7vP3RToWgsTjga579eOM57/+M1Djd224sHNy/Jw5nhYLWZzK5u7iHgddIXjiUtjmvsCjEQjY+5irolOEChucrd48xgTXmAI40jlxJ5u7aDyqIs/vyaKi5alEt7b5hnDzXamysdS6gIa/UU2noHUr4XGEnrxI2QrJld6xYEONPZb68TOZ9IUBBiBMuK/LT1hnFnOIZ9qzeCQoj6jn57xtJoLlqUi8fpYNuJNl4z6x1dsnT0vRlKA14cCvsbfUWuj5xMY7HbRrNkx9fev5bibA9fvn4Ft25aaL92ZWm2XcspcQbWkkIfde191LT2srzYT3G2JykoPLnvLJff+yIf+u4b/GJnHdG45uCZbjYvyWNJgY+bzXUiVlAAeO8FRiA8mFAvyvqW/sw7qUt8WFqDA0kl1VeVBjjSEEz5DV1rzdu1nWxclMefXFXJY396OQtyM/mX3x+1h+ZqzP0rBqIxe6pw2yg9hR++XsPV33jZ/m9s1Z+yrun1UYayRtMcDNHWM3Iwms0kKAgxgkozr7BlWcGwMhvluZnUtvfR2jMwrqDgcWaweUk+20608kZ1KxsX5Y1YusNiDVP1DETxe5wEMp0syM3kggU5XL+mhEuX5vOhixaw86vX8efXVpGRsEp8Q8KiPWv4CGBRfhZ1HX3UtPSwuCCLpYVZ9jTQqLmlaZbHyTtnu5PWRizIy+Tlr1zNRy829tDIz3JTaiblL63Mx+9x2vs2aK3tIafnDzeNmshuCQ4klVRfVZZNcCBq5y8Snensp603bK9SdzgUH7pogd1Lum51CTWtPfb7WlpHuTn/Zl8DcQ1f+dW+pECyYWEuZTletp2YXFD43C/e5ouP7iMSi9PQlXwtO2raxrVD4EyRoCDECKypndevHr7V6JrywW/K1sK5sVy2rIAjjUEOnu3iXWMMHVmsIaTyXC9KKb7ziY38y0fX84ELy/nlZy4bsVxIYvuyE1ZvLy7wEYlp6jv6WVLgY2lhlt1T2FffRc9AlK/cuJLPX7OcS5bms8i8tpIUO+utNnMciwuyqCrx2wvaegai9IVjXFlVSDAU5cm9Z7nvlRMEQ8mL7vrDMYIDUYoDyT0FgCMNwxfHHTxj9ETWJewH/tmrl3P/bRfz4Kc2s7Y8QH1HP6FILCkotPWGqUmxr8XJ1l4ON3RzxfICalp62VbdZieu83xuLl9WyLYTbcTHu0dtgpqWHnadbOc/nj/OFfe+yIOvnwSMwPtHD+7kn38/uVLmWms+/dBuHjDfLx0kKAgxgqtWFPGBC8uHldYAeP/6Mi42h3AWjTMoXL7MGC7SmjGTzBYrd2D9LPR7htVtSiVxj4vE4aPFCW21egptvWG6+iNsq25FKWOW0pduWMmjn7mMC8xv5SUpFvxZgWdRvo8VxdkcN6enWt+CP7xxAeU5Xr7yq/3c+/QRnj7QmPR66xt8Yk/BWrfxxonWYd/wD57pIsOhkoauMt0Z3LC2lAyHorIoC62NelHNCUHhyb1nuebfXuHAkPpTv91/FoB/vGUdTodi16l2O6eQ63PxrqoCOvsiSeXSd9S0JVWeTWUgGqO1J0x/JMZD206R4VD841OH+MWOWk619TEQjfNG9eQW/HWHojx/uImvP3WIf3/u2NgvmAQJCkKMoNDv4T8/dlHKaaZKKX7xJ5fyoz/enDRUM5oLFuTg9zjJ9jqTCvWNxuopLBjHENVQ1kI6a/tSSO7VLCnIYlmRMc315aPNvHGilTVlgaTrXVdutDPx27zlU5cv5T+2bqDQb9SLau8N09ozYE9hLcvJTMpzWKuzm7tDNAdD9o07Mafg9zhZlO/jR2+c4hM/2JH09w6c6aKq2I/XlXpTJ+taalp67J5CQZbbHopKLPHROxDlR2+c4sqqQpYV+Vm7IIfdpzrs0uS5mUZPAbCnyFY3B/nD+7fzo9dPpfz7lsRiicGBKF+4bgXvXlHE3z1xkKcPNADGNN+acazeHupsp7VPuZOczJGnM09F2oKCUupBpVSzUupgwrF8pdRzSqnj5s+8hN/drZSqVkodVUrdmK52CTFdPM4Mrl5ZPKysxUicGQ62bl7Ixy9ZlHJhXSrldk9hfL2RRP/ykfUEvE67aKD1fq4Mo71LCnxcuaKQDQtz+cr/28/2mnauSpjBBHDVikKKsz32sE6iomwPt2xYAAx+w0+cwlqc7eHOqyr514+uZ2F+pr0e4o6HdnPJPS/w8x2n7fdJdO+HL+D6NSUcbQralWe11hw805U0dDTU0oRFey3BAZSCFQm1pY42dvOh777B42/V8+Ntp2jrDfOl61cAcMmSPPbWd9IcDOHOcOB1Gbv6LS/284aZxH5kZx1grJVIJR7X3PfKCXu2mOWaVcX8663ricY1D7wxOOyzLSGJHY7GefD1k0mlUFKxgsJP7riEO961dNRzJ2v0TNfU/Bj4NvCThGN3AS9ore9VSt1lPv8rpdQaYCuwFigHnldKrdBaj/5fSIg55m/MMhrjZQ8fTaKncMPaUvavLU06luFQVOT5aOwKUZTtQSnF92+7mK/8aj8bF+Vy51WVSeevLc9h51evG/NvWTffY41B+iPGrKfigJcsj5NbNy3k2UNNnGjpIR7X9jf2x98y1hQMDQqXLy/E4VA8d6iJvXWdXL2qmLp2I8l8wShBIcvjpNDvoa69D6UU+T63vd8GwG8PNNLaM0Bz9wDBUITrVhdz0SLje+mmJfn84LWTvHa8lRzfYMHEdy0v5Je76ugLR3ncXAMxtKhgTUsPj+yqY0tlPvc+fcROwK9bEKCjN8KqUqMS7qrSbI40Bu3P9M2aNm67bAlgbMf6j08dYn99J9/amlwePpEVFCbzv4fxSltPQWv9KjC00MotwEPm44eADyYcf0RrPaC1PglUA5ekq21CzBWbl+SzdfNCrhxnDmI8qor9rCjx2ze+koCXn/zPS/jCdSvwuSf3PbE420N+lptDDd00dYfwe5xJs6uWFfk51dZLnVkW5G9uXk2xGQzyU+RI1lfk4FDYNYieP2xMbX33kJ7MUAvyMqnv6Ke52wh6BeZQmMfpsHMUZzr76Q5F+aLZSwDs/FB1cw+5CcMyFyzIoT8S46n9DbT3htlSmU9LcLAEeXtvmE/9aBf3v1rDXzyyFxisFfXDP9rMLz+zJSnAAKwo8XPhwpykLV+ttv333rNJ27IOdabT6MkUZg0fzpsu5zqnUKK1bgAwf1rTOhYAdQnn1ZvHhlFK3amU2q2U2t3SItsLivkty+Pk3o+sT5nXmKz/++ELuO+2i6ft/cDIsaxbkMOBM900B0PDchDLi/12vSYwbrZv3HUN2+66JuVQms/tZFVpwF4x/fzhJqqK/WOWXa/IzeRMZz+n2npZXOCjwExi32j2mJYU+Fhe7OeDG8pZWz7Y6yj0e+xv8IlFDa1yJ8+a6y3+cLORI7F6Cz964yRnOvu5cGEuQXOXOzBWwJfmeKnIGxz2u8IOCtmsLg1wuq3PLr+euI/3wzsTb4XJznb2U5brndQmVeM1WxLNqa4wZWpea32/1nqT1npTUdHo3xqEEMMV+j1JeYbpsq48wPGmIIcbBodILMvMm6u1mG15sR9XhsPOmaRy0aJc9tZ20tYzwI6T7Vy3pmTMNlTkZXKmo5/a9j4qi/zcuLaEP7lyKe+/0JhBdvnyQp7683fxjVsvHPZaa8+JnMzBAFxpBqHXjrfgdTm4bnUJSmHvpLfjZDvrygN8839cyLKiLD5tjvOn+u97aWU+Fy/O45pVxfYMqqPm6u3Grn6Ksz1cvDiPx96q596nj/Do7uHB4Wxnf9J+4ulwroNCk1KqDMD8aRU5qQcWJpxXAZw9x20TQkzBBQtyiMY1J1t7uWFILsMIAoodJ43CfQX+sYc/rqwqJDgQ5Z+ePkIsrrlhHEFhQV4m4VicSExTWZhFZZGfr968hgsX5uB1Obh+TQleV0bK3sn6ilwguaeQ63OTn+VmIBqnstBPttfYNOnlo82Eo3H21XVy8eJ8Kov8vPDl9/AxcxOmVMHO53by2J9dzqWVBaw2p/MeMtdjNHSFKMvN5CMbK6hu7uG+V07wkzdP2a99u7aDrz91iINnu0YNpNPhXAeFJ4Hbzce3A08kHN+qlPIopZYCVcDOc9w2IcQUWDODXBlqWGHAbK+LP9y8kLgmqQT4aK6sKsKd4eBXe+pZlO8b19TfxB5KZdHg3ynO9rL/azdy9crhCxEtgz2F5KmeVm/Bavf7LyxjX30XvzvQwEA0zqYl9iRKlhRkUZbjZUXJ6NdYnuMl4HXaJdQbukKUBbzcfEEZPncGGQ7F0cYgA9EYrxxr4UPf3cYDr58kFIlTmpO+fAKkd0rqw8CbwEqlVL1S6g7gXuB6pdRx4HrzOVrrd4BHgUPA74HPyswjIeaWirxMCv0erltdknKB3eeursLjdIy6sVCiLI+Ty8wFf7dsKB/X1N/EWTmVQ/IPbufot7sLKnJwm6VFEi0dFhSMfbfvfdpYlbxp8WBQcDgUv/v8lfYe2yNRyliEZ+3u12DmCnJ8Lp794lV849b1RGKao41BXjvWgsfp4Cs3rgRS90KmU9qmpGqtPzbCr64d4fx7gHvS1R4hRHoppfjlZ7bYM36GKs3x8uTn3jVsCupobr6gjNerW+31EGOxegp5PteEk/MBr4vf/Pm7WJiffNO1ehxWUCjLyeTKqiJePdbCypLsYdu7jvfvXrQojwder6ElOEBvOEaZOX22Is/YRwOMhPbRpiBVJX7+13uWsaUyf9S1GtMhnesUhBDnmWVFow+bjLeXYPnoxRVcvrwgaRbPaLK9LnIyXUlDRxORqn0XLcrFneFIWiPxwO2baO0ZIDdz8rPCtlTmc98rJ3hqv7HKuTQhgVyRl0lOposD9V0cawryruVFKKW4eHH+pP/eeElQEELMWg5zsd1EfODC8jGnrk7ElsoC9n3tBjLdg+U1XBmOKc/g2rzE2PTI2hioPGGhnVKK9RU5vHqshabuAVaWTi7ITcZsmZIqhBDT4usfXDftJSASA8J0yfI4WV+Rw4EzXTgULCpIDn7vX1/OWXP9QmK5jnSToCCEEDPkhjWleF0OvrX1IoqHlCf/wIZyexvYVLWn0kWGj4QQYoZ85qpK/viKJSkrv3pdGXz6ykoef6uekhRVatNFzeWNqTdt2qR37949080QQoi0sO7P463EO15KqT1a602pfic9BSGEmKWmOxiMh+QUhBBC2CQoCCGEsElQEEIIYZOgIIQQwiZBQQghhE2CghBCCJsEBSGEEDYJCkIIIWwSFIQQQtgkKAghhLBJUBBCCGGToCCEEMImQUEIIYRNgoIQQgibBAUhhBA2CQpCCCFsEhSEEELYJCgIIYSwSVAQQghhk6AghBDCJkFBCCGETYKCEEIImwQFIYQQNgkKQgghbBIUhBBC2CQoCCGEsElQEEIIYZOgIIQQwjbrgoJS6ial1FGlVLVS6q6Zbo8QQpxPZlVQUEplAN8B/gBYA3xMKbVmZlslhBDnj1kVFIBLgGqtdY3WOgw8Atwyw20SQojzhnOmGzDEAqAu4Xk9cGniCUqpO4E7zac9SqmjU/h7hUDrFF4/F8g1zg9yjfPDbLnGxSP9YrYFBZXimE56ovX9wP3T8seU2q213jQd7zVbyTXOD3KN88NcuMbZNnxUDyxMeF4BnJ2htgghxHlntgWFXUCVUmqpUsoNbAWenOE2CSHEeWNWDR9praNKqc8BzwAZwINa63fS+CenZRhqlpNrnB/kGueHWX+NSms99llCCCHOC7Nt+EgIIcQMkqAghBDCdl4GhflaSkMpdUopdUAptVcptds8lq+Uek4pddz8mTfT7ZwIpdSDSqlmpdTBhGMjXpNS6m7zcz2qlLpxZlo9MSNc498rpc6Yn+VepdR7E343F69xoVLqJaXUYaXUO0qpvzCPz5vPcpRrnFufpdb6vPqHkcA+AVQCbmAfsGam2zVN13YKKBxy7F+Au8zHdwH/PNPtnOA1XQVsBA6OdU0YpVH2AR5gqfk5Z8z0NUzyGv8e+N8pzp2r11gGbDQfZwPHzGuZN5/lKNc4pz7L87GncL6V0rgFeMh8/BDwwZlrysRprV8F2occHumabgEe0VoPaK1PAtUYn/esNsI1jmSuXmOD1vot83EQOIxRwWDefJajXONIZuU1no9BIVUpjdE+uLlEA88qpfaY5UAASrTWDWD8jxYonrHWTZ+Rrmm+fbafU0rtN4eXrGGVOX+NSqklwEXADubpZznkGmEOfZbnY1AYs5TGHHaF1nojRpXZzyqlrprpBp1j8+mz/R6wDNgANAD/Zh6f09eolPIDjwFf0Fp3j3ZqimNz4jpTXOOc+izPx6Awb0tpaK3Pmj+bgV9jdEWblFJlAObP5plr4bQZ6ZrmzWertW7SWse01nHgBwwOK8zZa1RKuTBulj/XWj9uHp5Xn2Wqa5xrn+X5GBTmZSkNpVSWUirbegzcABzEuLbbzdNuB56YmRZOq5Gu6Ulgq1LKo5RaClQBO2egfVNm3ShNH8L4LGGOXqNSSgEPAIe11v+e8Kt581mOdI1z7rOc6Uz3TPwD3osxM+AE8NWZbs80XVMlxkyGfcA71nUBBcALwHHzZ/5Mt3WC1/UwRpc7gvHN6o7Rrgn4qvm5HgX+YKbbP4Vr/ClwANiPcfMom+PX+C6MoZH9wF7z33vn02c5yjXOqc9SylwIIYSwnY/DR0IIIUYgQUEIIYRNgoIQQgibBAUhhBA2CQpCCCFsEhSEmAbK8KJSKjDKORuUUm+aFTT3K6X+MOF3S5VSO8xqob8019CglHqfUuofzsU1CAGy85oQgFHeGNgCRM1DTmC7+XjYca313w95/c3AdVrrL47yN1YAWmt9XClVDuwBVmutO5VSjwKPa60fUUrdB+zTWn/PXBD1FkYJk77puFYhRiM9BSEGbdVav09r/T6Mle5jHU/0CczVuEqpzWZPwGuuNH9HKbVOa31Ma30c7JIkzUCReeO/BviV+V52tVBtfGt7GXjftF6pECOQoCDE9LgC45s/WutdGCtX/w/GfgE/01ofTDxZKXUJxn4eJzBW9XZqra3eyNBqmbuBK9PaeiFMzplugBDzRL42auhb/hGjzlYI+HziiWYtnJ8Ct2ut42ZPYajEcd1moHya2ytEStJTEGJ6RJVSif9/ygf8GDtwea2DZiL6t8DfaK2tnEUrkKuUsr6kDa2W6QX609VwIRJJUBBiehzFKEpouR/4W+DnwD8DmDOKfg38RGv9/6wTzbzBS8BHzUNDq9muYLCyphBpJUFBiOnxW+A9AEqpPwKiWutfAPcCm5VS1wD/A2M/5k8lbOK+wXz9XwFfUkpVY+QYHkh476vN9xci7SSnIMT0+CHwE+CHWuufmI/RWseASxPO+1mqF2uta0ixP69SqgTI1FofmPYWC5GCBAUhDM3AT5RScfO5A/i9+Xik4zatdYNS6gdKqYAefZvJiVoEfHka30+IUcniNSGEEDbJKQghhLBJUBBCCGGToCCEEMImQUEIIYRNgoIQQgjb/wcvWTdqG7xNKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  136.70701618791762\n"
     ]
    }
   ],
   "source": [
    "# PTB학습\n",
    "\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from ch06.rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 RNNLM 추가 개선\n",
    "\n",
    "#### LSTM 계층 다중화\n",
    "\n",
    "![15](https://media.vlpt.us/images/dscwinterstudy/post/962a9cbd-ec80-4365-b7d9-10045598ea32/fig%206-29.png)\n",
    "\n",
    "RNNLM으로 정확한 모델을 만들고자 한다면 많은 경우 LSTM 계층을 깊게 쌓아 효과를 볼 수 있음<br>\n",
    "지금까지는 1층만 사용했지만 2층, 3층 식으로 여러 겹 쌓으면 언어 모델의 정확도가 향상되리라 기대\n",
    "\n",
    "#### 드롭아웃에 의한 과적합 억제\n",
    "\n",
    "RNN은 일반적인 피드포워드 신경망보다 쉽게 과적합을 일으킴\n",
    "\n",
    "드롭아웃? 흔련 시 계층 내의 뉴런 몇개를 무작위로 무시하고 학습\n",
    "\n",
    "![16](https://media.vlpt.us/images/dscwinterstudy/post/34d46f9e-d783-444f-b6cb-beadc86727ae/fig%206-33.png)\n",
    "\n",
    "시간방향(좌우)으로 아무리 진행해도 정보를 잃지 않고, 깊이방향(상하)에만 영향\n",
    "\n",
    "![17](https://media.vlpt.us/images/dscwinterstudy/post/dd7f0519-684e-4910-835d-7c44c51c824b/fig%206-34.png)\n",
    "\n",
    "같은 계층의 드롭 아웃끼리 마스크를 공유함으로써 마스크가 고정됨.<br>\n",
    "정보를 잃게되는 방법도 고정되므로 일반적인 드롭아웃때와 달리 정보가 지수적으로 손실되는 사태를 피할 수 있음\n",
    "\n",
    "#### 가중치 공유\n",
    "\n",
    "언어 모델을 개선하는 간단한 트릭\n",
    "\n",
    "![18](https://media.vlpt.us/images/dscwinterstudy/post/e3705441-5a2a-4a50-b6d9-591ef8c00aeb/fig%206-35.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#개선된 RNN 구현\n",
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    '''\n",
    "     LSTM 계층을 2개 사용하고 각 층에 드롭아웃을 적용한 모델이다.\n",
    "     아래 [1]에서 제안한 모델을 기초로 하였고, [2]와 [3]의 가중치 공유(weight tying)를 적용했다.\n",
    "\n",
    "     [1] Recurrent Neural Network Regularization (https://arxiv.org/abs/1409.2329)\n",
    "     [2] Using the Output Embedding to Improve Language Models (https://arxiv.org/abs/1608.05859)\n",
    "     [3] Tying Word Vectors and Word Classifiers (https://arxiv.org/pdf/1611.01462.pdf)\n",
    "    '''\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-> 오래걸림^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정리\n",
    "- 단순한 RNN의 학습에서는 기울기 소실과 기울기 폭발이 문제가 된다\n",
    "- 기울기 폭발에는 기울기 클리핑, 기울기 소실에는 게이트가 추가된 RNN(LSTM, GRU 등)이 효과적이다\n",
    "- LSTM에는 input 게이트, forget 게이트, output 게이트 등 3개의 게이트가 있어\n",
    "- 게이트에는 전용 가중치가 있으며, 시그모이드 함수를 사용하여 0-1사이의 실수를 출력한다.\n",
    "- 언어 모델 개선에는 LSTM 계층 다중화, 드롭아웃, 가중치 공유등의 기법이 효과적이다.\n",
    "- RNN의 정규화는 중요한 주제이며, 드롭아웃 기반의 다양한 기법이 제안되고 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
