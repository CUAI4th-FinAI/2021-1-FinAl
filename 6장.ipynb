{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM17Gt7mhXiD"
      },
      "source": [
        "# 6장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb9STA3VcMQO"
      },
      "source": [
        "class LSTM:\n",
        "    \n",
        "    \n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "\n",
        "        \n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, H = h_prev.shape\n",
        "\n",
        "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "\n",
        "        f = A[:, :H]\n",
        "        g = A[:, H:2*H]\n",
        "        i = A[:, 2*H:3*H]\n",
        "        o = A[:, 3*H:]\n",
        "\n",
        "        f = sigmoid(f)\n",
        "        g = np.tanh(g)\n",
        "        i = sigmoid(i)\n",
        "        o = sigmoid(o)\n",
        "\n",
        "        c_next = f * c_prev + g * i\n",
        "        h_next = o * np.tanh(c_next)\n",
        "\n",
        "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "        return h_next, c_next\n",
        "\n",
        "    \n",
        "    def backward(self, dh_next, dc_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
        "\n",
        "        tanh_c_next = np.tanh(c_next)\n",
        "\n",
        "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
        "\n",
        "        dc_prev = ds * f\n",
        "\n",
        "        di = ds * g\n",
        "        df = ds * c_prev\n",
        "        do = dh_next * tanh_c_next\n",
        "        dg = ds * i\n",
        "\n",
        "        di *= i * (1 - i)\n",
        "        df *= f * (1 - f)\n",
        "        do *= o * (1 - o)\n",
        "        dg *= (1 - g ** 2)\n",
        "\n",
        "        dA = np.hstack((df, dg, di, do))\n",
        "\n",
        "        dWh = np.dot(h_prev.T, dA)\n",
        "        dWx = np.dot(x.T, dA)\n",
        "        db = dA.sum(axis=0)\n",
        "\n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "\n",
        "        dx = np.dot(dA, Wx.T)\n",
        "        dh_prev = np.dot(dA, Wh.T)\n",
        "\n",
        "        return dx, dh_prev, dc_prev"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkMYFlSmdDlw"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Cola/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmK02SZeegM3"
      },
      "source": [
        "class TimeLSTM:\n",
        "    \n",
        "    \n",
        "    def __init__(self, Wx, Wh, b, stateful=False):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.layers = None\n",
        "\n",
        "        self.h, self.c = None, None\n",
        "        self.dh = None\n",
        "        self.stateful = stateful\n",
        "\n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        H = Wh.shape[0]\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if not self.stateful or self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "        if not self.stateful or self.c is None:\n",
        "            self.c = np.zeros((N, H), dtype='f')\n",
        "\n",
        "        for t in range(T):\n",
        "            layer = LSTM(*self.params)\n",
        "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "            hs[:, t, :] = self.h\n",
        "\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        return hs\n",
        "\n",
        "    def backward(self, dhs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, H = dhs.shape\n",
        "        D = Wx.shape[0]\n",
        "\n",
        "        dxs = np.empty((N, T, D), dtype='f')\n",
        "        dh, dc = 0, 0\n",
        "\n",
        "        grads = [0, 0, 0]\n",
        "        for t in reversed(range(T)):\n",
        "            layer = self.layers[t]\n",
        "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "            dxs[:, t, :] = dx\n",
        "            for i, grad in enumerate(layer.grads):\n",
        "                grads[i] += grad\n",
        "\n",
        "        for i, grad in enumerate(grads):\n",
        "            self.grads[i][...] = grad\n",
        "        self.dh = dh\n",
        "        return dxs\n",
        "\n",
        "    def set_state(self, h, c=None):\n",
        "        self.h, self.c = h, c\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.h, self.c = None, None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7OuwBG0em1H"
      },
      "source": [
        "from common.time_layers import *\n",
        "from common.np import *  # import numpy as np\n",
        "from common.base_model import BaseModel\n",
        "\n",
        "\n",
        "class BetterRnnlm(BaseModel):\n",
        "\n",
        "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
        "                 hidden_size=650, dropout_ratio=0.5):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        embed_W = (rn(V, D) / 100).astype('f')\n",
        "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
        "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
        "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
        "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
        "        affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
        "            TimeDropout(dropout_ratio),\n",
        "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "    def predict(self, xs, train_flg=False):\n",
        "        for layer in self.drop_layers:\n",
        "            layer.train_flg = train_flg\n",
        "\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        return xs\n",
        "\n",
        "    def forward(self, xs, ts, train_flg=True):\n",
        "        score = self.predict(xs, train_flg)\n",
        "        loss = self.loss_layer.forward(score, ts)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.loss_layer.backward(dout)\n",
        "        for layer in reversed(self.layers):\n",
        "            dout = layer.backward(dout)\n",
        "        return dout\n",
        "\n",
        "    def reset_state(self):\n",
        "        for layer in self.lstm_layers:\n",
        "            layer.reset_state()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_udc45a1ezEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "outputId": "07fa1009-5868-4ba8-f4c8-67006ae55a07"
      },
      "source": [
        "from common import config\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity, to_gpu\n",
        "from common.dataset import ptb\n",
        "\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 20\n",
        "wordvec_size = 650\n",
        "hidden_size = 650\n",
        "time_size = 35\n",
        "lr = 20.0\n",
        "max_epoch = 40\n",
        "max_grad = 0.25\n",
        "dropout = 0.5\n",
        "\n",
        "# 학습 데이터 읽기\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_val, _, _ = ptb.load_data('val')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "\n",
        "if config.GPU:\n",
        "    corpus = to_gpu(corpus)\n",
        "    corpus_val = to_gpu(corpus_val)\n",
        "    corpus_test = to_gpu(corpus_test)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "best_ppl = float('inf')\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
        "                time_size=time_size, max_grad=max_grad)\n",
        "\n",
        "    model.reset_state()\n",
        "    ppl = eval_perplexity(model, corpus_val)\n",
        "    print('검증 퍼플렉서티: ', ppl)\n",
        "\n",
        "    if best_ppl > ppl:\n",
        "        best_ppl = ppl\n",
        "        model.save_params()\n",
        "    else:\n",
        "        lr /= 4.0\n",
        "        optimizer.lr = lr\n",
        "\n",
        "    model.reset_state()\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.reset_state()\n",
        "ppl_test = eval_perplexity(model, corpus_test)\n",
        "print('테스트 퍼플렉서티: ', ppl_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.valid.txt ... \n",
            "Done\n",
            "Downloading ptb.test.txt ... \n",
            "Done\n",
            "| 에폭 1 |  반복 1 / 1327 | 시간 3[s] | 퍼플렉서티 9999.61\n",
            "| 에폭 1 |  반복 21 / 1327 | 시간 71[s] | 퍼플렉서티 4307.79\n",
            "| 에폭 1 |  반복 41 / 1327 | 시간 141[s] | 퍼플렉서티 2017.56\n",
            "| 에폭 1 |  반복 61 / 1327 | 시간 213[s] | 퍼플렉서티 1327.80\n",
            "| 에폭 1 |  반복 81 / 1327 | 시간 282[s] | 퍼플렉서티 1118.35\n",
            "| 에폭 1 |  반복 101 / 1327 | 시간 351[s] | 퍼플렉서티 851.95\n",
            "| 에폭 1 |  반복 121 / 1327 | 시간 420[s] | 퍼플렉서티 810.12\n",
            "| 에폭 1 |  반복 141 / 1327 | 시간 489[s] | 퍼플렉서티 727.79\n",
            "| 에폭 1 |  반복 161 / 1327 | 시간 559[s] | 퍼플렉서티 684.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e4815a3c5788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[0;32m---> 40\u001b[0;31m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Cola/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ded027706fa3>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Cola/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dhs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mdxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Cola/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dh_next, dc_next)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mdh_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znLOf9cEFV4g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}